<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="pdoc 12.1.0"/>
    <title>IGEnvironments API documentation</title>

    <style>/*! * Bootstrap Reboot v5.0.0 (https://getbootstrap.com/) * Copyright 2011-2021 The Bootstrap Authors * Copyright 2011-2021 Twitter, Inc. * Licensed under MIT (https://github.com/twbs/bootstrap/blob/main/LICENSE) * Forked from Normalize.css, licensed MIT (https://github.com/necolas/normalize.css/blob/master/LICENSE.md) */*,::after,::before{box-sizing:border-box}@media (prefers-reduced-motion:no-preference){:root{scroll-behavior:smooth}}body{margin:0;font-family:system-ui,-apple-system,"Segoe UI",Roboto,"Helvetica Neue",Arial,"Noto Sans","Liberation Sans",sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji";font-size:1rem;font-weight:400;line-height:1.5;color:#212529;background-color:#fff;-webkit-text-size-adjust:100%;-webkit-tap-highlight-color:transparent}hr{margin:1rem 0;color:inherit;background-color:currentColor;border:0;opacity:.25}hr:not([size]){height:1px}h1,h2,h3,h4,h5,h6{margin-top:0;margin-bottom:.5rem;font-weight:500;line-height:1.2}h1{font-size:calc(1.375rem + 1.5vw)}@media (min-width:1200px){h1{font-size:2.5rem}}h2{font-size:calc(1.325rem + .9vw)}@media (min-width:1200px){h2{font-size:2rem}}h3{font-size:calc(1.3rem + .6vw)}@media (min-width:1200px){h3{font-size:1.75rem}}h4{font-size:calc(1.275rem + .3vw)}@media (min-width:1200px){h4{font-size:1.5rem}}h5{font-size:1.25rem}h6{font-size:1rem}p{margin-top:0;margin-bottom:1rem}abbr[data-bs-original-title],abbr[title]{-webkit-text-decoration:underline dotted;text-decoration:underline dotted;cursor:help;-webkit-text-decoration-skip-ink:none;text-decoration-skip-ink:none}address{margin-bottom:1rem;font-style:normal;line-height:inherit}ol,ul{padding-left:2rem}dl,ol,ul{margin-top:0;margin-bottom:1rem}ol ol,ol ul,ul ol,ul ul{margin-bottom:0}dt{font-weight:700}dd{margin-bottom:.5rem;margin-left:0}blockquote{margin:0 0 1rem}b,strong{font-weight:bolder}small{font-size:.875em}mark{padding:.2em;background-color:#fcf8e3}sub,sup{position:relative;font-size:.75em;line-height:0;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}a{color:#0d6efd;text-decoration:underline}a:hover{color:#0a58ca}a:not([href]):not([class]),a:not([href]):not([class]):hover{color:inherit;text-decoration:none}code,kbd,pre,samp{font-family:SFMono-Regular,Menlo,Monaco,Consolas,"Liberation Mono","Courier New",monospace;font-size:1em;direction:ltr;unicode-bidi:bidi-override}pre{display:block;margin-top:0;margin-bottom:1rem;overflow:auto;font-size:.875em}pre code{font-size:inherit;color:inherit;word-break:normal}code{font-size:.875em;color:#d63384;word-wrap:break-word}a>code{color:inherit}kbd{padding:.2rem .4rem;font-size:.875em;color:#fff;background-color:#212529;border-radius:.2rem}kbd kbd{padding:0;font-size:1em;font-weight:700}figure{margin:0 0 1rem}img,svg{vertical-align:middle}table{caption-side:bottom;border-collapse:collapse}caption{padding-top:.5rem;padding-bottom:.5rem;color:#6c757d;text-align:left}th{text-align:inherit;text-align:-webkit-match-parent}tbody,td,tfoot,th,thead,tr{border-color:inherit;border-style:solid;border-width:0}label{display:inline-block}button{border-radius:0}button:focus:not(:focus-visible){outline:0}button,input,optgroup,select,textarea{margin:0;font-family:inherit;font-size:inherit;line-height:inherit}button,select{text-transform:none}[role=button]{cursor:pointer}select{word-wrap:normal}select:disabled{opacity:1}[list]::-webkit-calendar-picker-indicator{display:none}[type=button],[type=reset],[type=submit],button{-webkit-appearance:button}[type=button]:not(:disabled),[type=reset]:not(:disabled),[type=submit]:not(:disabled),button:not(:disabled){cursor:pointer}::-moz-focus-inner{padding:0;border-style:none}textarea{resize:vertical}fieldset{min-width:0;padding:0;margin:0;border:0}legend{float:left;width:100%;padding:0;margin-bottom:.5rem;font-size:calc(1.275rem + .3vw);line-height:inherit}@media (min-width:1200px){legend{font-size:1.5rem}}legend+*{clear:left}::-webkit-datetime-edit-day-field,::-webkit-datetime-edit-fields-wrapper,::-webkit-datetime-edit-hour-field,::-webkit-datetime-edit-minute,::-webkit-datetime-edit-month-field,::-webkit-datetime-edit-text,::-webkit-datetime-edit-year-field{padding:0}::-webkit-inner-spin-button{height:auto}[type=search]{outline-offset:-2px;-webkit-appearance:textfield}::-webkit-search-decoration{-webkit-appearance:none}::-webkit-color-swatch-wrapper{padding:0}::file-selector-button{font:inherit}::-webkit-file-upload-button{font:inherit;-webkit-appearance:button}output{display:inline-block}iframe{border:0}summary{display:list-item;cursor:pointer}progress{vertical-align:baseline}[hidden]{display:none!important}</style>
    <style>/*! syntax-highlighting.css */pre{line-height:125%;}span.linenos{color:inherit; background-color:transparent; padding-left:5px; padding-right:20px;}.pdoc-code .hll{background-color:#ffffcc}.pdoc-code{background:#f8f8f8;}.pdoc-code .c{color:#3D7B7B; font-style:italic}.pdoc-code .err{border:1px solid #FF0000}.pdoc-code .k{color:#008000; font-weight:bold}.pdoc-code .o{color:#666666}.pdoc-code .ch{color:#3D7B7B; font-style:italic}.pdoc-code .cm{color:#3D7B7B; font-style:italic}.pdoc-code .cp{color:#9C6500}.pdoc-code .cpf{color:#3D7B7B; font-style:italic}.pdoc-code .c1{color:#3D7B7B; font-style:italic}.pdoc-code .cs{color:#3D7B7B; font-style:italic}.pdoc-code .gd{color:#A00000}.pdoc-code .ge{font-style:italic}.pdoc-code .gr{color:#E40000}.pdoc-code .gh{color:#000080; font-weight:bold}.pdoc-code .gi{color:#008400}.pdoc-code .go{color:#717171}.pdoc-code .gp{color:#000080; font-weight:bold}.pdoc-code .gs{font-weight:bold}.pdoc-code .gu{color:#800080; font-weight:bold}.pdoc-code .gt{color:#0044DD}.pdoc-code .kc{color:#008000; font-weight:bold}.pdoc-code .kd{color:#008000; font-weight:bold}.pdoc-code .kn{color:#008000; font-weight:bold}.pdoc-code .kp{color:#008000}.pdoc-code .kr{color:#008000; font-weight:bold}.pdoc-code .kt{color:#B00040}.pdoc-code .m{color:#666666}.pdoc-code .s{color:#BA2121}.pdoc-code .na{color:#687822}.pdoc-code .nb{color:#008000}.pdoc-code .nc{color:#0000FF; font-weight:bold}.pdoc-code .no{color:#880000}.pdoc-code .nd{color:#AA22FF}.pdoc-code .ni{color:#717171; font-weight:bold}.pdoc-code .ne{color:#CB3F38; font-weight:bold}.pdoc-code .nf{color:#0000FF}.pdoc-code .nl{color:#767600}.pdoc-code .nn{color:#0000FF; font-weight:bold}.pdoc-code .nt{color:#008000; font-weight:bold}.pdoc-code .nv{color:#19177C}.pdoc-code .ow{color:#AA22FF; font-weight:bold}.pdoc-code .w{color:#bbbbbb}.pdoc-code .mb{color:#666666}.pdoc-code .mf{color:#666666}.pdoc-code .mh{color:#666666}.pdoc-code .mi{color:#666666}.pdoc-code .mo{color:#666666}.pdoc-code .sa{color:#BA2121}.pdoc-code .sb{color:#BA2121}.pdoc-code .sc{color:#BA2121}.pdoc-code .dl{color:#BA2121}.pdoc-code .sd{color:#BA2121; font-style:italic}.pdoc-code .s2{color:#BA2121}.pdoc-code .se{color:#AA5D1F; font-weight:bold}.pdoc-code .sh{color:#BA2121}.pdoc-code .si{color:#A45A77; font-weight:bold}.pdoc-code .sx{color:#008000}.pdoc-code .sr{color:#A45A77}.pdoc-code .s1{color:#BA2121}.pdoc-code .ss{color:#19177C}.pdoc-code .bp{color:#008000}.pdoc-code .fm{color:#0000FF}.pdoc-code .vc{color:#19177C}.pdoc-code .vg{color:#19177C}.pdoc-code .vi{color:#19177C}.pdoc-code .vm{color:#19177C}.pdoc-code .il{color:#666666}</style>
    <style>/*! theme.css */:root{--pdoc-background:#fff;}.pdoc{--text:#212529;--muted:#6c757d;--link:#3660a5;--link-hover:#1659c5;--code:#f8f8f8;--active:#fff598;--accent:#eee;--accent2:#c1c1c1;--nav-hover:rgba(255, 255, 255, 0.5);--name:#0066BB;--def:#008800;--annotation:#007020;}</style>
    <style>/*! layout.css */html, body{width:100%;height:100%;}html, main{scroll-behavior:smooth;}body{background-color:var(--pdoc-background);}@media (max-width:769px){#navtoggle{cursor:pointer;position:absolute;width:50px;height:40px;top:1rem;right:1rem;border-color:var(--text);color:var(--text);display:flex;opacity:0.8;}#navtoggle:hover{opacity:1;}#togglestate + div{display:none;}#togglestate:checked + div{display:inherit;}main, header{padding:2rem 3vw;}header + main{margin-top:-3rem;}.git-button{display:none !important;}nav input[type="search"]{max-width:77%;}nav input[type="search"]:first-child{margin-top:-6px;}nav input[type="search"]:valid ~ *{display:none !important;}}@media (min-width:770px){:root{--sidebar-width:clamp(12.5rem, 28vw, 22rem);}nav{position:fixed;overflow:auto;height:100vh;width:var(--sidebar-width);}main, header{padding:3rem 2rem 3rem calc(var(--sidebar-width) + 3rem);width:calc(54rem + var(--sidebar-width));max-width:100%;}header + main{margin-top:-4rem;}#navtoggle{display:none;}}#togglestate{position:absolute;height:0;opacity:0;}nav.pdoc{--pad:clamp(0.5rem, 2vw, 1.75rem);--indent:1.5rem;background-color:var(--accent);border-right:1px solid var(--accent2);box-shadow:0 0 20px rgba(50, 50, 50, .2) inset;padding:0 0 0 var(--pad);overflow-wrap:anywhere;scrollbar-width:thin; scrollbar-color:var(--accent2) transparent }nav.pdoc::-webkit-scrollbar{width:.4rem; }nav.pdoc::-webkit-scrollbar-thumb{background-color:var(--accent2); }nav.pdoc > div{padding:var(--pad) 0;}nav.pdoc .module-list-button{display:inline-flex;align-items:center;color:var(--text);border-color:var(--muted);margin-bottom:1rem;}nav.pdoc .module-list-button:hover{border-color:var(--text);}nav.pdoc input[type=search]{display:block;outline-offset:0;width:calc(100% - var(--pad));}nav.pdoc .logo{max-width:calc(100% - var(--pad));max-height:35vh;display:block;margin:0 auto 1rem;transform:translate(calc(-.5 * var(--pad)), 0);}nav.pdoc ul{list-style:none;padding-left:0;}nav.pdoc > div > ul{margin-left:calc(0px - var(--pad));}nav.pdoc li a{padding:.2rem 0 .2rem calc(var(--pad) + var(--indent));}nav.pdoc > div > ul > li > a{padding-left:var(--pad);}nav.pdoc li{transition:all 100ms;}nav.pdoc li:hover{background-color:var(--nav-hover);}nav.pdoc a, nav.pdoc a:hover{color:var(--text);}nav.pdoc a{display:block;}nav.pdoc > h2:first-of-type{margin-top:1.5rem;}nav.pdoc .class:before{content:"class ";color:var(--muted);}nav.pdoc .function:after{content:"()";color:var(--muted);}nav.pdoc footer:before{content:"";display:block;width:calc(100% - var(--pad));border-top:solid var(--accent2) 1px;margin-top:1.5rem;padding-top:.5rem;}nav.pdoc footer{font-size:small;}</style>
    <style>/*! content.css */.pdoc{color:var(--text);box-sizing:border-box;line-height:1.5;background:none;}.pdoc .pdoc-button{display:inline-block;border:solid black 1px;border-radius:2px;font-size:.75rem;padding:calc(0.5em - 1px) 1em;transition:100ms all;}.pdoc .pdoc-alert{padding:1rem 1rem 1rem calc(1.5rem + 24px);border:1px solid transparent;border-radius:.25rem;background-repeat:no-repeat;background-position:1rem center;margin-bottom:1rem;}.pdoc .pdoc-alert > *:last-child{margin-bottom:0;}.pdoc .pdoc-alert-note {color:#084298;background-color:#cfe2ff;border-color:#b6d4fe;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23084298%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M8%2016A8%208%200%201%200%208%200a8%208%200%200%200%200%2016zm.93-9.412-1%204.705c-.07.34.029.533.304.533.194%200%20.487-.07.686-.246l-.088.416c-.287.346-.92.598-1.465.598-.703%200-1.002-.422-.808-1.319l.738-3.468c.064-.293.006-.399-.287-.47l-.451-.081.082-.381%202.29-.287zM8%205.5a1%201%200%201%201%200-2%201%201%200%200%201%200%202z%22/%3E%3C/svg%3E");}.pdoc .pdoc-alert-warning{color:#664d03;background-color:#fff3cd;border-color:#ffecb5;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23664d03%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M8.982%201.566a1.13%201.13%200%200%200-1.96%200L.165%2013.233c-.457.778.091%201.767.98%201.767h13.713c.889%200%201.438-.99.98-1.767L8.982%201.566zM8%205c.535%200%20.954.462.9.995l-.35%203.507a.552.552%200%200%201-1.1%200L7.1%205.995A.905.905%200%200%201%208%205zm.002%206a1%201%200%201%201%200%202%201%201%200%200%201%200-2z%22/%3E%3C/svg%3E");}.pdoc .pdoc-alert-danger{color:#842029;background-color:#f8d7da;border-color:#f5c2c7;background-image:url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20width%3D%2224%22%20height%3D%2224%22%20fill%3D%22%23842029%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M5.52.359A.5.5%200%200%201%206%200h4a.5.5%200%200%201%20.474.658L8.694%206H12.5a.5.5%200%200%201%20.395.807l-7%209a.5.5%200%200%201-.873-.454L6.823%209.5H3.5a.5.5%200%200%201-.48-.641l2.5-8.5z%22/%3E%3C/svg%3E");}.pdoc .visually-hidden{position:absolute !important;width:1px !important;height:1px !important;padding:0 !important;margin:-1px !important;overflow:hidden !important;clip:rect(0, 0, 0, 0) !important;white-space:nowrap !important;border:0 !important;}.pdoc h1, .pdoc h2, .pdoc h3{font-weight:300;margin:.3em 0;padding:.2em 0;}.pdoc > section:not(.module-info) h1{font-size:1.5rem;font-weight:500;}.pdoc > section:not(.module-info) h2{font-size:1.4rem;font-weight:500;}.pdoc > section:not(.module-info) h3{font-size:1.3rem;font-weight:500;}.pdoc > section:not(.module-info) h4{font-size:1.2rem;}.pdoc > section:not(.module-info) h5{font-size:1.1rem;}.pdoc a{text-decoration:none;color:var(--link);}.pdoc a:hover{color:var(--link-hover);}.pdoc blockquote{margin-left:2rem;}.pdoc pre{border-top:1px solid var(--accent2);border-bottom:1px solid var(--accent2);margin-top:0;margin-bottom:1em;padding:.5rem 0 .5rem .5rem;overflow-x:auto;background-color:var(--code);}.pdoc code{color:var(--text);padding:.2em .4em;margin:0;font-size:85%;background-color:var(--code);border-radius:6px;}.pdoc a > code{color:inherit;}.pdoc pre > code{display:inline-block;font-size:inherit;background:none;border:none;padding:0;}.pdoc > section:not(.module-info){margin-bottom:1.5rem;}.pdoc .modulename{margin-top:0;font-weight:bold;}.pdoc .modulename a{color:var(--link);transition:100ms all;}.pdoc .git-button{float:right;border:solid var(--link) 1px;}.pdoc .git-button:hover{background-color:var(--link);color:var(--pdoc-background);}.view-source-toggle-state,.view-source-toggle-state ~ .pdoc-code{display:none;}.view-source-toggle-state:checked ~ .pdoc-code{display:block;}.view-source-button{display:inline-block;float:right;font-size:.75rem;line-height:1.5rem;color:var(--muted);padding:0 .4rem 0 1.3rem;cursor:pointer;text-indent:-2px;}.view-source-button > span{visibility:hidden;}.module-info .view-source-button{float:none;display:flex;justify-content:flex-end;margin:-1.2rem .4rem -.2rem 0;}.view-source-button::before{position:absolute;content:"View Source";display:list-item;list-style-type:disclosure-closed;}.view-source-toggle-state:checked ~ .attr .view-source-button::before,.view-source-toggle-state:checked ~ .view-source-button::before{list-style-type:disclosure-open;}.pdoc .docstring{margin-bottom:1.5rem;}.pdoc section:not(.module-info) .docstring{margin-left:clamp(0rem, 5vw - 2rem, 1rem);}.pdoc .docstring .pdoc-code{margin-left:1em;margin-right:1em;}.pdoc h1:target,.pdoc h2:target,.pdoc h3:target,.pdoc h4:target,.pdoc h5:target,.pdoc h6:target,.pdoc .pdoc-code > pre > span:target{background-color:var(--active);box-shadow:-1rem 0 0 0 var(--active);}.pdoc .pdoc-code > pre > span:target{display:block;}.pdoc div:target > .attr,.pdoc section:target > .attr,.pdoc dd:target > a{background-color:var(--active);}.pdoc *{scroll-margin:2rem;}.pdoc .pdoc-code .linenos{user-select:none;}.pdoc .attr:hover{filter:contrast(0.95);}.pdoc section, .pdoc .classattr{position:relative;}.pdoc .headerlink{--width:clamp(1rem, 3vw, 2rem);position:absolute;top:0;left:calc(0rem - var(--width));transition:all 100ms ease-in-out;opacity:0;}.pdoc .headerlink::before{content:"#";display:block;text-align:center;width:var(--width);height:2.3rem;line-height:2.3rem;font-size:1.5rem;}.pdoc .attr:hover ~ .headerlink,.pdoc *:target > .headerlink,.pdoc .headerlink:hover{opacity:1;}.pdoc .attr{display:block;margin:.5rem 0 .5rem;padding:.4rem .4rem .4rem 1rem;background-color:var(--accent);overflow-x:auto;}.pdoc .classattr{margin-left:2rem;}.pdoc .name{color:var(--name);font-weight:bold;}.pdoc .def{color:var(--def);font-weight:bold;}.pdoc .signature{background-color:transparent;}.pdoc .param, .pdoc .return-annotation{white-space:pre;}.pdoc .signature.multiline .param{display:block;}.pdoc .signature.condensed .param{display:inline-block;}.pdoc .annotation{color:var(--annotation);}.pdoc .inherited{margin-left:2rem;}.pdoc .inherited dt{font-weight:700;}.pdoc .inherited dt, .pdoc .inherited dd{display:inline;margin-left:0;margin-bottom:.5rem;}.pdoc .inherited dd:not(:last-child):after{content:", ";}.pdoc .inherited .class:before{content:"class ";}.pdoc .inherited .function a:after{content:"()";}.pdoc .search-result .docstring{overflow:auto;max-height:25vh;}.pdoc .search-result.focused > .attr{background-color:var(--active);}.pdoc .attribution{margin-top:2rem;display:block;opacity:0.5;transition:all 200ms;filter:grayscale(100%);}.pdoc .attribution:hover{opacity:1;filter:grayscale(0%);}.pdoc .attribution img{margin-left:5px;height:35px;vertical-align:middle;width:70px;transition:all 200ms;}.pdoc table{display:block;width:max-content;max-width:100%;overflow:auto;margin-bottom:1rem;}.pdoc table th{font-weight:600;}.pdoc table th, .pdoc table td{padding:6px 13px;border:1px solid var(--accent2);}</style>
    <style>/*! custom.css */</style></head>
<body>
    <nav class="pdoc">
        <label id="navtoggle" for="togglestate" class="pdoc-button"><svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 30 30'><path stroke-linecap='round' stroke="currentColor" stroke-miterlimit='10' stroke-width='2' d='M4 7h22M4 15h22M4 23h22'/></svg></label>
        <input id="togglestate" type="checkbox" aria-hidden="true" tabindex="-1">
        <div>            <a class="pdoc-button module-list-button" href="index.html">
<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-box-arrow-in-left" viewBox="0 0 16 16">
  <path fill-rule="evenodd" d="M10 3.5a.5.5 0 0 0-.5-.5h-8a.5.5 0 0 0-.5.5v9a.5.5 0 0 0 .5.5h8a.5.5 0 0 0 .5-.5v-2a.5.5 0 0 1 1 0v2A1.5 1.5 0 0 1 9.5 14h-8A1.5 1.5 0 0 1 0 12.5v-9A1.5 1.5 0 0 1 1.5 2h8A1.5 1.5 0 0 1 11 3.5v2a.5.5 0 0 1-1 0v-2z"/>
  <path fill-rule="evenodd" d="M4.146 8.354a.5.5 0 0 1 0-.708l3-3a.5.5 0 1 1 .708.708L5.707 7.5H14.5a.5.5 0 0 1 0 1H5.707l2.147 2.146a.5.5 0 0 1-.708.708l-3-3z"/>
</svg>                &nbsp;
                Module Index
            </a>

            <img src="https://i.im.ge/2022/08/19/OaUFYa.dibujo.png" class="logo" alt="project logo"/>

            <input type="search" placeholder="Search..." role="searchbox" aria-label="search"
                   pattern=".+" required>



        <h2>API Documentation</h2>
            <ul class="memberlist">
            <li>
                    <a class="class" href="#InformationGatheringEnv">InformationGatheringEnv</a>
                            <ul class="memberlist">
                        <li>
                                <a class="function" href="#InformationGatheringEnv.__init__">InformationGatheringEnv</a>
                        </li>
                        <li>
                                <a class="function" href="#InformationGatheringEnv.reset">reset</a>
                        </li>
                        <li>
                                <a class="function" href="#InformationGatheringEnv.eval">eval</a>
                        </li>
                        <li>
                                <a class="function" href="#InformationGatheringEnv.update_model">update_model</a>
                        </li>
                        <li>
                                <a class="function" href="#InformationGatheringEnv.reward_function">reward_function</a>
                        </li>
                        <li>
                                <a class="function" href="#InformationGatheringEnv.process_states">process_states</a>
                        </li>
                        <li>
                                <a class="function" href="#InformationGatheringEnv.individual_state">individual_state</a>
                        </li>
                        <li>
                                <a class="function" href="#InformationGatheringEnv.update_vehicles_ground_truths">update_vehicles_ground_truths</a>
                        </li>
                        <li>
                                <a class="function" href="#InformationGatheringEnv.action_dict_to_targets">action_dict_to_targets</a>
                        </li>
                        <li>
                                <a class="function" href="#InformationGatheringEnv.linear_min_max">linear_min_max</a>
                        </li>
                        <li>
                                <a class="function" href="#InformationGatheringEnv.step">step</a>
                        </li>
                        <li>
                                <a class="function" href="#InformationGatheringEnv.render">render</a>
                        </li>
                        <li>
                                <a class="function" href="#InformationGatheringEnv.get_action_mask">get_action_mask</a>
                        </li>
                </ul>

            </li>
    </ul>



        <a class="attribution" title="pdoc: Python API documentation generator" href="https://pdoc.dev" target="_blank">
            built with <span class="visually-hidden">pdoc</span><img
                alt="pdoc logo"
                src="data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20role%3D%22img%22%20aria-label%3D%22pdoc%20logo%22%20width%3D%22300%22%20height%3D%22150%22%20viewBox%3D%22-1%200%2060%2030%22%3E%3Ctitle%3Epdoc%3C/title%3E%3Cpath%20d%3D%22M29.621%2021.293c-.011-.273-.214-.475-.511-.481a.5.5%200%200%200-.489.503l-.044%201.393c-.097.551-.695%201.215-1.566%201.704-.577.428-1.306.486-2.193.182-1.426-.617-2.467-1.654-3.304-2.487l-.173-.172a3.43%203.43%200%200%200-.365-.306.49.49%200%200%200-.286-.196c-1.718-1.06-4.931-1.47-7.353.191l-.219.15c-1.707%201.187-3.413%202.131-4.328%201.03-.02-.027-.49-.685-.141-1.763.233-.721.546-2.408.772-4.076.042-.09.067-.187.046-.288.166-1.347.277-2.625.241-3.351%201.378-1.008%202.271-2.586%202.271-4.362%200-.976-.272-1.935-.788-2.774-.057-.094-.122-.18-.184-.268.033-.167.052-.339.052-.516%200-1.477-1.202-2.679-2.679-2.679-.791%200-1.496.352-1.987.9a6.3%206.3%200%200%200-1.001.029c-.492-.564-1.207-.929-2.012-.929-1.477%200-2.679%201.202-2.679%202.679A2.65%202.65%200%200%200%20.97%206.554c-.383.747-.595%201.572-.595%202.41%200%202.311%201.507%204.29%203.635%205.107-.037.699-.147%202.27-.423%203.294l-.137.461c-.622%202.042-2.515%208.257%201.727%2010.643%201.614.908%203.06%201.248%204.317%201.248%202.665%200%204.492-1.524%205.322-2.401%201.476-1.559%202.886-1.854%206.491.82%201.877%201.393%203.514%201.753%204.861%201.068%202.223-1.713%202.811-3.867%203.399-6.374.077-.846.056-1.469.054-1.537zm-4.835%204.313c-.054.305-.156.586-.242.629-.034-.007-.131-.022-.307-.157-.145-.111-.314-.478-.456-.908.221.121.432.25.675.355.115.039.219.051.33.081zm-2.251-1.238c-.05.33-.158.648-.252.694-.022.001-.125-.018-.307-.157-.217-.166-.488-.906-.639-1.573.358.344.754.693%201.198%201.036zm-3.887-2.337c-.006-.116-.018-.231-.041-.342.635.145%201.189.368%201.599.625.097.231.166.481.174.642-.03.049-.055.101-.067.158-.046.013-.128.026-.298.004-.278-.037-.901-.57-1.367-1.087zm-1.127-.497c.116.306.176.625.12.71-.019.014-.117.045-.345.016-.206-.027-.604-.332-.986-.695.41-.051.816-.056%201.211-.031zm-4.535%201.535c.209.22.379.47.358.598-.006.041-.088.138-.351.234-.144.055-.539-.063-.979-.259a11.66%2011.66%200%200%200%20.972-.573zm.983-.664c.359-.237.738-.418%201.126-.554.25.237.479.548.457.694-.006.042-.087.138-.351.235-.174.064-.694-.105-1.232-.375zm-3.381%201.794c-.022.145-.061.29-.149.401-.133.166-.358.248-.69.251h-.002c-.133%200-.306-.26-.45-.621.417.091.854.07%201.291-.031zm-2.066-8.077a4.78%204.78%200%200%201-.775-.584c.172-.115.505-.254.88-.378l-.105.962zm-.331%202.302a10.32%2010.32%200%200%201-.828-.502c.202-.143.576-.328.984-.49l-.156.992zm-.45%202.157l-.701-.403c.214-.115.536-.249.891-.376a11.57%2011.57%200%200%201-.19.779zm-.181%201.716c.064.398.194.702.298.893-.194-.051-.435-.162-.736-.398.061-.119.224-.3.438-.495zM8.87%204.141c0%20.152-.123.276-.276.276s-.275-.124-.275-.276.123-.276.276-.276.275.124.275.276zm-.735-.389a1.15%201.15%200%200%200-.314.783%201.16%201.16%200%200%200%201.162%201.162c.457%200%20.842-.27%201.032-.653.026.117.042.238.042.362a1.68%201.68%200%200%201-1.679%201.679%201.68%201.68%200%200%201-1.679-1.679c0-.843.626-1.535%201.436-1.654zM5.059%205.406A1.68%201.68%200%200%201%203.38%207.085a1.68%201.68%200%200%201-1.679-1.679c0-.037.009-.072.011-.109.21.3.541.508.935.508a1.16%201.16%200%200%200%201.162-1.162%201.14%201.14%200%200%200-.474-.912c.015%200%20.03-.005.045-.005.926.001%201.679.754%201.679%201.68zM3.198%204.141c0%20.152-.123.276-.276.276s-.275-.124-.275-.276.123-.276.276-.276.275.124.275.276zM1.375%208.964c0-.52.103-1.035.288-1.52.466.394%201.06.64%201.717.64%201.144%200%202.116-.725%202.499-1.738.383%201.012%201.355%201.738%202.499%201.738.867%200%201.631-.421%202.121-1.062.307.605.478%201.267.478%201.942%200%202.486-2.153%204.51-4.801%204.51s-4.801-2.023-4.801-4.51zm24.342%2019.349c-.985.498-2.267.168-3.813-.979-3.073-2.281-5.453-3.199-7.813-.705-1.315%201.391-4.163%203.365-8.423.97-3.174-1.786-2.239-6.266-1.261-9.479l.146-.492c.276-1.02.395-2.457.444-3.268a6.11%206.11%200%200%200%201.18.115%206.01%206.01%200%200%200%202.536-.562l-.006.175c-.802.215-1.848.612-2.021%201.25-.079.295.021.601.274.837.219.203.415.364.598.501-.667.304-1.243.698-1.311%201.179-.02.144-.022.507.393.787.213.144.395.26.564.365-1.285.521-1.361.96-1.381%201.126-.018.142-.011.496.427.746l.854.489c-.473.389-.971.914-.999%201.429-.018.278.095.532.316.713.675.556%201.231.721%201.653.721.059%200%20.104-.014.158-.02.207.707.641%201.64%201.513%201.64h.013c.8-.008%201.236-.345%201.462-.626.173-.216.268-.457.325-.692.424.195.93.374%201.372.374.151%200%20.294-.021.423-.068.732-.27.944-.704.993-1.021.009-.061.003-.119.002-.179.266.086.538.147.789.147.15%200%20.294-.021.423-.069.542-.2.797-.489.914-.754.237.147.478.258.704.288.106.014.205.021.296.021.356%200%20.595-.101.767-.229.438.435%201.094.992%201.656%201.067.106.014.205.021.296.021a1.56%201.56%200%200%200%20.323-.035c.17.575.453%201.289.866%201.605.358.273.665.362.914.362a.99.99%200%200%200%20.421-.093%201.03%201.03%200%200%200%20.245-.164c.168.428.39.846.68%201.068.358.273.665.362.913.362a.99.99%200%200%200%20.421-.093c.317-.148.512-.448.639-.762.251.157.495.257.726.257.127%200%20.25-.024.37-.071.427-.17.706-.617.841-1.314.022-.015.047-.022.068-.038.067-.051.133-.104.196-.159-.443%201.486-1.107%202.761-2.086%203.257zM8.66%209.925a.5.5%200%201%200-1%200c0%20.653-.818%201.205-1.787%201.205s-1.787-.552-1.787-1.205a.5.5%200%201%200-1%200c0%201.216%201.25%202.205%202.787%202.205s2.787-.989%202.787-2.205zm4.4%2015.965l-.208.097c-2.661%201.258-4.708%201.436-6.086.527-1.542-1.017-1.88-3.19-1.844-4.198a.4.4%200%200%200-.385-.414c-.242-.029-.406.164-.414.385-.046%201.249.367%203.686%202.202%204.896.708.467%201.547.7%202.51.7%201.248%200%202.706-.392%204.362-1.174l.185-.086a.4.4%200%200%200%20.205-.527c-.089-.204-.326-.291-.527-.206zM9.547%202.292c.093.077.205.114.317.114a.5.5%200%200%200%20.318-.886L8.817.397a.5.5%200%200%200-.703.068.5.5%200%200%200%20.069.703l1.364%201.124zm-7.661-.065c.086%200%20.173-.022.253-.068l1.523-.893a.5.5%200%200%200-.506-.863l-1.523.892a.5.5%200%200%200-.179.685c.094.158.261.247.432.247z%22%20transform%3D%22matrix%28-1%200%200%201%2058%200%29%22%20fill%3D%22%233bb300%22/%3E%3Cpath%20d%3D%22M.3%2021.86V10.18q0-.46.02-.68.04-.22.18-.5.28-.54%201.34-.54%201.06%200%201.42.28.38.26.44.78.76-1.04%202.38-1.04%201.64%200%203.1%201.54%201.46%201.54%201.46%203.58%200%202.04-1.46%203.58-1.44%201.54-3.08%201.54-1.64%200-2.38-.92v4.04q0%20.46-.04.68-.02.22-.18.5-.14.3-.5.42-.36.12-.98.12-.62%200-1-.12-.36-.12-.52-.4-.14-.28-.18-.5-.02-.22-.02-.68zm3.96-9.42q-.46.54-.46%201.18%200%20.64.46%201.18.48.52%201.2.52.74%200%201.24-.52.52-.52.52-1.18%200-.66-.48-1.18-.48-.54-1.26-.54-.76%200-1.22.54zm14.741-8.36q.16-.3.54-.42.38-.12%201-.12.64%200%201.02.12.38.12.52.42.16.3.18.54.04.22.04.68v11.94q0%20.46-.04.7-.02.22-.18.5-.3.54-1.7.54-1.38%200-1.54-.98-.84.96-2.34.96-1.8%200-3.28-1.56-1.48-1.58-1.48-3.66%200-2.1%201.48-3.68%201.5-1.58%203.28-1.58%201.48%200%202.3%201v-4.2q0-.46.02-.68.04-.24.18-.52zm-3.24%2010.86q.52.54%201.26.54.74%200%201.22-.54.5-.54.5-1.18%200-.66-.48-1.22-.46-.56-1.26-.56-.8%200-1.28.56-.48.54-.48%201.2%200%20.66.52%201.2zm7.833-1.2q0-2.4%201.68-3.96%201.68-1.56%203.84-1.56%202.16%200%203.82%201.56%201.66%201.54%201.66%203.94%200%201.66-.86%202.96-.86%201.28-2.1%201.9-1.22.6-2.54.6-1.32%200-2.56-.64-1.24-.66-2.1-1.92-.84-1.28-.84-2.88zm4.18%201.44q.64.48%201.3.48.66%200%201.32-.5.66-.5.66-1.48%200-.98-.62-1.46-.62-.48-1.34-.48-.72%200-1.34.5-.62.5-.62%201.48%200%20.96.64%201.46zm11.412-1.44q0%20.84.56%201.32.56.46%201.18.46.64%200%201.18-.36.56-.38.9-.38.6%200%201.46%201.06.46.58.46%201.04%200%20.76-1.1%201.42-1.14.8-2.8.8-1.86%200-3.58-1.34-.82-.64-1.34-1.7-.52-1.08-.52-2.36%200-1.3.52-2.34.52-1.06%201.34-1.7%201.66-1.32%203.54-1.32.76%200%201.48.22.72.2%201.06.4l.32.2q.36.24.56.38.52.4.52.92%200%20.5-.42%201.14-.72%201.1-1.38%201.1-.38%200-1.08-.44-.36-.34-1.04-.34-.66%200-1.24.48-.58.48-.58%201.34z%22%20fill%3D%22green%22/%3E%3C/svg%3E"/>
        </a>
</div>
    </nav>
    <main class="pdoc">
            <section class="module-info">
                    <h1 class="modulename">
IGEnvironments    </h1>

                
                        <input id="IGEnvironments-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">

                        <label class="view-source-button" for="IGEnvironments-view-source"><span>View Source</span></label>

                        <div class="pdoc-code codehilite"><pre><span></span><span id="L-1"><a href="#L-1"><span class="linenos">  1</span></a><span class="kn">import</span> <span class="nn">gym</span>
</span><span id="L-2"><a href="#L-2"><span class="linenos">  2</span></a><span class="kn">from</span> <span class="nn">ray.rllib.env.multi_agent_env</span> <span class="kn">import</span> <span class="n">MultiAgentEnv</span>
</span><span id="L-3"><a href="#L-3"><span class="linenos">  3</span></a><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span><span id="L-4"><a href="#L-4"><span class="linenos">  4</span></a><span class="kn">from</span> <span class="nn">sklearn.gaussian_process.kernels</span> <span class="kn">import</span> <span class="n">RBF</span>
</span><span id="L-5"><a href="#L-5"><span class="linenos">  5</span></a><span class="kn">from</span> <span class="nn">sklearn.gaussian_process</span> <span class="kn">import</span> <span class="n">GaussianProcessRegressor</span>
</span><span id="L-6"><a href="#L-6"><span class="linenos">  6</span></a><span class="kn">from</span> <span class="nn">OilSpillEnvironment</span> <span class="kn">import</span> <span class="n">OilSpillEnv</span>
</span><span id="L-7"><a href="#L-7"><span class="linenos">  7</span></a><span class="kn">from</span> <span class="nn">ShekelGroundTruth</span> <span class="kn">import</span> <span class="n">Shekel</span>
</span><span id="L-8"><a href="#L-8"><span class="linenos">  8</span></a><span class="kn">from</span> <span class="nn">Fleet</span> <span class="kn">import</span> <span class="n">Fleet</span>
</span><span id="L-9"><a href="#L-9"><span class="linenos">  9</span></a><span class="kn">from</span> <span class="nn">Vehicle</span> <span class="kn">import</span> <span class="n">FleetState</span>
</span><span id="L-10"><a href="#L-10"><span class="linenos"> 10</span></a><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Union</span>
</span><span id="L-11"><a href="#L-11"><span class="linenos"> 11</span></a><span class="kn">from</span> <span class="nn">random</span> <span class="kn">import</span> <span class="n">shuffle</span>
</span><span id="L-12"><a href="#L-12"><span class="linenos"> 12</span></a>
</span><span id="L-13"><a href="#L-13"><span class="linenos"> 13</span></a><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</span><span id="L-14"><a href="#L-14"><span class="linenos"> 14</span></a>
</span><span id="L-15"><a href="#L-15"><span class="linenos"> 15</span></a>
</span><span id="L-16"><a href="#L-16"><span class="linenos"> 16</span></a><span class="k">class</span> <span class="nc">InformationGatheringEnv</span><span class="p">(</span><span class="n">MultiAgentEnv</span><span class="p">):</span>
</span><span id="L-17"><a href="#L-17"><span class="linenos"> 17</span></a>
</span><span id="L-18"><a href="#L-18"><span class="linenos"> 18</span></a>	<span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env_config</span><span class="p">:</span> <span class="nb">dict</span><span class="p">):</span>
</span><span id="L-19"><a href="#L-19"><span class="linenos"> 19</span></a>
</span><span id="L-20"><a href="#L-20"><span class="linenos"> 20</span></a>		<span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="L-21"><a href="#L-21"><span class="linenos"> 21</span></a>
</span><span id="L-22"><a href="#L-22"><span class="linenos"> 22</span></a>		<span class="c1"># Environment configuration dictionary</span>
</span><span id="L-23"><a href="#L-23"><span class="linenos"> 23</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">env_config</span> <span class="o">=</span> <span class="n">env_config</span>
</span><span id="L-24"><a href="#L-24"><span class="linenos"> 24</span></a>
</span><span id="L-25"><a href="#L-25"><span class="linenos"> 25</span></a>		<span class="c1"># Create a fleet of N vehicles #</span>
</span><span id="L-26"><a href="#L-26"><span class="linenos"> 26</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">fleet</span> <span class="o">=</span> <span class="n">Fleet</span><span class="p">(</span><span class="n">fleet_configuration</span><span class="o">=</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;fleet_configuration&#39;</span><span class="p">])</span>
</span><span id="L-27"><a href="#L-27"><span class="linenos"> 27</span></a>		<span class="c1"># Save the number of agents #</span>
</span><span id="L-28"><a href="#L-28"><span class="linenos"> 28</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">number_of_agents</span> <span class="o">=</span> <span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;fleet_configuration&#39;</span><span class="p">][</span><span class="s1">&#39;number_of_vehicles&#39;</span><span class="p">]</span>
</span><span id="L-29"><a href="#L-29"><span class="linenos"> 29</span></a>		<span class="c1"># Save the agents ids #</span>
</span><span id="L-30"><a href="#L-30"><span class="linenos"> 30</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">agents_ids</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">number_of_agents</span><span class="p">))</span>
</span><span id="L-31"><a href="#L-31"><span class="linenos"> 31</span></a>		<span class="c1"># Create a set of agents IDs - This is required for the RLLIB MA Environment class #</span>
</span><span id="L-32"><a href="#L-32"><span class="linenos"> 32</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">_agent_ids</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">number_of_agents</span><span class="p">))</span>
</span><span id="L-33"><a href="#L-33"><span class="linenos"> 33</span></a>
</span><span id="L-34"><a href="#L-34"><span class="linenos"> 34</span></a>		<span class="c1"># Define the observation space and the action space #</span>
</span><span id="L-35"><a href="#L-35"><span class="linenos"> 35</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">observation_type</span> <span class="o">=</span> <span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;observation_type&#39;</span><span class="p">]</span>
</span><span id="L-36"><a href="#L-36"><span class="linenos"> 36</span></a>
</span><span id="L-37"><a href="#L-37"><span class="linenos"> 37</span></a>		<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">observation_type</span> <span class="o">==</span> <span class="s1">&#39;visual&#39;</span><span class="p">:</span>
</span><span id="L-38"><a href="#L-38"><span class="linenos"> 38</span></a>			<span class="c1"># The visual observation space is defined as 5 images:</span>
</span><span id="L-39"><a href="#L-39"><span class="linenos"> 39</span></a>			<span class="c1"># - The navigation map</span>
</span><span id="L-40"><a href="#L-40"><span class="linenos"> 40</span></a>			<span class="c1"># - The observer position on the map</span>
</span><span id="L-41"><a href="#L-41"><span class="linenos"> 41</span></a>			<span class="c1"># - The other vehicles positions on the map</span>
</span><span id="L-42"><a href="#L-42"><span class="linenos"> 42</span></a>			<span class="c1"># - The mu of the model</span>
</span><span id="L-43"><a href="#L-43"><span class="linenos"> 43</span></a>			<span class="c1"># - The uncertainty of the model</span>
</span><span id="L-44"><a href="#L-44"><span class="linenos"> 44</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">observation_space</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Box</span><span class="p">(</span><span class="n">low</span><span class="o">=-</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="o">*</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;navigation_map&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
</span><span id="L-45"><a href="#L-45"><span class="linenos"> 45</span></a>		<span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">observation_type</span> <span class="o">==</span> <span class="s1">&#39;hybrid&#39;</span><span class="p">:</span>
</span><span id="L-46"><a href="#L-46"><span class="linenos"> 46</span></a>			<span class="c1"># The hybrid state is its position [x,y] and 3 images [fleet positions, mean-model, uncertainty] #</span>
</span><span id="L-47"><a href="#L-47"><span class="linenos"> 47</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">observation_space</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Dict</span><span class="p">({</span><span class="s1">&#39;visual_state&#39;</span><span class="p">:</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Box</span><span class="p">(</span><span class="n">low</span><span class="o">=-</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="o">*</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;navigation_map&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)),</span>
</span><span id="L-48"><a href="#L-48"><span class="linenos"> 48</span></a>			                                          <span class="s1">&#39;odometry&#39;</span><span class="p">:</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Box</span><span class="p">(</span><span class="n">low</span><span class="o">=-</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,))})</span>
</span><span id="L-49"><a href="#L-49"><span class="linenos"> 49</span></a>		<span class="k">else</span><span class="p">:</span>
</span><span id="L-50"><a href="#L-50"><span class="linenos"> 50</span></a>			<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s1">&#39;This observation type is not defined. Pleas choose between: visual / hybrid&#39;</span><span class="p">)</span>
</span><span id="L-51"><a href="#L-51"><span class="linenos"> 51</span></a>
</span><span id="L-52"><a href="#L-52"><span class="linenos"> 52</span></a>		<span class="c1"># Define the type of the action #</span>
</span><span id="L-53"><a href="#L-53"><span class="linenos"> 53</span></a>		<span class="k">if</span> <span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;movement_type&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;DIRECTIONAL&#39;</span><span class="p">:</span>
</span><span id="L-54"><a href="#L-54"><span class="linenos"> 54</span></a>			<span class="c1"># The action space is a discrete action space with number_of_actions actions:</span>
</span><span id="L-55"><a href="#L-55"><span class="linenos"> 55</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">action_space</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Discrete</span><span class="p">(</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;number_of_actions&#39;</span><span class="p">])</span>
</span><span id="L-56"><a href="#L-56"><span class="linenos"> 56</span></a>		<span class="k">elif</span> <span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;movement_type&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;DIRECTIONAL_DISTANCE&#39;</span><span class="p">:</span>
</span><span id="L-57"><a href="#L-57"><span class="linenos"> 57</span></a>			<span class="c1"># This action is defined with the direction and the distance to move (both normalized between -1 and 1) #</span>
</span><span id="L-58"><a href="#L-58"><span class="linenos"> 58</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">action_space</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Box</span><span class="p">(</span><span class="n">low</span><span class="o">=-</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,))</span>
</span><span id="L-59"><a href="#L-59"><span class="linenos"> 59</span></a>		<span class="k">else</span><span class="p">:</span>
</span><span id="L-60"><a href="#L-60"><span class="linenos"> 60</span></a>			<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s1">&#39;This movement type is not defined. Pleas choose between: DIRECTIONAL / DIRECTIONAL+DISTANCE&#39;</span><span class="p">)</span>
</span><span id="L-61"><a href="#L-61"><span class="linenos"> 61</span></a>
</span><span id="L-62"><a href="#L-62"><span class="linenos"> 62</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">measurements</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># Measurements of the environment (Usually a dictionary)</span>
</span><span id="L-63"><a href="#L-63"><span class="linenos"> 63</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">resetted</span> <span class="o">=</span> <span class="kc">False</span>  <span class="c1"># Flag to check if the environment has been resetted #</span>
</span><span id="L-64"><a href="#L-64"><span class="linenos"> 64</span></a>
</span><span id="L-65"><a href="#L-65"><span class="linenos"> 65</span></a>		<span class="c1"># Gym Environment variables #</span>
</span><span id="L-66"><a href="#L-66"><span class="linenos"> 66</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">rewards</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="L-67"><a href="#L-67"><span class="linenos"> 67</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">states</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="L-68"><a href="#L-68"><span class="linenos"> 68</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">infos</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="L-69"><a href="#L-69"><span class="linenos"> 69</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">dones</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="L-70"><a href="#L-70"><span class="linenos"> 70</span></a>
</span><span id="L-71"><a href="#L-71"><span class="linenos"> 71</span></a>		<span class="c1"># Ground truth - The task to solve #</span>
</span><span id="L-72"><a href="#L-72"><span class="linenos"> 72</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">random_benchmark</span> <span class="o">=</span> <span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;random_benchmark&#39;</span><span class="p">]</span>
</span><span id="L-73"><a href="#L-73"><span class="linenos"> 73</span></a>		<span class="k">if</span> <span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;dynamic&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;OilSpillEnv&#39;</span><span class="p">:</span>
</span><span id="L-74"><a href="#L-74"><span class="linenos"> 74</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">ground_truth</span> <span class="o">=</span> <span class="n">OilSpillEnv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;navigation_map&#39;</span><span class="p">],</span> <span class="n">dt</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">flow</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">kc</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">kw</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;seed&#39;</span><span class="p">])</span>
</span><span id="L-75"><a href="#L-75"><span class="linenos"> 75</span></a>		<span class="k">elif</span> <span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;dynamic&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;Shekel&#39;</span><span class="p">:</span>
</span><span id="L-76"><a href="#L-76"><span class="linenos"> 76</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">ground_truth</span> <span class="o">=</span> <span class="n">Shekel</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;navigation_map&#39;</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="n">max_number_of_peaks</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">is_bounded</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;seed&#39;</span><span class="p">])</span>
</span><span id="L-77"><a href="#L-77"><span class="linenos"> 77</span></a>		<span class="k">else</span><span class="p">:</span>
</span><span id="L-78"><a href="#L-78"><span class="linenos"> 78</span></a>			<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;This benchmark is not implemented&quot;</span><span class="p">)</span>
</span><span id="L-79"><a href="#L-79"><span class="linenos"> 79</span></a>
</span><span id="L-80"><a href="#L-80"><span class="linenos"> 80</span></a>		<span class="c1"># [N x 2] matrix with all the possible visitable positions #</span>
</span><span id="L-81"><a href="#L-81"><span class="linenos"> 81</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">visitable_positions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;navigation_map&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">))</span>
</span><span id="L-82"><a href="#L-82"><span class="linenos"> 82</span></a>
</span><span id="L-83"><a href="#L-83"><span class="linenos"> 83</span></a>		<span class="c1"># ---- Parameters of the model (Gaussian Process) ---- #</span>
</span><span id="L-84"><a href="#L-84"><span class="linenos"> 84</span></a>		<span class="c1"># Kernel for model-conditioning #</span>
</span><span id="L-85"><a href="#L-85"><span class="linenos"> 85</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">kernel</span> <span class="o">=</span> <span class="n">RBF</span><span class="p">(</span><span class="n">length_scale</span><span class="o">=</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;kernel_length_scale&#39;</span><span class="p">],</span> <span class="n">length_scale_bounds</span><span class="o">=</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">))</span>
</span><span id="L-86"><a href="#L-86"><span class="linenos"> 86</span></a>		<span class="c1"># The Gaussian Process #</span>
</span><span id="L-87"><a href="#L-87"><span class="linenos"> 87</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">GaussianProcess</span> <span class="o">=</span> <span class="n">GaussianProcessRegressor</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">n_restarts_optimizer</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</span><span id="L-88"><a href="#L-88"><span class="linenos"> 88</span></a>		<span class="c1"># The list of measured values (y in GP)</span>
</span><span id="L-89"><a href="#L-89"><span class="linenos"> 89</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">measured_values</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-90"><a href="#L-90"><span class="linenos"> 90</span></a>		<span class="c1"># The list of measured positions (x in GP)</span>
</span><span id="L-91"><a href="#L-91"><span class="linenos"> 91</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">measured_locations</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-92"><a href="#L-92"><span class="linenos"> 92</span></a>
</span><span id="L-93"><a href="#L-93"><span class="linenos"> 93</span></a>		<span class="c1"># The surrogate model #</span>
</span><span id="L-94"><a href="#L-94"><span class="linenos"> 94</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">mu</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-95"><a href="#L-95"><span class="linenos"> 95</span></a>		<span class="c1"># The surrogate uncertainty #</span>
</span><span id="L-96"><a href="#L-96"><span class="linenos"> 96</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">uncertainty</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-97"><a href="#L-97"><span class="linenos"> 97</span></a>
</span><span id="L-98"><a href="#L-98"><span class="linenos"> 98</span></a>		<span class="c1"># Array of the last measurements of every agent (to compute the reward) #</span>
</span><span id="L-99"><a href="#L-99"><span class="linenos"> 99</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">last_measurement_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.0</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">number_of_agents</span><span class="p">)])</span>
</span><span id="L-100"><a href="#L-100"><span class="linenos">100</span></a>		<span class="c1"># The contribution of every agent to the uncertainty decrement (to compute the reward)#</span>
</span><span id="L-101"><a href="#L-101"><span class="linenos">101</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">intermediate_uncertainty_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">visitable_positions</span><span class="p">),))</span>
</span><span id="L-102"><a href="#L-102"><span class="linenos">102</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">individual_uncertainty_decrement</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.0</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">number_of_agents</span><span class="p">)])</span>
</span><span id="L-103"><a href="#L-103"><span class="linenos">103</span></a>		<span class="c1"># The error of the model #</span>
</span><span id="L-104"><a href="#L-104"><span class="linenos">104</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">mse</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-105"><a href="#L-105"><span class="linenos">105</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">mse_ant</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-106"><a href="#L-106"><span class="linenos">106</span></a>
</span><span id="L-107"><a href="#L-107"><span class="linenos">107</span></a>		<span class="c1"># For the collision computation #</span>
</span><span id="L-108"><a href="#L-108"><span class="linenos">108</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">number_of_collisions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">number_of_agents</span><span class="p">,))</span>
</span><span id="L-109"><a href="#L-109"><span class="linenos">109</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">max_collisions</span> <span class="o">=</span> <span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;max_collisions&#39;</span><span class="p">]</span>
</span><span id="L-110"><a href="#L-110"><span class="linenos">110</span></a>
</span><span id="L-111"><a href="#L-111"><span class="linenos">111</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">_eval</span> <span class="o">=</span> <span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;eval_mode&#39;</span><span class="p">]</span>
</span><span id="L-112"><a href="#L-112"><span class="linenos">112</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">fig</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-113"><a href="#L-113"><span class="linenos">113</span></a>
</span><span id="L-114"><a href="#L-114"><span class="linenos">114</span></a>	<span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
</span><span id="L-115"><a href="#L-115"><span class="linenos">115</span></a>		<span class="sd">&quot;&quot;&quot; Reset all the variables and the fleet. This method must be called before the first step of the episode.</span>
</span><span id="L-116"><a href="#L-116"><span class="linenos">116</span></a><span class="sd">		It resets the fleet position, the measurements, the ground truth, the surrogate model and the uncertainty.</span>
</span><span id="L-117"><a href="#L-117"><span class="linenos">117</span></a>
</span><span id="L-118"><a href="#L-118"><span class="linenos">118</span></a><span class="sd">		:return:</span>
</span><span id="L-119"><a href="#L-119"><span class="linenos">119</span></a><span class="sd">			The initial observation of the environment in a dictionary of agents.</span>
</span><span id="L-120"><a href="#L-120"><span class="linenos">120</span></a>
</span><span id="L-121"><a href="#L-121"><span class="linenos">121</span></a><span class="sd">		&quot;&quot;&quot;</span>
</span><span id="L-122"><a href="#L-122"><span class="linenos">122</span></a>
</span><span id="L-123"><a href="#L-123"><span class="linenos">123</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">resetted</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="L-124"><a href="#L-124"><span class="linenos">124</span></a>
</span><span id="L-125"><a href="#L-125"><span class="linenos">125</span></a>		<span class="c1"># Reset the dones #</span>
</span><span id="L-126"><a href="#L-126"><span class="linenos">126</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">dones</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span> <span class="kc">False</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">number_of_agents</span><span class="p">)}</span>
</span><span id="L-127"><a href="#L-127"><span class="linenos">127</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">dones</span><span class="p">[</span><span class="s1">&#39;__all__&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="L-128"><a href="#L-128"><span class="linenos">128</span></a>
</span><span id="L-129"><a href="#L-129"><span class="linenos">129</span></a>		<span class="c1"># Reset the ground truth and update the ground truth (if the ground truth is dynamic) #</span>
</span><span id="L-130"><a href="#L-130"><span class="linenos">130</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">ground_truth</span><span class="o">.</span><span class="n">reset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_benchmark</span><span class="p">)</span>
</span><span id="L-131"><a href="#L-131"><span class="linenos">131</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">update_vehicles_ground_truths</span><span class="p">()</span>
</span><span id="L-132"><a href="#L-132"><span class="linenos">132</span></a>
</span><span id="L-133"><a href="#L-133"><span class="linenos">133</span></a>		<span class="c1"># Reset the model parameters#</span>
</span><span id="L-134"><a href="#L-134"><span class="linenos">134</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">measured_locations</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-135"><a href="#L-135"><span class="linenos">135</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">measured_values</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-136"><a href="#L-136"><span class="linenos">136</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">mu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;navigation_map&#39;</span><span class="p">])</span>
</span><span id="L-137"><a href="#L-137"><span class="linenos">137</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">uncertainty</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;navigation_map&#39;</span><span class="p">])</span>
</span><span id="L-138"><a href="#L-138"><span class="linenos">138</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">number_of_collisions</span><span class="p">[:]</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="L-139"><a href="#L-139"><span class="linenos">139</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">mse_ant</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-140"><a href="#L-140"><span class="linenos">140</span></a>
</span><span id="L-141"><a href="#L-141"><span class="linenos">141</span></a>		<span class="c1"># Reset the fleet and take the first measurements #</span>
</span><span id="L-142"><a href="#L-142"><span class="linenos">142</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">measurements</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fleet</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
</span><span id="L-143"><a href="#L-143"><span class="linenos">143</span></a>
</span><span id="L-144"><a href="#L-144"><span class="linenos">144</span></a>		<span class="c1"># Update the model with the initial values #</span>
</span><span id="L-145"><a href="#L-145"><span class="linenos">145</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">last_measurement_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.0</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">number_of_agents</span><span class="p">)])</span>
</span><span id="L-146"><a href="#L-146"><span class="linenos">146</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">intermediate_uncertainty_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">visitable_positions</span><span class="p">),))</span>
</span><span id="L-147"><a href="#L-147"><span class="linenos">147</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">individual_uncertainty_decrement</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.0</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">number_of_agents</span><span class="p">)])</span>
</span><span id="L-148"><a href="#L-148"><span class="linenos">148</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">uncertainty</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">update_model</span><span class="p">(</span><span class="n">new_measurements</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">measurements</span><span class="p">)</span>
</span><span id="L-149"><a href="#L-149"><span class="linenos">149</span></a>
</span><span id="L-150"><a href="#L-150"><span class="linenos">150</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">uncertainty_0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">uncertainty</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</span><span id="L-151"><a href="#L-151"><span class="linenos">151</span></a>
</span><span id="L-152"><a href="#L-152"><span class="linenos">152</span></a>		<span class="c1"># Update the state</span>
</span><span id="L-153"><a href="#L-153"><span class="linenos">153</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">process_states</span><span class="p">()</span>
</span><span id="L-154"><a href="#L-154"><span class="linenos">154</span></a>
</span><span id="L-155"><a href="#L-155"><span class="linenos">155</span></a>		<span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">states</span>
</span><span id="L-156"><a href="#L-156"><span class="linenos">156</span></a>
</span><span id="L-157"><a href="#L-157"><span class="linenos">157</span></a>	<span class="k">def</span> <span class="nf">eval</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-158"><a href="#L-158"><span class="linenos">158</span></a>		<span class="sd">&quot;&quot;&quot; Change the environment to evaluation mode. In this mode,</span>
</span><span id="L-159"><a href="#L-159"><span class="linenos">159</span></a><span class="sd">		computationally expensive operations are enabled for evaluation. &quot;&quot;&quot;</span>
</span><span id="L-160"><a href="#L-160"><span class="linenos">160</span></a>
</span><span id="L-161"><a href="#L-161"><span class="linenos">161</span></a>		<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Environment in eval mode!&quot;</span><span class="p">)</span>
</span><span id="L-162"><a href="#L-162"><span class="linenos">162</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">_eval</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="L-163"><a href="#L-163"><span class="linenos">163</span></a>
</span><span id="L-164"><a href="#L-164"><span class="linenos">164</span></a>	<span class="k">def</span> <span class="nf">update_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_measurements</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span> <span class="n">agents_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
</span><span id="L-165"><a href="#L-165"><span class="linenos">165</span></a>		<span class="sd">&quot;&quot;&quot;</span>
</span><span id="L-166"><a href="#L-166"><span class="linenos">166</span></a><span class="sd">		Fit the gaussian process using the new_measurements and return a new inferred map and its uncertainty.</span>
</span><span id="L-167"><a href="#L-167"><span class="linenos">167</span></a><span class="sd">		The process will update the gaussian model sequentially for each agent in *agents_ids*.</span>
</span><span id="L-168"><a href="#L-168"><span class="linenos">168</span></a>
</span><span id="L-169"><a href="#L-169"><span class="linenos">169</span></a>
</span><span id="L-170"><a href="#L-170"><span class="linenos">170</span></a><span class="sd">		:param new_measurements: The new measurements to fit the model with in a dictionary.</span>
</span><span id="L-171"><a href="#L-171"><span class="linenos">171</span></a><span class="sd">		:param agents_ids: The ids of those agents that generated the measurements. If None, all the agents will be updated.</span>
</span><span id="L-172"><a href="#L-172"><span class="linenos">172</span></a>
</span><span id="L-173"><a href="#L-173"><span class="linenos">173</span></a><span class="sd">		:return:</span>
</span><span id="L-174"><a href="#L-174"><span class="linenos">174</span></a><span class="sd">			- mu - The new inferred map mu.</span>
</span><span id="L-175"><a href="#L-175"><span class="linenos">175</span></a><span class="sd">			- sigma - The new inferred uncertainty sigma.</span>
</span><span id="L-176"><a href="#L-176"><span class="linenos">176</span></a>
</span><span id="L-177"><a href="#L-177"><span class="linenos">177</span></a><span class="sd">		&quot;&quot;&quot;</span>
</span><span id="L-178"><a href="#L-178"><span class="linenos">178</span></a>
</span><span id="L-179"><a href="#L-179"><span class="linenos">179</span></a>		<span class="k">if</span> <span class="n">agents_ids</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-180"><a href="#L-180"><span class="linenos">180</span></a>			<span class="n">agents_ids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">agents_ids</span>
</span><span id="L-181"><a href="#L-181"><span class="linenos">181</span></a>		<span class="k">else</span><span class="p">:</span>
</span><span id="L-182"><a href="#L-182"><span class="linenos">182</span></a>			<span class="n">new_measurements</span> <span class="o">=</span> <span class="p">[</span><span class="n">new_measurements</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">agents_ids</span><span class="p">]</span>
</span><span id="L-183"><a href="#L-183"><span class="linenos">183</span></a>
</span><span id="L-184"><a href="#L-184"><span class="linenos">184</span></a>		<span class="n">shufled_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">agents_ids</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">agents_ids</span><span class="p">))))</span>
</span><span id="L-185"><a href="#L-185"><span class="linenos">185</span></a>		<span class="n">shuffle</span><span class="p">(</span><span class="n">shufled_list</span><span class="p">)</span>
</span><span id="L-186"><a href="#L-186"><span class="linenos">186</span></a>		<span class="k">for</span> <span class="n">agent_id</span><span class="p">,</span> <span class="n">measurement_id</span> <span class="ow">in</span> <span class="n">shufled_list</span><span class="p">:</span>
</span><span id="L-187"><a href="#L-187"><span class="linenos">187</span></a>			<span class="c1"># Sequentially update the model for each agent. #</span>
</span><span id="L-188"><a href="#L-188"><span class="linenos">188</span></a>
</span><span id="L-189"><a href="#L-189"><span class="linenos">189</span></a>			<span class="c1"># Append the data to the list of measurement locations and values #</span>
</span><span id="L-190"><a href="#L-190"><span class="linenos">190</span></a>			<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">measured_locations</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-191"><a href="#L-191"><span class="linenos">191</span></a>				<span class="bp">self</span><span class="o">.</span><span class="n">measured_locations</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="n">new_measurements</span><span class="p">[</span><span class="n">measurement_id</span><span class="p">][</span><span class="s1">&#39;position&#39;</span><span class="p">]])</span>
</span><span id="L-192"><a href="#L-192"><span class="linenos">192</span></a>				<span class="c1"># We compute the mean of the measurement-image #</span>
</span><span id="L-193"><a href="#L-193"><span class="linenos">193</span></a>				<span class="bp">self</span><span class="o">.</span><span class="n">measured_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">nanmean</span><span class="p">(</span><span class="n">new_measurements</span><span class="p">[</span><span class="n">measurement_id</span><span class="p">][</span><span class="s1">&#39;data&#39;</span><span class="p">])])</span>
</span><span id="L-194"><a href="#L-194"><span class="linenos">194</span></a>			<span class="k">else</span><span class="p">:</span>
</span><span id="L-195"><a href="#L-195"><span class="linenos">195</span></a>				<span class="bp">self</span><span class="o">.</span><span class="n">measured_locations</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">measured_locations</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="n">new_measurements</span><span class="p">[</span><span class="n">measurement_id</span><span class="p">][</span><span class="s1">&#39;position&#39;</span><span class="p">]])))</span>
</span><span id="L-196"><a href="#L-196"><span class="linenos">196</span></a>				<span class="bp">self</span><span class="o">.</span><span class="n">measured_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">measured_values</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">nanmean</span><span class="p">(</span><span class="n">new_measurements</span><span class="p">[</span><span class="n">measurement_id</span><span class="p">][</span><span class="s1">&#39;data&#39;</span><span class="p">])])))</span>
</span><span id="L-197"><a href="#L-197"><span class="linenos">197</span></a>
</span><span id="L-198"><a href="#L-198"><span class="linenos">198</span></a>			<span class="c1"># Store this last measured value #</span>
</span><span id="L-199"><a href="#L-199"><span class="linenos">199</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">last_measurement_values</span><span class="p">[</span><span class="n">agent_id</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">measured_values</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span><span id="L-200"><a href="#L-200"><span class="linenos">200</span></a>
</span><span id="L-201"><a href="#L-201"><span class="linenos">201</span></a>			<span class="c1"># Fit the gaussian process #</span>
</span><span id="L-202"><a href="#L-202"><span class="linenos">202</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">GaussianProcess</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">measured_locations</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">measured_values</span><span class="p">)</span>
</span><span id="L-203"><a href="#L-203"><span class="linenos">203</span></a>
</span><span id="L-204"><a href="#L-204"><span class="linenos">204</span></a>			<span class="c1"># Compute the mean and the std values for all the visitable positions #</span>
</span><span id="L-205"><a href="#L-205"><span class="linenos">205</span></a>			<span class="n">mu_array</span><span class="p">,</span> <span class="n">sigma_array</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">GaussianProcess</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">visitable_positions</span><span class="p">[:],</span> <span class="n">return_std</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="L-206"><a href="#L-206"><span class="linenos">206</span></a>
</span><span id="L-207"><a href="#L-207"><span class="linenos">207</span></a>			<span class="c1"># Compute the new mean error #</span>
</span><span id="L-208"><a href="#L-208"><span class="linenos">208</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">mse</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ground_truth</span><span class="o">.</span><span class="n">ground_truth_field</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">visitable_positions</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">visitable_positions</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">-</span> <span class="n">mu_array</span><span class="p">))</span>
</span><span id="L-209"><a href="#L-209"><span class="linenos">209</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">mse_ant</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mse</span>
</span><span id="L-210"><a href="#L-210"><span class="linenos">210</span></a>
</span><span id="L-211"><a href="#L-211"><span class="linenos">211</span></a>			<span class="c1"># Save the intermediate uncertainty maps for uncertainty credit assignment #</span>
</span><span id="L-212"><a href="#L-212"><span class="linenos">212</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">individual_uncertainty_decrement</span><span class="p">[</span><span class="n">agent_id</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">intermediate_uncertainty_values</span> <span class="o">-</span> <span class="n">sigma_array</span><span class="p">)</span>
</span><span id="L-213"><a href="#L-213"><span class="linenos">213</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">intermediate_uncertainty_values</span> <span class="o">=</span> <span class="n">sigma_array</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
</span><span id="L-214"><a href="#L-214"><span class="linenos">214</span></a>
</span><span id="L-215"><a href="#L-215"><span class="linenos">215</span></a>		<span class="c1"># Conform the map of the surrogate model for the state #</span>
</span><span id="L-216"><a href="#L-216"><span class="linenos">216</span></a>		<span class="n">mu_map</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;navigation_map&#39;</span><span class="p">])</span>
</span><span id="L-217"><a href="#L-217"><span class="linenos">217</span></a>		<span class="n">mu_map</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">visitable_positions</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span>
</span><span id="L-218"><a href="#L-218"><span class="linenos">218</span></a>		       <span class="bp">self</span><span class="o">.</span><span class="n">visitable_positions</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="n">mu_array</span>
</span><span id="L-219"><a href="#L-219"><span class="linenos">219</span></a>
</span><span id="L-220"><a href="#L-220"><span class="linenos">220</span></a>		<span class="n">uncertainty_map</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;navigation_map&#39;</span><span class="p">])</span>
</span><span id="L-221"><a href="#L-221"><span class="linenos">221</span></a>		<span class="n">uncertainty_map</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">visitable_positions</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span>
</span><span id="L-222"><a href="#L-222"><span class="linenos">222</span></a>		                <span class="bp">self</span><span class="o">.</span><span class="n">visitable_positions</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="n">sigma_array</span>
</span><span id="L-223"><a href="#L-223"><span class="linenos">223</span></a>
</span><span id="L-224"><a href="#L-224"><span class="linenos">224</span></a>		<span class="k">return</span> <span class="n">mu_map</span><span class="p">,</span> <span class="n">uncertainty_map</span>
</span><span id="L-225"><a href="#L-225"><span class="linenos">225</span></a>
</span><span id="L-226"><a href="#L-226"><span class="linenos">226</span></a>	<span class="k">def</span> <span class="nf">reward_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">collision_array</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span> <span class="n">agents_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
</span><span id="L-227"><a href="#L-227"><span class="linenos">227</span></a>		<span class="sd">&quot;&quot;&quot; The reward function is defined depending on the reward_type parameter</span>
</span><span id="L-228"><a href="#L-228"><span class="linenos">228</span></a><span class="sd">		1) &#39;uncertainty&#39;: the reward is merely the uncertainty decrement of each agent. This will serve for complete coverage</span>
</span><span id="L-229"><a href="#L-229"><span class="linenos">229</span></a><span class="sd">		2) &#39;regret&#39;: the reward is the decrement of uncertainty but weighted with the sampling value of each agent. This will serve for finding maxima</span>
</span><span id="L-230"><a href="#L-230"><span class="linenos">230</span></a><span class="sd">		3) &#39;error&#39;: the reward is the error between the ground truth and the inferred map. This is for characterization.</span>
</span><span id="L-231"><a href="#L-231"><span class="linenos">231</span></a>
</span><span id="L-232"><a href="#L-232"><span class="linenos">232</span></a><span class="sd">		:param collision_array: The collision array of the current state.</span>
</span><span id="L-233"><a href="#L-233"><span class="linenos">233</span></a><span class="sd">		:param agents_ids: The ids of those agents that are expecting the reward.</span>
</span><span id="L-234"><a href="#L-234"><span class="linenos">234</span></a>
</span><span id="L-235"><a href="#L-235"><span class="linenos">235</span></a><span class="sd">		:return:</span>
</span><span id="L-236"><a href="#L-236"><span class="linenos">236</span></a><span class="sd">			- reward: The reward for each agent in a dictionary.</span>
</span><span id="L-237"><a href="#L-237"><span class="linenos">237</span></a><span class="sd">		&quot;&quot;&quot;</span>
</span><span id="L-238"><a href="#L-238"><span class="linenos">238</span></a>
</span><span id="L-239"><a href="#L-239"><span class="linenos">239</span></a>		<span class="k">if</span> <span class="n">agents_ids</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-240"><a href="#L-240"><span class="linenos">240</span></a>			<span class="n">agents_ids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">agents_ids</span>
</span><span id="L-241"><a href="#L-241"><span class="linenos">241</span></a>
</span><span id="L-242"><a href="#L-242"><span class="linenos">242</span></a>		<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;reward_type&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;uncertainty&#39;</span><span class="p">:</span>
</span><span id="L-243"><a href="#L-243"><span class="linenos">243</span></a>			<span class="n">reward</span> <span class="o">=</span> <span class="mi">100</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">individual_uncertainty_decrement</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">uncertainty_0</span>
</span><span id="L-244"><a href="#L-244"><span class="linenos">244</span></a>		<span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;reward_type&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;improvement&#39;</span><span class="p">:</span>
</span><span id="L-245"><a href="#L-245"><span class="linenos">245</span></a>			<span class="n">reward</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">individual_uncertainty_decrement</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">last_measurement_values</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">uncertainty_0</span>
</span><span id="L-246"><a href="#L-246"><span class="linenos">246</span></a>		<span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;reward_type&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;error&#39;</span><span class="p">:</span>
</span><span id="L-247"><a href="#L-247"><span class="linenos">247</span></a>			<span class="n">reward</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">mse_ant</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">mse</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">number_of_agents</span><span class="p">)])</span>
</span><span id="L-248"><a href="#L-248"><span class="linenos">248</span></a>		<span class="k">else</span><span class="p">:</span>
</span><span id="L-249"><a href="#L-249"><span class="linenos">249</span></a>			<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Invalid reward type&quot;</span><span class="p">)</span>
</span><span id="L-250"><a href="#L-250"><span class="linenos">250</span></a>
</span><span id="L-251"><a href="#L-251"><span class="linenos">251</span></a>		<span class="c1"># Penalize the agents that collided #</span>
</span><span id="L-252"><a href="#L-252"><span class="linenos">252</span></a>		<span class="n">reward</span><span class="p">[</span><span class="n">collision_array</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span>
</span><span id="L-253"><a href="#L-253"><span class="linenos">253</span></a>
</span><span id="L-254"><a href="#L-254"><span class="linenos">254</span></a>		<span class="k">return</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span> <span class="n">reward</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">agents_ids</span><span class="p">}</span>
</span><span id="L-255"><a href="#L-255"><span class="linenos">255</span></a>
</span><span id="L-256"><a href="#L-256"><span class="linenos">256</span></a>	<span class="k">def</span> <span class="nf">process_states</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">agent_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
</span><span id="L-257"><a href="#L-257"><span class="linenos">257</span></a>		<span class="sd">&quot;&quot;&quot; Render the states of the agents.</span>
</span><span id="L-258"><a href="#L-258"><span class="linenos">258</span></a>
</span><span id="L-259"><a href="#L-259"><span class="linenos">259</span></a><span class="sd">		:param agent_ids: The ids of those agents that are expecting the state.</span>
</span><span id="L-260"><a href="#L-260"><span class="linenos">260</span></a>
</span><span id="L-261"><a href="#L-261"><span class="linenos">261</span></a><span class="sd">		:return:</span>
</span><span id="L-262"><a href="#L-262"><span class="linenos">262</span></a><span class="sd">			- states: The state of the agents in a dictionary.</span>
</span><span id="L-263"><a href="#L-263"><span class="linenos">263</span></a>
</span><span id="L-264"><a href="#L-264"><span class="linenos">264</span></a><span class="sd">		&quot;&quot;&quot;</span>
</span><span id="L-265"><a href="#L-265"><span class="linenos">265</span></a>
</span><span id="L-266"><a href="#L-266"><span class="linenos">266</span></a>		<span class="k">if</span> <span class="n">agent_ids</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-267"><a href="#L-267"><span class="linenos">267</span></a>			<span class="n">agent_ids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">agents_ids</span>
</span><span id="L-268"><a href="#L-268"><span class="linenos">268</span></a>
</span><span id="L-269"><a href="#L-269"><span class="linenos">269</span></a>		<span class="n">s</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">individual_state</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">agent_ids</span><span class="p">}</span>
</span><span id="L-270"><a href="#L-270"><span class="linenos">270</span></a>
</span><span id="L-271"><a href="#L-271"><span class="linenos">271</span></a>		<span class="k">return</span> <span class="n">s</span>
</span><span id="L-272"><a href="#L-272"><span class="linenos">272</span></a>
</span><span id="L-273"><a href="#L-273"><span class="linenos">273</span></a>	<span class="k">def</span> <span class="nf">individual_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">agent_indx</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="nb">dict</span><span class="p">]:</span>
</span><span id="L-274"><a href="#L-274"><span class="linenos">274</span></a>		<span class="sd">&quot;&quot;&quot; Return the state of an individual agent.</span>
</span><span id="L-275"><a href="#L-275"><span class="linenos">275</span></a>
</span><span id="L-276"><a href="#L-276"><span class="linenos">276</span></a><span class="sd">		:param agent_indx: The index of the agent.</span>
</span><span id="L-277"><a href="#L-277"><span class="linenos">277</span></a>
</span><span id="L-278"><a href="#L-278"><span class="linenos">278</span></a><span class="sd">		:return:</span>
</span><span id="L-279"><a href="#L-279"><span class="linenos">279</span></a><span class="sd">			- state: The state of the agent. Could be a matrix (visual) or a dictionary (hybrid).</span>
</span><span id="L-280"><a href="#L-280"><span class="linenos">280</span></a>
</span><span id="L-281"><a href="#L-281"><span class="linenos">281</span></a><span class="sd">		&quot;&quot;&quot;</span>
</span><span id="L-282"><a href="#L-282"><span class="linenos">282</span></a>
</span><span id="L-283"><a href="#L-283"><span class="linenos">283</span></a>		<span class="n">other_agents_map</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;navigation_map&#39;</span><span class="p">])</span>
</span><span id="L-284"><a href="#L-284"><span class="linenos">284</span></a>		<span class="n">other_agents_ids</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">agents_ids</span><span class="p">)</span>
</span><span id="L-285"><a href="#L-285"><span class="linenos">285</span></a>		<span class="n">other_agents_ids</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">other_agents_ids</span><span class="p">,</span> <span class="n">agent_indx</span><span class="p">)</span>
</span><span id="L-286"><a href="#L-286"><span class="linenos">286</span></a>
</span><span id="L-287"><a href="#L-287"><span class="linenos">287</span></a>		<span class="k">for</span> <span class="n">agent_id</span> <span class="ow">in</span> <span class="n">other_agents_ids</span><span class="p">:</span>
</span><span id="L-288"><a href="#L-288"><span class="linenos">288</span></a>			<span class="n">agent_position</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fleet</span><span class="o">.</span><span class="n">vehicles</span><span class="p">[</span><span class="n">agent_id</span><span class="p">]</span><span class="o">.</span><span class="n">position</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
</span><span id="L-289"><a href="#L-289"><span class="linenos">289</span></a>			<span class="n">other_agents_map</span><span class="p">[</span><span class="n">agent_position</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">agent_position</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">1.0</span>
</span><span id="L-290"><a href="#L-290"><span class="linenos">290</span></a>
</span><span id="L-291"><a href="#L-291"><span class="linenos">291</span></a>		<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">observation_type</span> <span class="o">==</span> <span class="s1">&#39;visual&#39;</span><span class="p">:</span>
</span><span id="L-292"><a href="#L-292"><span class="linenos">292</span></a>
</span><span id="L-293"><a href="#L-293"><span class="linenos">293</span></a>			<span class="c1"># First channel: navigation/obstacle map</span>
</span><span id="L-294"><a href="#L-294"><span class="linenos">294</span></a>			<span class="n">nav_map</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;navigation_map&#39;</span><span class="p">])</span>
</span><span id="L-295"><a href="#L-295"><span class="linenos">295</span></a>
</span><span id="L-296"><a href="#L-296"><span class="linenos">296</span></a>			<span class="c1"># Second channel: self-position map</span>
</span><span id="L-297"><a href="#L-297"><span class="linenos">297</span></a>			<span class="n">position_map</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;navigation_map&#39;</span><span class="p">])</span>
</span><span id="L-298"><a href="#L-298"><span class="linenos">298</span></a>			<span class="n">agent_position</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fleet</span><span class="o">.</span><span class="n">vehicles</span><span class="p">[</span><span class="n">agent_indx</span><span class="p">]</span><span class="o">.</span><span class="n">position</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
</span><span id="L-299"><a href="#L-299"><span class="linenos">299</span></a>			<span class="n">position_map</span><span class="p">[</span><span class="n">agent_position</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">agent_position</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">1.0</span>
</span><span id="L-300"><a href="#L-300"><span class="linenos">300</span></a>
</span><span id="L-301"><a href="#L-301"><span class="linenos">301</span></a>			<span class="c1"># Note that the mu and sigma maps are already normalized to [0, 1]</span>
</span><span id="L-302"><a href="#L-302"><span class="linenos">302</span></a>			<span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">nav_map</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">],</span>
</span><span id="L-303"><a href="#L-303"><span class="linenos">303</span></a>			                       <span class="n">position_map</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">],</span>
</span><span id="L-304"><a href="#L-304"><span class="linenos">304</span></a>			                       <span class="n">other_agents_map</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">],</span>
</span><span id="L-305"><a href="#L-305"><span class="linenos">305</span></a>			                       <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">],</span> <span class="n">a_min</span><span class="o">=-</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">a_max</span><span class="o">=</span><span class="mf">1.0</span><span class="p">),</span>
</span><span id="L-306"><a href="#L-306"><span class="linenos">306</span></a>			                       <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">uncertainty</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">],</span> <span class="n">a_min</span><span class="o">=-</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">a_max</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)))</span>
</span><span id="L-307"><a href="#L-307"><span class="linenos">307</span></a>
</span><span id="L-308"><a href="#L-308"><span class="linenos">308</span></a>		<span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">observation_type</span> <span class="o">==</span> <span class="s1">&#39;hybrid&#39;</span><span class="p">:</span>
</span><span id="L-309"><a href="#L-309"><span class="linenos">309</span></a>
</span><span id="L-310"><a href="#L-310"><span class="linenos">310</span></a>			<span class="k">return</span> <span class="p">{</span><span class="s1">&#39;visual_state&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">],</span>
</span><span id="L-311"><a href="#L-311"><span class="linenos">311</span></a>			                                        <span class="bp">self</span><span class="o">.</span><span class="n">uncertainty</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">],</span>
</span><span id="L-312"><a href="#L-312"><span class="linenos">312</span></a>			                                        <span class="n">other_agents_map</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">])),</span>
</span><span id="L-313"><a href="#L-313"><span class="linenos">313</span></a>			        <span class="s1">&#39;odometry&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">fleet</span><span class="o">.</span><span class="n">vehicles</span><span class="p">[</span><span class="n">agent_indx</span><span class="p">]</span><span class="o">.</span><span class="n">position</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;navigation_map&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">}</span>
</span><span id="L-314"><a href="#L-314"><span class="linenos">314</span></a>
</span><span id="L-315"><a href="#L-315"><span class="linenos">315</span></a>	<span class="k">def</span> <span class="nf">update_vehicles_ground_truths</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="L-316"><a href="#L-316"><span class="linenos">316</span></a>		<span class="sd">&quot;&quot;&quot; Setter to update the ground truth of the vehicles. &quot;&quot;&quot;</span>
</span><span id="L-317"><a href="#L-317"><span class="linenos">317</span></a>
</span><span id="L-318"><a href="#L-318"><span class="linenos">318</span></a>		<span class="k">for</span> <span class="n">vehicle</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">fleet</span><span class="o">.</span><span class="n">vehicles</span><span class="p">:</span>
</span><span id="L-319"><a href="#L-319"><span class="linenos">319</span></a>			<span class="n">vehicle</span><span class="o">.</span><span class="n">ground_truth</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ground_truth</span><span class="o">.</span><span class="n">ground_truth_field</span>
</span><span id="L-320"><a href="#L-320"><span class="linenos">320</span></a>
</span><span id="L-321"><a href="#L-321"><span class="linenos">321</span></a>	<span class="k">def</span> <span class="nf">action_dict_to_targets</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">a_dict</span><span class="p">:</span> <span class="nb">dict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
</span><span id="L-322"><a href="#L-322"><span class="linenos">322</span></a>		<span class="sd">&quot;&quot;&quot; Transform the actions of the dictionary to a dictionary with the target goals.</span>
</span><span id="L-323"><a href="#L-323"><span class="linenos">323</span></a>
</span><span id="L-324"><a href="#L-324"><span class="linenos">324</span></a><span class="sd">		:param a_dict: The dictionary of actions. Every key is an agent_id, and the values corresponds to the action.</span>
</span><span id="L-325"><a href="#L-325"><span class="linenos">325</span></a>
</span><span id="L-326"><a href="#L-326"><span class="linenos">326</span></a><span class="sd">		:return:</span>
</span><span id="L-327"><a href="#L-327"><span class="linenos">327</span></a><span class="sd">			- targets: An array that contains the target positions for every vehicle.</span>
</span><span id="L-328"><a href="#L-328"><span class="linenos">328</span></a>
</span><span id="L-329"><a href="#L-329"><span class="linenos">329</span></a><span class="sd">		&quot;&quot;&quot;</span>
</span><span id="L-330"><a href="#L-330"><span class="linenos">330</span></a>
</span><span id="L-331"><a href="#L-331"><span class="linenos">331</span></a>		<span class="n">target_agents</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">a_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
</span><span id="L-332"><a href="#L-332"><span class="linenos">332</span></a>
</span><span id="L-333"><a href="#L-333"><span class="linenos">333</span></a>		<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;movement_type&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;DIRECTIONAL&#39;</span><span class="p">:</span>
</span><span id="L-334"><a href="#L-334"><span class="linenos">334</span></a>			<span class="c1"># Transform discrete actions to displacement</span>
</span><span id="L-335"><a href="#L-335"><span class="linenos">335</span></a>			<span class="n">angles</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">action</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;number_of_actions&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">action</span> <span class="ow">in</span> <span class="n">a_dict</span><span class="o">.</span><span class="n">values</span><span class="p">()])</span>
</span><span id="L-336"><a href="#L-336"><span class="linenos">336</span></a>			<span class="c1"># Transform the displacement to positions #</span>
</span><span id="L-337"><a href="#L-337"><span class="linenos">337</span></a>			<span class="n">target_positions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fleet</span><span class="o">.</span><span class="n">get_positions</span><span class="p">()[</span><span class="n">target_agents</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;measurement_distance&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">(</span>
</span><span id="L-338"><a href="#L-338"><span class="linenos">338</span></a>				<span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">angles</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">angles</span><span class="p">)))</span>
</span><span id="L-339"><a href="#L-339"><span class="linenos">339</span></a>
</span><span id="L-340"><a href="#L-340"><span class="linenos">340</span></a>		<span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;movement_type&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;DIRECTIONAL_DISTANCE&#39;</span><span class="p">:</span>
</span><span id="L-341"><a href="#L-341"><span class="linenos">341</span></a>			<span class="c1"># Transform the continuous actions into displacement #</span>
</span><span id="L-342"><a href="#L-342"><span class="linenos">342</span></a>			<span class="n">actions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">action</span> <span class="k">for</span> <span class="n">action</span> <span class="ow">in</span> <span class="n">a_dict</span><span class="o">.</span><span class="n">values</span><span class="p">()])</span>
</span><span id="L-343"><a href="#L-343"><span class="linenos">343</span></a>			<span class="n">angles</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">actions</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
</span><span id="L-344"><a href="#L-344"><span class="linenos">344</span></a>			<span class="n">distances</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear_min_max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;min_measurement_distance&#39;</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;max_measurement_distance&#39;</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span>
</span><span id="L-345"><a href="#L-345"><span class="linenos">345</span></a>			                                <span class="n">actions</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
</span><span id="L-346"><a href="#L-346"><span class="linenos">346</span></a>			<span class="n">target_positions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fleet</span><span class="o">.</span><span class="n">get_positions</span><span class="p">()[</span><span class="n">target_agents</span><span class="p">]</span> <span class="o">+</span> <span class="n">distances</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">angles</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">angles</span><span class="p">)))</span>
</span><span id="L-347"><a href="#L-347"><span class="linenos">347</span></a>		<span class="k">else</span><span class="p">:</span>
</span><span id="L-348"><a href="#L-348"><span class="linenos">348</span></a>			<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Invalid movement type&quot;</span><span class="p">)</span>
</span><span id="L-349"><a href="#L-349"><span class="linenos">349</span></a>
</span><span id="L-350"><a href="#L-350"><span class="linenos">350</span></a>		<span class="k">return</span> <span class="n">target_positions</span>
</span><span id="L-351"><a href="#L-351"><span class="linenos">351</span></a>
</span><span id="L-352"><a href="#L-352"><span class="linenos">352</span></a>	<span class="nd">@staticmethod</span>
</span><span id="L-353"><a href="#L-353"><span class="linenos">353</span></a>	<span class="k">def</span> <span class="nf">linear_min_max</span><span class="p">(</span><span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span><span class="p">,</span> <span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
</span><span id="L-354"><a href="#L-354"><span class="linenos">354</span></a>		<span class="sd">&quot;&quot;&quot; Transform the input x into a line &quot;&quot;&quot;</span>
</span><span id="L-355"><a href="#L-355"><span class="linenos">355</span></a>		<span class="k">return</span> <span class="p">(</span><span class="n">y_max</span> <span class="o">-</span> <span class="n">y_min</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">x_max</span> <span class="o">-</span> <span class="n">x_min</span><span class="p">)</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y_min</span>
</span><span id="L-356"><a href="#L-356"><span class="linenos">356</span></a>
</span><span id="L-357"><a href="#L-357"><span class="linenos">357</span></a>	<span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">action_dict</span><span class="p">:</span> <span class="nb">dict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="p">(</span><span class="nb">dict</span><span class="p">,</span> <span class="nb">dict</span><span class="p">,</span> <span class="nb">dict</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
</span><span id="L-358"><a href="#L-358"><span class="linenos">358</span></a>		<span class="sd">&quot;&quot;&quot; Process the actions. The action is processed for those waiting vehicles. The fleet is updated until one/all vehicles are ready.</span>
</span><span id="L-359"><a href="#L-359"><span class="linenos">359</span></a><span class="sd">		Every vehicle takes a measurement and the reward is processed</span>
</span><span id="L-360"><a href="#L-360"><span class="linenos">360</span></a>
</span><span id="L-361"><a href="#L-361"><span class="linenos">361</span></a><span class="sd">		:param action_dict: The dictionary of actions. Every key is an agent_id, and the values corresponds to the action.</span>
</span><span id="L-362"><a href="#L-362"><span class="linenos">362</span></a>
</span><span id="L-363"><a href="#L-363"><span class="linenos">363</span></a><span class="sd">		:return:</span>
</span><span id="L-364"><a href="#L-364"><span class="linenos">364</span></a><span class="sd">			- reward: The reward for each agent.</span>
</span><span id="L-365"><a href="#L-365"><span class="linenos">365</span></a><span class="sd">			- observation: The observation for each agent.</span>
</span><span id="L-366"><a href="#L-366"><span class="linenos">366</span></a><span class="sd">			- done: A boolean that indicates if the episode is finished.</span>
</span><span id="L-367"><a href="#L-367"><span class="linenos">367</span></a><span class="sd">			- info: A dictionary that contains additional information.</span>
</span><span id="L-368"><a href="#L-368"><span class="linenos">368</span></a>
</span><span id="L-369"><a href="#L-369"><span class="linenos">369</span></a><span class="sd">		&quot;&quot;&quot;</span>
</span><span id="L-370"><a href="#L-370"><span class="linenos">370</span></a>
</span><span id="L-371"><a href="#L-371"><span class="linenos">371</span></a>		<span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">resetted</span><span class="p">,</span> <span class="s2">&quot;You need to reset the environment first with env.reset()&quot;</span>
</span><span id="L-372"><a href="#L-372"><span class="linenos">372</span></a>
</span><span id="L-373"><a href="#L-373"><span class="linenos">373</span></a>		<span class="c1"># Compute the new target with the given actions #</span>
</span><span id="L-374"><a href="#L-374"><span class="linenos">374</span></a>		<span class="n">new_targets</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_dict_to_targets</span><span class="p">(</span><span class="n">action_dict</span><span class="p">)</span>
</span><span id="L-375"><a href="#L-375"><span class="linenos">375</span></a>
</span><span id="L-376"><a href="#L-376"><span class="linenos">376</span></a>		<span class="c1"># Apply the new target to the vehicles #</span>
</span><span id="L-377"><a href="#L-377"><span class="linenos">377</span></a>		<span class="k">for</span> <span class="n">vehicle_id</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">action_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">(),</span> <span class="n">new_targets</span><span class="p">):</span>
</span><span id="L-378"><a href="#L-378"><span class="linenos">378</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">fleet</span><span class="o">.</span><span class="n">set_target_position</span><span class="p">(</span><span class="n">vehicle_id</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
</span><span id="L-379"><a href="#L-379"><span class="linenos">379</span></a>
</span><span id="L-380"><a href="#L-380"><span class="linenos">380</span></a>		<span class="c1"># Step until any vehicle has completed (or failed its goal) #</span>
</span><span id="L-381"><a href="#L-381"><span class="linenos">381</span></a>		<span class="n">new_measurements</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="L-382"><a href="#L-382"><span class="linenos">382</span></a>
</span><span id="L-383"><a href="#L-383"><span class="linenos">383</span></a>		<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;movement_type&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;DIRECTIONAL&#39;</span><span class="p">:</span>
</span><span id="L-384"><a href="#L-384"><span class="linenos">384</span></a>			<span class="c1"># Update until ALL vehicles have arrived to their goals #</span>
</span><span id="L-385"><a href="#L-385"><span class="linenos">385</span></a>			<span class="n">_</span><span class="p">,</span> <span class="n">new_measurements</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fleet</span><span class="o">.</span><span class="n">update_syncronously</span><span class="p">()</span>
</span><span id="L-386"><a href="#L-386"><span class="linenos">386</span></a>		<span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;movement_type&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;DIRECTIONAL_DISTANCE&#39;</span><span class="p">:</span>
</span><span id="L-387"><a href="#L-387"><span class="linenos">387</span></a>			<span class="c1"># Update until AT LEAST ONE vehicle has arrived to their goals#</span>
</span><span id="L-388"><a href="#L-388"><span class="linenos">388</span></a>			<span class="n">_</span><span class="p">,</span> <span class="n">new_measurements</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fleet</span><span class="o">.</span><span class="n">update_asyncronously</span><span class="p">()</span>
</span><span id="L-389"><a href="#L-389"><span class="linenos">389</span></a>
</span><span id="L-390"><a href="#L-390"><span class="linenos">390</span></a>		<span class="c1"># Retrieve the ids of the agents that must return a state and a reward #</span>
</span><span id="L-391"><a href="#L-391"><span class="linenos">391</span></a>		<span class="n">ready_agents_ids</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">veh_state</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fleet</span><span class="o">.</span><span class="n">fleet_state</span><span class="p">)</span> <span class="k">if</span> <span class="n">veh_state</span> <span class="ow">in</span> <span class="p">[</span><span class="n">FleetState</span><span class="o">.</span><span class="n">WAITING_FOR_ACTION</span><span class="p">,</span> <span class="n">FleetState</span><span class="o">.</span><span class="n">COLLIDED</span><span class="p">,</span> <span class="n">FleetState</span><span class="o">.</span><span class="n">LAST_ACTION</span><span class="p">]]</span>
</span><span id="L-392"><a href="#L-392"><span class="linenos">392</span></a>
</span><span id="L-393"><a href="#L-393"><span class="linenos">393</span></a>		<span class="c1"># Compute those agents that collided and add 1 collision to their counter #</span>
</span><span id="L-394"><a href="#L-394"><span class="linenos">394</span></a>		<span class="n">collision_array</span> <span class="o">=</span> <span class="p">[</span><span class="n">s</span> <span class="o">==</span> <span class="n">FleetState</span><span class="o">.</span><span class="n">COLLIDED</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">fleet</span><span class="o">.</span><span class="n">fleet_state</span><span class="p">]</span>
</span><span id="L-395"><a href="#L-395"><span class="linenos">395</span></a>		<span class="c1"># Accumulate every agent collision #</span>
</span><span id="L-396"><a href="#L-396"><span class="linenos">396</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">number_of_collisions</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">collision_array</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
</span><span id="L-397"><a href="#L-397"><span class="linenos">397</span></a>		<span class="c1"># For every agent, change its state to final if its number of collisions is equal to the maximum number of collisions #</span>
</span><span id="L-398"><a href="#L-398"><span class="linenos">398</span></a>		<span class="k">for</span> <span class="n">agent_id</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">agents_ids</span><span class="p">:</span>
</span><span id="L-399"><a href="#L-399"><span class="linenos">399</span></a>			<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">number_of_collisions</span><span class="p">[</span><span class="n">agent_id</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_collisions</span><span class="p">:</span>
</span><span id="L-400"><a href="#L-400"><span class="linenos">400</span></a>				<span class="bp">self</span><span class="o">.</span><span class="n">fleet</span><span class="o">.</span><span class="n">set_state</span><span class="p">(</span><span class="n">agent_id</span><span class="p">,</span> <span class="n">FleetState</span><span class="o">.</span><span class="n">LAST_ACTION</span><span class="p">)</span>
</span><span id="L-401"><a href="#L-401"><span class="linenos">401</span></a>
</span><span id="L-402"><a href="#L-402"><span class="linenos">402</span></a>		<span class="n">done_agents_vals</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">fleet</span><span class="o">.</span><span class="n">fleet_state</span><span class="p">[</span><span class="n">agents_id</span><span class="p">]</span> <span class="o">==</span> <span class="n">FleetState</span><span class="o">.</span><span class="n">LAST_ACTION</span> <span class="k">for</span> <span class="n">agents_id</span> <span class="ow">in</span> <span class="n">ready_agents_ids</span><span class="p">]</span>
</span><span id="L-403"><a href="#L-403"><span class="linenos">403</span></a>
</span><span id="L-404"><a href="#L-404"><span class="linenos">404</span></a>		<span class="c1"># Update the model</span>
</span><span id="L-405"><a href="#L-405"><span class="linenos">405</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">uncertainty</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">update_model</span><span class="p">(</span><span class="n">new_measurements</span><span class="o">=</span><span class="n">new_measurements</span><span class="p">,</span> <span class="n">agents_ids</span><span class="o">=</span><span class="n">ready_agents_ids</span><span class="p">)</span>
</span><span id="L-406"><a href="#L-406"><span class="linenos">406</span></a>
</span><span id="L-407"><a href="#L-407"><span class="linenos">407</span></a>		<span class="c1"># Compute the rewards for those finished agents #</span>
</span><span id="L-408"><a href="#L-408"><span class="linenos">408</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">rewards</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_function</span><span class="p">(</span><span class="n">collision_array</span><span class="o">=</span><span class="n">collision_array</span><span class="p">,</span> <span class="n">agents_ids</span><span class="o">=</span><span class="n">ready_agents_ids</span><span class="p">)</span>
</span><span id="L-409"><a href="#L-409"><span class="linenos">409</span></a>
</span><span id="L-410"><a href="#L-410"><span class="linenos">410</span></a>		<span class="c1"># Compute the states for those same agents #</span>
</span><span id="L-411"><a href="#L-411"><span class="linenos">411</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">process_states</span><span class="p">(</span><span class="n">agent_ids</span><span class="o">=</span><span class="n">ready_agents_ids</span><span class="p">)</span>
</span><span id="L-412"><a href="#L-412"><span class="linenos">412</span></a>
</span><span id="L-413"><a href="#L-413"><span class="linenos">413</span></a>		<span class="c1"># Info is useless by the moment</span>
</span><span id="L-414"><a href="#L-414"><span class="linenos">414</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">infos</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;Collisions&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">number_of_collisions</span><span class="p">[</span><span class="n">i</span><span class="p">]}</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">ready_agents_ids</span><span class="p">}</span>
</span><span id="L-415"><a href="#L-415"><span class="linenos">415</span></a>
</span><span id="L-416"><a href="#L-416"><span class="linenos">416</span></a>		<span class="c1"># Update the ground truth state and pass the field to agents #</span>
</span><span id="L-417"><a href="#L-417"><span class="linenos">417</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">ground_truth</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</span><span id="L-418"><a href="#L-418"><span class="linenos">418</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">update_vehicles_ground_truths</span><span class="p">()</span>
</span><span id="L-419"><a href="#L-419"><span class="linenos">419</span></a>
</span><span id="L-420"><a href="#L-420"><span class="linenos">420</span></a>		<span class="c1"># Compute if the agents have finished #</span>
</span><span id="L-421"><a href="#L-421"><span class="linenos">421</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">dones</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span> <span class="n">val</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">ready_agents_ids</span><span class="p">,</span> <span class="n">done_agents_vals</span><span class="p">)}</span>
</span><span id="L-422"><a href="#L-422"><span class="linenos">422</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">dones</span><span class="p">[</span><span class="s1">&#39;__all__&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">all</span><span class="p">([</span><span class="n">veh_state</span> <span class="ow">in</span> <span class="p">[</span><span class="n">FleetState</span><span class="o">.</span><span class="n">LAST_ACTION</span><span class="p">,</span> <span class="n">FleetState</span><span class="o">.</span><span class="n">FINISHED</span><span class="p">]</span> <span class="k">for</span> <span class="n">veh_state</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">fleet</span><span class="o">.</span><span class="n">fleet_state</span><span class="p">])</span>
</span><span id="L-423"><a href="#L-423"><span class="linenos">423</span></a>
</span><span id="L-424"><a href="#L-424"><span class="linenos">424</span></a>
</span><span id="L-425"><a href="#L-425"><span class="linenos">425</span></a>		<span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">states</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">rewards</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dones</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">infos</span>
</span><span id="L-426"><a href="#L-426"><span class="linenos">426</span></a>
</span><span id="L-427"><a href="#L-427"><span class="linenos">427</span></a>	<span class="k">def</span> <span class="nf">render</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;human&#39;</span><span class="p">):</span>
</span><span id="L-428"><a href="#L-428"><span class="linenos">428</span></a>		<span class="sd">&quot;&quot;&quot; Render the environment. &quot;&quot;&quot;</span>
</span><span id="L-429"><a href="#L-429"><span class="linenos">429</span></a>
</span><span id="L-430"><a href="#L-430"><span class="linenos">430</span></a>		<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">fig</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="L-431"><a href="#L-431"><span class="linenos">431</span></a>
</span><span id="L-432"><a href="#L-432"><span class="linenos">432</span></a>			<span class="n">plt</span><span class="o">.</span><span class="n">ion</span><span class="p">()</span>
</span><span id="L-433"><a href="#L-433"><span class="linenos">433</span></a>
</span><span id="L-434"><a href="#L-434"><span class="linenos">434</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">fig</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
</span><span id="L-435"><a href="#L-435"><span class="linenos">435</span></a>
</span><span id="L-436"><a href="#L-436"><span class="linenos">436</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Navigation map&#39;</span><span class="p">)</span>
</span><span id="L-437"><a href="#L-437"><span class="linenos">437</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">s0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;navigation_map&#39;</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
</span><span id="L-438"><a href="#L-438"><span class="linenos">438</span></a>
</span><span id="L-439"><a href="#L-439"><span class="linenos">439</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Fleet positions&#39;</span><span class="p">)</span>
</span><span id="L-440"><a href="#L-440"><span class="linenos">440</span></a>			<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">observation_type</span> <span class="o">==</span> <span class="s1">&#39;visual&#39;</span><span class="p">:</span>
</span><span id="L-441"><a href="#L-441"><span class="linenos">441</span></a>				<span class="bp">self</span><span class="o">.</span><span class="n">s1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">individual_state</span><span class="p">(</span><span class="n">i</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">number_of_agents</span><span class="p">)],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
</span><span id="L-442"><a href="#L-442"><span class="linenos">442</span></a>			<span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">observation_type</span> <span class="o">==</span> <span class="s1">&#39;hybrid&#39;</span><span class="p">:</span>
</span><span id="L-443"><a href="#L-443"><span class="linenos">443</span></a>				<span class="bp">self</span><span class="o">.</span><span class="n">s1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">individual_state</span><span class="p">(</span><span class="n">i</span><span class="p">)[</span><span class="s1">&#39;visual_state&#39;</span><span class="p">][</span><span class="mi">2</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">number_of_agents</span><span class="p">)],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
</span><span id="L-444"><a href="#L-444"><span class="linenos">444</span></a>			<span class="k">else</span><span class="p">:</span>
</span><span id="L-445"><a href="#L-445"><span class="linenos">445</span></a>				<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s1">&#39;Cannot render with an invalid observation type.&#39;</span><span class="p">)</span>
</span><span id="L-446"><a href="#L-446"><span class="linenos">446</span></a>
</span><span id="L-447"><a href="#L-447"><span class="linenos">447</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Estimated model&#39;</span><span class="p">)</span>
</span><span id="L-448"><a href="#L-448"><span class="linenos">448</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">s2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;jet&#39;</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
</span><span id="L-449"><a href="#L-449"><span class="linenos">449</span></a>
</span><span id="L-450"><a href="#L-450"><span class="linenos">450</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">axs</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Uncertainty&#39;</span><span class="p">)</span>
</span><span id="L-451"><a href="#L-451"><span class="linenos">451</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">s3</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">axs</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">uncertainty</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
</span><span id="L-452"><a href="#L-452"><span class="linenos">452</span></a>
</span><span id="L-453"><a href="#L-453"><span class="linenos">453</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">axs</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Ground truth&#39;</span><span class="p">)</span>
</span><span id="L-454"><a href="#L-454"><span class="linenos">454</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">s4</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">axs</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ground_truth</span><span class="o">.</span><span class="n">ground_truth_field</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;jet&#39;</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
</span><span id="L-455"><a href="#L-455"><span class="linenos">455</span></a>
</span><span id="L-456"><a href="#L-456"><span class="linenos">456</span></a>		<span class="k">else</span><span class="p">:</span>
</span><span id="L-457"><a href="#L-457"><span class="linenos">457</span></a>
</span><span id="L-458"><a href="#L-458"><span class="linenos">458</span></a>			<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">observation_type</span> <span class="o">==</span> <span class="s1">&#39;visual&#39;</span><span class="p">:</span>
</span><span id="L-459"><a href="#L-459"><span class="linenos">459</span></a>				<span class="bp">self</span><span class="o">.</span><span class="n">s1</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">individual_state</span><span class="p">(</span><span class="n">i</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">number_of_agents</span><span class="p">)],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
</span><span id="L-460"><a href="#L-460"><span class="linenos">460</span></a>			<span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">observation_type</span> <span class="o">==</span> <span class="s1">&#39;hybrid&#39;</span><span class="p">:</span>
</span><span id="L-461"><a href="#L-461"><span class="linenos">461</span></a>				<span class="bp">self</span><span class="o">.</span><span class="n">s1</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">individual_state</span><span class="p">(</span><span class="n">i</span><span class="p">)[</span><span class="s1">&#39;visual_state&#39;</span><span class="p">][</span><span class="mi">2</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">number_of_agents</span><span class="p">)],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
</span><span id="L-462"><a href="#L-462"><span class="linenos">462</span></a>
</span><span id="L-463"><a href="#L-463"><span class="linenos">463</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">s2</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="p">)</span>
</span><span id="L-464"><a href="#L-464"><span class="linenos">464</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">s3</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">uncertainty</span><span class="p">)</span>
</span><span id="L-465"><a href="#L-465"><span class="linenos">465</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">s4</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ground_truth</span><span class="o">.</span><span class="n">ground_truth_field</span><span class="p">)</span>
</span><span id="L-466"><a href="#L-466"><span class="linenos">466</span></a>
</span><span id="L-467"><a href="#L-467"><span class="linenos">467</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">fig</span><span class="o">.</span><span class="n">canvas</span><span class="o">.</span><span class="n">draw</span><span class="p">()</span>
</span><span id="L-468"><a href="#L-468"><span class="linenos">468</span></a>
</span><span id="L-469"><a href="#L-469"><span class="linenos">469</span></a>		<span class="n">plt</span><span class="o">.</span><span class="n">pause</span><span class="p">(</span><span class="mf">0.01</span><span class="p">)</span>
</span><span id="L-470"><a href="#L-470"><span class="linenos">470</span></a>		<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">(</span><span class="n">pad</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
</span><span id="L-471"><a href="#L-471"><span class="linenos">471</span></a>		<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span><span id="L-472"><a href="#L-472"><span class="linenos">472</span></a>
</span><span id="L-473"><a href="#L-473"><span class="linenos">473</span></a>	<span class="k">def</span> <span class="nf">get_action_mask</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ind</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
</span><span id="L-474"><a href="#L-474"><span class="linenos">474</span></a>		<span class="sd">&quot;&quot;&quot; Get the invalid action mask for a certain vehicle (*ind*)</span>
</span><span id="L-475"><a href="#L-475"><span class="linenos">475</span></a>
</span><span id="L-476"><a href="#L-476"><span class="linenos">476</span></a><span class="sd">		:param ind: The index of the vehicle</span>
</span><span id="L-477"><a href="#L-477"><span class="linenos">477</span></a>
</span><span id="L-478"><a href="#L-478"><span class="linenos">478</span></a><span class="sd">		:return:</span>
</span><span id="L-479"><a href="#L-479"><span class="linenos">479</span></a><span class="sd">			- mask: The invalid action mask for the vehicle, where true means that the action is valid.</span>
</span><span id="L-480"><a href="#L-480"><span class="linenos">480</span></a>
</span><span id="L-481"><a href="#L-481"><span class="linenos">481</span></a><span class="sd">		&quot;&quot;&quot;</span>
</span><span id="L-482"><a href="#L-482"><span class="linenos">482</span></a>
</span><span id="L-483"><a href="#L-483"><span class="linenos">483</span></a>		<span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;movement_type&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;DIRECTIONAL&#39;</span><span class="p">,</span> <span class="s1">&#39;This function is only valid for DIRECTIONAL movement.&#39;</span>
</span><span id="L-484"><a href="#L-484"><span class="linenos">484</span></a>
</span><span id="L-485"><a href="#L-485"><span class="linenos">485</span></a>		<span class="n">angles</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;number_of_actions&#39;</span><span class="p">])</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;number_of_actions&#39;</span><span class="p">]</span>
</span><span id="L-486"><a href="#L-486"><span class="linenos">486</span></a>		<span class="n">possible_points</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fleet</span><span class="o">.</span><span class="n">vehicles</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span><span class="o">.</span><span class="n">position</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;measurement_distance&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">angles</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">angles</span><span class="p">)))</span>
</span><span id="L-487"><a href="#L-487"><span class="linenos">487</span></a>
</span><span id="L-488"><a href="#L-488"><span class="linenos">488</span></a>		<span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fleet</span><span class="o">.</span><span class="n">vehicles</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span><span class="o">.</span><span class="n">is_the_position_valid</span><span class="p">,</span> <span class="n">possible_points</span><span class="p">)))</span>
</span><span id="L-489"><a href="#L-489"><span class="linenos">489</span></a>
</span><span id="L-490"><a href="#L-490"><span class="linenos">490</span></a>
</span><span id="L-491"><a href="#L-491"><span class="linenos">491</span></a><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
</span><span id="L-492"><a href="#L-492"><span class="linenos">492</span></a>
</span><span id="L-493"><a href="#L-493"><span class="linenos">493</span></a>	<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</span><span id="L-494"><a href="#L-494"><span class="linenos">494</span></a>
</span><span id="L-495"><a href="#L-495"><span class="linenos">495</span></a>	<span class="n">navigation_map</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">genfromtxt</span><span class="p">(</span><span class="s1">&#39;./wesslinger_map.txt&#39;</span><span class="p">)</span>
</span><span id="L-496"><a href="#L-496"><span class="linenos">496</span></a>
</span><span id="L-497"><a href="#L-497"><span class="linenos">497</span></a>	<span class="n">N</span> <span class="o">=</span> <span class="mi">4</span>
</span><span id="L-498"><a href="#L-498"><span class="linenos">498</span></a>
</span><span id="L-499"><a href="#L-499"><span class="linenos">499</span></a>	<span class="n">env_config</span> <span class="o">=</span> <span class="p">{</span>
</span><span id="L-500"><a href="#L-500"><span class="linenos">500</span></a>		<span class="s1">&#39;fleet_configuration&#39;</span><span class="p">:</span> <span class="p">{</span>
</span><span id="L-501"><a href="#L-501"><span class="linenos">501</span></a>			<span class="s1">&#39;vehicle_configuration&#39;</span><span class="p">:</span> <span class="p">{</span>
</span><span id="L-502"><a href="#L-502"><span class="linenos">502</span></a>				<span class="s1">&#39;dt&#39;</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span>
</span><span id="L-503"><a href="#L-503"><span class="linenos">503</span></a>				<span class="s1">&#39;navigation_map&#39;</span><span class="p">:</span> <span class="n">navigation_map</span><span class="p">,</span>
</span><span id="L-504"><a href="#L-504"><span class="linenos">504</span></a>				<span class="s1">&#39;target_threshold&#39;</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">,</span>
</span><span id="L-505"><a href="#L-505"><span class="linenos">505</span></a>				<span class="s1">&#39;ground_truth&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span><span class="mi">50</span><span class="p">),</span>
</span><span id="L-506"><a href="#L-506"><span class="linenos">506</span></a>				<span class="s1">&#39;measurement_size&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]),</span>
</span><span id="L-507"><a href="#L-507"><span class="linenos">507</span></a>				<span class="s1">&#39;max_travel_distance&#39;</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span>
</span><span id="L-508"><a href="#L-508"><span class="linenos">508</span></a>			<span class="p">},</span>
</span><span id="L-509"><a href="#L-509"><span class="linenos">509</span></a>			<span class="s1">&#39;number_of_vehicles&#39;</span><span class="p">:</span> <span class="n">N</span><span class="p">,</span>
</span><span id="L-510"><a href="#L-510"><span class="linenos">510</span></a>			<span class="s1">&#39;initial_positions&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">15</span><span class="p">,</span> <span class="mi">19</span><span class="p">],</span>
</span><span id="L-511"><a href="#L-511"><span class="linenos">511</span></a>			                               <span class="p">[</span><span class="mi">13</span><span class="p">,</span> <span class="mi">19</span><span class="p">],</span>
</span><span id="L-512"><a href="#L-512"><span class="linenos">512</span></a>			                               <span class="p">[</span><span class="mi">18</span><span class="p">,</span> <span class="mi">19</span><span class="p">],</span>
</span><span id="L-513"><a href="#L-513"><span class="linenos">513</span></a>			                               <span class="p">[</span><span class="mi">15</span><span class="p">,</span> <span class="mi">22</span><span class="p">]])</span>
</span><span id="L-514"><a href="#L-514"><span class="linenos">514</span></a>		<span class="p">},</span>
</span><span id="L-515"><a href="#L-515"><span class="linenos">515</span></a>		<span class="s1">&#39;movement_type&#39;</span><span class="p">:</span> <span class="s1">&#39;DIRECTIONAL&#39;</span><span class="p">,</span>
</span><span id="L-516"><a href="#L-516"><span class="linenos">516</span></a>		<span class="s1">&#39;navigation_map&#39;</span><span class="p">:</span> <span class="n">navigation_map</span><span class="p">,</span>
</span><span id="L-517"><a href="#L-517"><span class="linenos">517</span></a>		<span class="s1">&#39;dynamic&#39;</span><span class="p">:</span> <span class="s1">&#39;Shekel&#39;</span><span class="p">,</span>
</span><span id="L-518"><a href="#L-518"><span class="linenos">518</span></a>		<span class="s1">&#39;min_measurement_distance&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
</span><span id="L-519"><a href="#L-519"><span class="linenos">519</span></a>		<span class="s1">&#39;max_measurement_distance&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>
</span><span id="L-520"><a href="#L-520"><span class="linenos">520</span></a>		<span class="s1">&#39;measurement_distance&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
</span><span id="L-521"><a href="#L-521"><span class="linenos">521</span></a>		<span class="s1">&#39;number_of_actions&#39;</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span>
</span><span id="L-522"><a href="#L-522"><span class="linenos">522</span></a>		<span class="s1">&#39;kernel_length_scale&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
</span><span id="L-523"><a href="#L-523"><span class="linenos">523</span></a>		<span class="s1">&#39;random_benchmark&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="L-524"><a href="#L-524"><span class="linenos">524</span></a>		<span class="s1">&#39;observation_type&#39;</span><span class="p">:</span> <span class="s1">&#39;visual&#39;</span><span class="p">,</span>
</span><span id="L-525"><a href="#L-525"><span class="linenos">525</span></a>		<span class="s1">&#39;max_collisions&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>
</span><span id="L-526"><a href="#L-526"><span class="linenos">526</span></a>		<span class="s1">&#39;eval_mode&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
</span><span id="L-527"><a href="#L-527"><span class="linenos">527</span></a>		<span class="s1">&#39;seed&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>
</span><span id="L-528"><a href="#L-528"><span class="linenos">528</span></a>		<span class="s1">&#39;reward_type&#39;</span><span class="p">:</span> <span class="s1">&#39;uncertainty&#39;</span><span class="p">,</span>
</span><span id="L-529"><a href="#L-529"><span class="linenos">529</span></a>	<span class="p">}</span>
</span><span id="L-530"><a href="#L-530"><span class="linenos">530</span></a>
</span><span id="L-531"><a href="#L-531"><span class="linenos">531</span></a>	<span class="c1"># Create the environment #</span>
</span><span id="L-532"><a href="#L-532"><span class="linenos">532</span></a>	<span class="n">env</span> <span class="o">=</span> <span class="n">InformationGatheringEnv</span><span class="p">(</span><span class="n">env_config</span><span class="o">=</span><span class="n">env_config</span><span class="p">)</span>
</span><span id="L-533"><a href="#L-533"><span class="linenos">533</span></a>
</span><span id="L-534"><a href="#L-534"><span class="linenos">534</span></a>	<span class="n">state</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
</span><span id="L-535"><a href="#L-535"><span class="linenos">535</span></a>
</span><span id="L-536"><a href="#L-536"><span class="linenos">536</span></a>	<span class="n">dones</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span> <span class="kc">False</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">)}</span>
</span><span id="L-537"><a href="#L-537"><span class="linenos">537</span></a>	<span class="n">dones</span><span class="p">[</span><span class="s1">&#39;__all__&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="L-538"><a href="#L-538"><span class="linenos">538</span></a>
</span><span id="L-539"><a href="#L-539"><span class="linenos">539</span></a>	<span class="n">H</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="L-540"><a href="#L-540"><span class="linenos">540</span></a>	<span class="n">reg</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="L-541"><a href="#L-541"><span class="linenos">541</span></a>	<span class="n">rew</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="L-542"><a href="#L-542"><span class="linenos">542</span></a>
</span><span id="L-543"><a href="#L-543"><span class="linenos">543</span></a>	<span class="n">actions</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="L-544"><a href="#L-544"><span class="linenos">544</span></a>	<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
</span><span id="L-545"><a href="#L-545"><span class="linenos">545</span></a>		<span class="n">mask</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">get_action_mask</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
</span><span id="L-546"><a href="#L-546"><span class="linenos">546</span></a>		<span class="n">actions</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;number_of_actions&#39;</span><span class="p">]),</span> <span class="n">p</span><span class="o">=</span><span class="n">mask</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">mask</span><span class="p">))</span>
</span><span id="L-547"><a href="#L-547"><span class="linenos">547</span></a>
</span><span id="L-548"><a href="#L-548"><span class="linenos">548</span></a>	<span class="k">while</span> <span class="ow">not</span> <span class="n">dones</span><span class="p">[</span><span class="s1">&#39;__all__&#39;</span><span class="p">]:</span>
</span><span id="L-549"><a href="#L-549"><span class="linenos">549</span></a>
</span><span id="L-550"><a href="#L-550"><span class="linenos">550</span></a>		<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;&quot; ############################################################### &quot;&quot;&quot;</span><span class="p">)</span>
</span><span id="L-551"><a href="#L-551"><span class="linenos">551</span></a>		<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Action: &quot;</span><span class="p">,</span> <span class="n">actions</span><span class="p">)</span>
</span><span id="L-552"><a href="#L-552"><span class="linenos">552</span></a>
</span><span id="L-553"><a href="#L-553"><span class="linenos">553</span></a>		<span class="n">states</span><span class="p">,</span> <span class="n">rewards</span><span class="p">,</span> <span class="n">dones</span><span class="p">,</span> <span class="n">infos</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">({</span><span class="n">i</span><span class="p">:</span> <span class="n">actions</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">dones</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="k">if</span> <span class="p">(</span><span class="ow">not</span> <span class="n">dones</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">!=</span> <span class="s1">&#39;__all__&#39;</span><span class="p">})</span>
</span><span id="L-554"><a href="#L-554"><span class="linenos">554</span></a>
</span><span id="L-555"><a href="#L-555"><span class="linenos">555</span></a>		<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
</span><span id="L-556"><a href="#L-556"><span class="linenos">556</span></a>			<span class="n">mask</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">get_action_mask</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
</span><span id="L-557"><a href="#L-557"><span class="linenos">557</span></a>			<span class="k">if</span> <span class="ow">not</span> <span class="n">mask</span><span class="p">[</span><span class="n">actions</span><span class="p">[</span><span class="n">i</span><span class="p">]]:</span>
</span><span id="L-558"><a href="#L-558"><span class="linenos">558</span></a>				<span class="n">actions</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;number_of_actions&#39;</span><span class="p">]),</span> <span class="n">p</span><span class="o">=</span><span class="n">mask</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">mask</span><span class="p">))</span>
</span><span id="L-559"><a href="#L-559"><span class="linenos">559</span></a>
</span><span id="L-560"><a href="#L-560"><span class="linenos">560</span></a>
</span><span id="L-561"><a href="#L-561"><span class="linenos">561</span></a>		<span class="n">H</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="mi">100</span><span class="o">*</span><span class="n">env</span><span class="o">.</span><span class="n">individual_uncertainty_decrement</span><span class="o">/</span><span class="n">env</span><span class="o">.</span><span class="n">uncertainty_0</span><span class="p">))</span>
</span><span id="L-562"><a href="#L-562"><span class="linenos">562</span></a>		<span class="n">reg</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">last_measurement_values</span><span class="p">))</span>
</span><span id="L-563"><a href="#L-563"><span class="linenos">563</span></a>		<span class="n">rew</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="mi">100</span><span class="o">*</span><span class="n">env</span><span class="o">.</span><span class="n">individual_uncertainty_decrement</span><span class="o">*</span><span class="p">(</span><span class="n">env</span><span class="o">.</span><span class="n">last_measurement_values</span><span class="p">)</span><span class="o">/</span><span class="n">env</span><span class="o">.</span><span class="n">uncertainty_0</span><span class="p">))</span>
</span><span id="L-564"><a href="#L-564"><span class="linenos">564</span></a>
</span><span id="L-565"><a href="#L-565"><span class="linenos">565</span></a>		<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;States: &quot;</span><span class="p">,</span> <span class="n">states</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
</span><span id="L-566"><a href="#L-566"><span class="linenos">566</span></a>		<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Rewards: &quot;</span><span class="p">,</span> <span class="n">rewards</span><span class="p">)</span>
</span><span id="L-567"><a href="#L-567"><span class="linenos">567</span></a>		<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Dones: &quot;</span><span class="p">,</span> <span class="n">dones</span><span class="p">)</span>
</span><span id="L-568"><a href="#L-568"><span class="linenos">568</span></a>		<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Info: &quot;</span><span class="p">,</span> <span class="n">infos</span><span class="p">)</span>
</span><span id="L-569"><a href="#L-569"><span class="linenos">569</span></a>		<span class="n">env</span><span class="o">.</span><span class="n">render</span><span class="p">()</span>
</span><span id="L-570"><a href="#L-570"><span class="linenos">570</span></a>
</span><span id="L-571"><a href="#L-571"><span class="linenos">571</span></a>
</span><span id="L-572"><a href="#L-572"><span class="linenos">572</span></a>	<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Finished!&quot;</span><span class="p">)</span>
</span><span id="L-573"><a href="#L-573"><span class="linenos">573</span></a>	<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">block</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="L-574"><a href="#L-574"><span class="linenos">574</span></a>
</span><span id="L-575"><a href="#L-575"><span class="linenos">575</span></a>	<span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="s1">&#39;seaborn-whitegrid&#39;</span><span class="p">):</span>
</span><span id="L-576"><a href="#L-576"><span class="linenos">576</span></a>		<span class="n">_</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">sharex</span><span class="o">=</span><span class="s1">&#39;all&#39;</span><span class="p">)</span>
</span><span id="L-577"><a href="#L-577"><span class="linenos">577</span></a>
</span><span id="L-578"><a href="#L-578"><span class="linenos">578</span></a>		<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Uncertainty&#39;</span><span class="p">)</span>
</span><span id="L-579"><a href="#L-579"><span class="linenos">579</span></a>		<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</span><span id="L-580"><a href="#L-580"><span class="linenos">580</span></a>		<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Value&#39;</span><span class="p">)</span>
</span><span id="L-581"><a href="#L-581"><span class="linenos">581</span></a>		<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">reg</span><span class="p">,</span> <span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</span><span id="L-582"><a href="#L-582"><span class="linenos">582</span></a>		<span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Reward&#39;</span><span class="p">)</span>
</span><span id="L-583"><a href="#L-583"><span class="linenos">583</span></a>		<span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">rew</span><span class="p">,</span> <span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</span><span id="L-584"><a href="#L-584"><span class="linenos">584</span></a>
</span><span id="L-585"><a href="#L-585"><span class="linenos">585</span></a>	<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="n">block</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></pre></div>


            </section>
                <section id="InformationGatheringEnv">
                            <input id="InformationGatheringEnv-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr class">
            
    <span class="def">class</span>
    <span class="name">InformationGatheringEnv</span><wbr>(<span class="base">ray.rllib.env.multi_agent_env.MultiAgentEnv</span>):

                <label class="view-source-button" for="InformationGatheringEnv-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#InformationGatheringEnv"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="InformationGatheringEnv-17"><a href="#InformationGatheringEnv-17"><span class="linenos"> 17</span></a><span class="k">class</span> <span class="nc">InformationGatheringEnv</span><span class="p">(</span><span class="n">MultiAgentEnv</span><span class="p">):</span>
</span><span id="InformationGatheringEnv-18"><a href="#InformationGatheringEnv-18"><span class="linenos"> 18</span></a>
</span><span id="InformationGatheringEnv-19"><a href="#InformationGatheringEnv-19"><span class="linenos"> 19</span></a>	<span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env_config</span><span class="p">:</span> <span class="nb">dict</span><span class="p">):</span>
</span><span id="InformationGatheringEnv-20"><a href="#InformationGatheringEnv-20"><span class="linenos"> 20</span></a>
</span><span id="InformationGatheringEnv-21"><a href="#InformationGatheringEnv-21"><span class="linenos"> 21</span></a>		<span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="InformationGatheringEnv-22"><a href="#InformationGatheringEnv-22"><span class="linenos"> 22</span></a>
</span><span id="InformationGatheringEnv-23"><a href="#InformationGatheringEnv-23"><span class="linenos"> 23</span></a>		<span class="c1"># Environment configuration dictionary</span>
</span><span id="InformationGatheringEnv-24"><a href="#InformationGatheringEnv-24"><span class="linenos"> 24</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">env_config</span> <span class="o">=</span> <span class="n">env_config</span>
</span><span id="InformationGatheringEnv-25"><a href="#InformationGatheringEnv-25"><span class="linenos"> 25</span></a>
</span><span id="InformationGatheringEnv-26"><a href="#InformationGatheringEnv-26"><span class="linenos"> 26</span></a>		<span class="c1"># Create a fleet of N vehicles #</span>
</span><span id="InformationGatheringEnv-27"><a href="#InformationGatheringEnv-27"><span class="linenos"> 27</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">fleet</span> <span class="o">=</span> <span class="n">Fleet</span><span class="p">(</span><span class="n">fleet_configuration</span><span class="o">=</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;fleet_configuration&#39;</span><span class="p">])</span>
</span><span id="InformationGatheringEnv-28"><a href="#InformationGatheringEnv-28"><span class="linenos"> 28</span></a>		<span class="c1"># Save the number of agents #</span>
</span><span id="InformationGatheringEnv-29"><a href="#InformationGatheringEnv-29"><span class="linenos"> 29</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">number_of_agents</span> <span class="o">=</span> <span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;fleet_configuration&#39;</span><span class="p">][</span><span class="s1">&#39;number_of_vehicles&#39;</span><span class="p">]</span>
</span><span id="InformationGatheringEnv-30"><a href="#InformationGatheringEnv-30"><span class="linenos"> 30</span></a>		<span class="c1"># Save the agents ids #</span>
</span><span id="InformationGatheringEnv-31"><a href="#InformationGatheringEnv-31"><span class="linenos"> 31</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">agents_ids</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">number_of_agents</span><span class="p">))</span>
</span><span id="InformationGatheringEnv-32"><a href="#InformationGatheringEnv-32"><span class="linenos"> 32</span></a>		<span class="c1"># Create a set of agents IDs - This is required for the RLLIB MA Environment class #</span>
</span><span id="InformationGatheringEnv-33"><a href="#InformationGatheringEnv-33"><span class="linenos"> 33</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">_agent_ids</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">number_of_agents</span><span class="p">))</span>
</span><span id="InformationGatheringEnv-34"><a href="#InformationGatheringEnv-34"><span class="linenos"> 34</span></a>
</span><span id="InformationGatheringEnv-35"><a href="#InformationGatheringEnv-35"><span class="linenos"> 35</span></a>		<span class="c1"># Define the observation space and the action space #</span>
</span><span id="InformationGatheringEnv-36"><a href="#InformationGatheringEnv-36"><span class="linenos"> 36</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">observation_type</span> <span class="o">=</span> <span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;observation_type&#39;</span><span class="p">]</span>
</span><span id="InformationGatheringEnv-37"><a href="#InformationGatheringEnv-37"><span class="linenos"> 37</span></a>
</span><span id="InformationGatheringEnv-38"><a href="#InformationGatheringEnv-38"><span class="linenos"> 38</span></a>		<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">observation_type</span> <span class="o">==</span> <span class="s1">&#39;visual&#39;</span><span class="p">:</span>
</span><span id="InformationGatheringEnv-39"><a href="#InformationGatheringEnv-39"><span class="linenos"> 39</span></a>			<span class="c1"># The visual observation space is defined as 5 images:</span>
</span><span id="InformationGatheringEnv-40"><a href="#InformationGatheringEnv-40"><span class="linenos"> 40</span></a>			<span class="c1"># - The navigation map</span>
</span><span id="InformationGatheringEnv-41"><a href="#InformationGatheringEnv-41"><span class="linenos"> 41</span></a>			<span class="c1"># - The observer position on the map</span>
</span><span id="InformationGatheringEnv-42"><a href="#InformationGatheringEnv-42"><span class="linenos"> 42</span></a>			<span class="c1"># - The other vehicles positions on the map</span>
</span><span id="InformationGatheringEnv-43"><a href="#InformationGatheringEnv-43"><span class="linenos"> 43</span></a>			<span class="c1"># - The mu of the model</span>
</span><span id="InformationGatheringEnv-44"><a href="#InformationGatheringEnv-44"><span class="linenos"> 44</span></a>			<span class="c1"># - The uncertainty of the model</span>
</span><span id="InformationGatheringEnv-45"><a href="#InformationGatheringEnv-45"><span class="linenos"> 45</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">observation_space</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Box</span><span class="p">(</span><span class="n">low</span><span class="o">=-</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="o">*</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;navigation_map&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
</span><span id="InformationGatheringEnv-46"><a href="#InformationGatheringEnv-46"><span class="linenos"> 46</span></a>		<span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">observation_type</span> <span class="o">==</span> <span class="s1">&#39;hybrid&#39;</span><span class="p">:</span>
</span><span id="InformationGatheringEnv-47"><a href="#InformationGatheringEnv-47"><span class="linenos"> 47</span></a>			<span class="c1"># The hybrid state is its position [x,y] and 3 images [fleet positions, mean-model, uncertainty] #</span>
</span><span id="InformationGatheringEnv-48"><a href="#InformationGatheringEnv-48"><span class="linenos"> 48</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">observation_space</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Dict</span><span class="p">({</span><span class="s1">&#39;visual_state&#39;</span><span class="p">:</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Box</span><span class="p">(</span><span class="n">low</span><span class="o">=-</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="o">*</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;navigation_map&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)),</span>
</span><span id="InformationGatheringEnv-49"><a href="#InformationGatheringEnv-49"><span class="linenos"> 49</span></a>			                                          <span class="s1">&#39;odometry&#39;</span><span class="p">:</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Box</span><span class="p">(</span><span class="n">low</span><span class="o">=-</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,))})</span>
</span><span id="InformationGatheringEnv-50"><a href="#InformationGatheringEnv-50"><span class="linenos"> 50</span></a>		<span class="k">else</span><span class="p">:</span>
</span><span id="InformationGatheringEnv-51"><a href="#InformationGatheringEnv-51"><span class="linenos"> 51</span></a>			<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s1">&#39;This observation type is not defined. Pleas choose between: visual / hybrid&#39;</span><span class="p">)</span>
</span><span id="InformationGatheringEnv-52"><a href="#InformationGatheringEnv-52"><span class="linenos"> 52</span></a>
</span><span id="InformationGatheringEnv-53"><a href="#InformationGatheringEnv-53"><span class="linenos"> 53</span></a>		<span class="c1"># Define the type of the action #</span>
</span><span id="InformationGatheringEnv-54"><a href="#InformationGatheringEnv-54"><span class="linenos"> 54</span></a>		<span class="k">if</span> <span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;movement_type&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;DIRECTIONAL&#39;</span><span class="p">:</span>
</span><span id="InformationGatheringEnv-55"><a href="#InformationGatheringEnv-55"><span class="linenos"> 55</span></a>			<span class="c1"># The action space is a discrete action space with number_of_actions actions:</span>
</span><span id="InformationGatheringEnv-56"><a href="#InformationGatheringEnv-56"><span class="linenos"> 56</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">action_space</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Discrete</span><span class="p">(</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;number_of_actions&#39;</span><span class="p">])</span>
</span><span id="InformationGatheringEnv-57"><a href="#InformationGatheringEnv-57"><span class="linenos"> 57</span></a>		<span class="k">elif</span> <span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;movement_type&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;DIRECTIONAL_DISTANCE&#39;</span><span class="p">:</span>
</span><span id="InformationGatheringEnv-58"><a href="#InformationGatheringEnv-58"><span class="linenos"> 58</span></a>			<span class="c1"># This action is defined with the direction and the distance to move (both normalized between -1 and 1) #</span>
</span><span id="InformationGatheringEnv-59"><a href="#InformationGatheringEnv-59"><span class="linenos"> 59</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">action_space</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Box</span><span class="p">(</span><span class="n">low</span><span class="o">=-</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,))</span>
</span><span id="InformationGatheringEnv-60"><a href="#InformationGatheringEnv-60"><span class="linenos"> 60</span></a>		<span class="k">else</span><span class="p">:</span>
</span><span id="InformationGatheringEnv-61"><a href="#InformationGatheringEnv-61"><span class="linenos"> 61</span></a>			<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s1">&#39;This movement type is not defined. Pleas choose between: DIRECTIONAL / DIRECTIONAL+DISTANCE&#39;</span><span class="p">)</span>
</span><span id="InformationGatheringEnv-62"><a href="#InformationGatheringEnv-62"><span class="linenos"> 62</span></a>
</span><span id="InformationGatheringEnv-63"><a href="#InformationGatheringEnv-63"><span class="linenos"> 63</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">measurements</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># Measurements of the environment (Usually a dictionary)</span>
</span><span id="InformationGatheringEnv-64"><a href="#InformationGatheringEnv-64"><span class="linenos"> 64</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">resetted</span> <span class="o">=</span> <span class="kc">False</span>  <span class="c1"># Flag to check if the environment has been resetted #</span>
</span><span id="InformationGatheringEnv-65"><a href="#InformationGatheringEnv-65"><span class="linenos"> 65</span></a>
</span><span id="InformationGatheringEnv-66"><a href="#InformationGatheringEnv-66"><span class="linenos"> 66</span></a>		<span class="c1"># Gym Environment variables #</span>
</span><span id="InformationGatheringEnv-67"><a href="#InformationGatheringEnv-67"><span class="linenos"> 67</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">rewards</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="InformationGatheringEnv-68"><a href="#InformationGatheringEnv-68"><span class="linenos"> 68</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">states</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="InformationGatheringEnv-69"><a href="#InformationGatheringEnv-69"><span class="linenos"> 69</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">infos</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="InformationGatheringEnv-70"><a href="#InformationGatheringEnv-70"><span class="linenos"> 70</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">dones</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="InformationGatheringEnv-71"><a href="#InformationGatheringEnv-71"><span class="linenos"> 71</span></a>
</span><span id="InformationGatheringEnv-72"><a href="#InformationGatheringEnv-72"><span class="linenos"> 72</span></a>		<span class="c1"># Ground truth - The task to solve #</span>
</span><span id="InformationGatheringEnv-73"><a href="#InformationGatheringEnv-73"><span class="linenos"> 73</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">random_benchmark</span> <span class="o">=</span> <span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;random_benchmark&#39;</span><span class="p">]</span>
</span><span id="InformationGatheringEnv-74"><a href="#InformationGatheringEnv-74"><span class="linenos"> 74</span></a>		<span class="k">if</span> <span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;dynamic&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;OilSpillEnv&#39;</span><span class="p">:</span>
</span><span id="InformationGatheringEnv-75"><a href="#InformationGatheringEnv-75"><span class="linenos"> 75</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">ground_truth</span> <span class="o">=</span> <span class="n">OilSpillEnv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;navigation_map&#39;</span><span class="p">],</span> <span class="n">dt</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">flow</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">kc</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">kw</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;seed&#39;</span><span class="p">])</span>
</span><span id="InformationGatheringEnv-76"><a href="#InformationGatheringEnv-76"><span class="linenos"> 76</span></a>		<span class="k">elif</span> <span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;dynamic&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;Shekel&#39;</span><span class="p">:</span>
</span><span id="InformationGatheringEnv-77"><a href="#InformationGatheringEnv-77"><span class="linenos"> 77</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">ground_truth</span> <span class="o">=</span> <span class="n">Shekel</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;navigation_map&#39;</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="n">max_number_of_peaks</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">is_bounded</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;seed&#39;</span><span class="p">])</span>
</span><span id="InformationGatheringEnv-78"><a href="#InformationGatheringEnv-78"><span class="linenos"> 78</span></a>		<span class="k">else</span><span class="p">:</span>
</span><span id="InformationGatheringEnv-79"><a href="#InformationGatheringEnv-79"><span class="linenos"> 79</span></a>			<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;This benchmark is not implemented&quot;</span><span class="p">)</span>
</span><span id="InformationGatheringEnv-80"><a href="#InformationGatheringEnv-80"><span class="linenos"> 80</span></a>
</span><span id="InformationGatheringEnv-81"><a href="#InformationGatheringEnv-81"><span class="linenos"> 81</span></a>		<span class="c1"># [N x 2] matrix with all the possible visitable positions #</span>
</span><span id="InformationGatheringEnv-82"><a href="#InformationGatheringEnv-82"><span class="linenos"> 82</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">visitable_positions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;navigation_map&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">))</span>
</span><span id="InformationGatheringEnv-83"><a href="#InformationGatheringEnv-83"><span class="linenos"> 83</span></a>
</span><span id="InformationGatheringEnv-84"><a href="#InformationGatheringEnv-84"><span class="linenos"> 84</span></a>		<span class="c1"># ---- Parameters of the model (Gaussian Process) ---- #</span>
</span><span id="InformationGatheringEnv-85"><a href="#InformationGatheringEnv-85"><span class="linenos"> 85</span></a>		<span class="c1"># Kernel for model-conditioning #</span>
</span><span id="InformationGatheringEnv-86"><a href="#InformationGatheringEnv-86"><span class="linenos"> 86</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">kernel</span> <span class="o">=</span> <span class="n">RBF</span><span class="p">(</span><span class="n">length_scale</span><span class="o">=</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;kernel_length_scale&#39;</span><span class="p">],</span> <span class="n">length_scale_bounds</span><span class="o">=</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">))</span>
</span><span id="InformationGatheringEnv-87"><a href="#InformationGatheringEnv-87"><span class="linenos"> 87</span></a>		<span class="c1"># The Gaussian Process #</span>
</span><span id="InformationGatheringEnv-88"><a href="#InformationGatheringEnv-88"><span class="linenos"> 88</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">GaussianProcess</span> <span class="o">=</span> <span class="n">GaussianProcessRegressor</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">n_restarts_optimizer</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</span><span id="InformationGatheringEnv-89"><a href="#InformationGatheringEnv-89"><span class="linenos"> 89</span></a>		<span class="c1"># The list of measured values (y in GP)</span>
</span><span id="InformationGatheringEnv-90"><a href="#InformationGatheringEnv-90"><span class="linenos"> 90</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">measured_values</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="InformationGatheringEnv-91"><a href="#InformationGatheringEnv-91"><span class="linenos"> 91</span></a>		<span class="c1"># The list of measured positions (x in GP)</span>
</span><span id="InformationGatheringEnv-92"><a href="#InformationGatheringEnv-92"><span class="linenos"> 92</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">measured_locations</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="InformationGatheringEnv-93"><a href="#InformationGatheringEnv-93"><span class="linenos"> 93</span></a>
</span><span id="InformationGatheringEnv-94"><a href="#InformationGatheringEnv-94"><span class="linenos"> 94</span></a>		<span class="c1"># The surrogate model #</span>
</span><span id="InformationGatheringEnv-95"><a href="#InformationGatheringEnv-95"><span class="linenos"> 95</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">mu</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="InformationGatheringEnv-96"><a href="#InformationGatheringEnv-96"><span class="linenos"> 96</span></a>		<span class="c1"># The surrogate uncertainty #</span>
</span><span id="InformationGatheringEnv-97"><a href="#InformationGatheringEnv-97"><span class="linenos"> 97</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">uncertainty</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="InformationGatheringEnv-98"><a href="#InformationGatheringEnv-98"><span class="linenos"> 98</span></a>
</span><span id="InformationGatheringEnv-99"><a href="#InformationGatheringEnv-99"><span class="linenos"> 99</span></a>		<span class="c1"># Array of the last measurements of every agent (to compute the reward) #</span>
</span><span id="InformationGatheringEnv-100"><a href="#InformationGatheringEnv-100"><span class="linenos">100</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">last_measurement_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.0</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">number_of_agents</span><span class="p">)])</span>
</span><span id="InformationGatheringEnv-101"><a href="#InformationGatheringEnv-101"><span class="linenos">101</span></a>		<span class="c1"># The contribution of every agent to the uncertainty decrement (to compute the reward)#</span>
</span><span id="InformationGatheringEnv-102"><a href="#InformationGatheringEnv-102"><span class="linenos">102</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">intermediate_uncertainty_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">visitable_positions</span><span class="p">),))</span>
</span><span id="InformationGatheringEnv-103"><a href="#InformationGatheringEnv-103"><span class="linenos">103</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">individual_uncertainty_decrement</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.0</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">number_of_agents</span><span class="p">)])</span>
</span><span id="InformationGatheringEnv-104"><a href="#InformationGatheringEnv-104"><span class="linenos">104</span></a>		<span class="c1"># The error of the model #</span>
</span><span id="InformationGatheringEnv-105"><a href="#InformationGatheringEnv-105"><span class="linenos">105</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">mse</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="InformationGatheringEnv-106"><a href="#InformationGatheringEnv-106"><span class="linenos">106</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">mse_ant</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="InformationGatheringEnv-107"><a href="#InformationGatheringEnv-107"><span class="linenos">107</span></a>
</span><span id="InformationGatheringEnv-108"><a href="#InformationGatheringEnv-108"><span class="linenos">108</span></a>		<span class="c1"># For the collision computation #</span>
</span><span id="InformationGatheringEnv-109"><a href="#InformationGatheringEnv-109"><span class="linenos">109</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">number_of_collisions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">number_of_agents</span><span class="p">,))</span>
</span><span id="InformationGatheringEnv-110"><a href="#InformationGatheringEnv-110"><span class="linenos">110</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">max_collisions</span> <span class="o">=</span> <span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;max_collisions&#39;</span><span class="p">]</span>
</span><span id="InformationGatheringEnv-111"><a href="#InformationGatheringEnv-111"><span class="linenos">111</span></a>
</span><span id="InformationGatheringEnv-112"><a href="#InformationGatheringEnv-112"><span class="linenos">112</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">_eval</span> <span class="o">=</span> <span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;eval_mode&#39;</span><span class="p">]</span>
</span><span id="InformationGatheringEnv-113"><a href="#InformationGatheringEnv-113"><span class="linenos">113</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">fig</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="InformationGatheringEnv-114"><a href="#InformationGatheringEnv-114"><span class="linenos">114</span></a>
</span><span id="InformationGatheringEnv-115"><a href="#InformationGatheringEnv-115"><span class="linenos">115</span></a>	<span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
</span><span id="InformationGatheringEnv-116"><a href="#InformationGatheringEnv-116"><span class="linenos">116</span></a>		<span class="sd">&quot;&quot;&quot; Reset all the variables and the fleet. This method must be called before the first step of the episode.</span>
</span><span id="InformationGatheringEnv-117"><a href="#InformationGatheringEnv-117"><span class="linenos">117</span></a><span class="sd">		It resets the fleet position, the measurements, the ground truth, the surrogate model and the uncertainty.</span>
</span><span id="InformationGatheringEnv-118"><a href="#InformationGatheringEnv-118"><span class="linenos">118</span></a>
</span><span id="InformationGatheringEnv-119"><a href="#InformationGatheringEnv-119"><span class="linenos">119</span></a><span class="sd">		:return:</span>
</span><span id="InformationGatheringEnv-120"><a href="#InformationGatheringEnv-120"><span class="linenos">120</span></a><span class="sd">			The initial observation of the environment in a dictionary of agents.</span>
</span><span id="InformationGatheringEnv-121"><a href="#InformationGatheringEnv-121"><span class="linenos">121</span></a>
</span><span id="InformationGatheringEnv-122"><a href="#InformationGatheringEnv-122"><span class="linenos">122</span></a><span class="sd">		&quot;&quot;&quot;</span>
</span><span id="InformationGatheringEnv-123"><a href="#InformationGatheringEnv-123"><span class="linenos">123</span></a>
</span><span id="InformationGatheringEnv-124"><a href="#InformationGatheringEnv-124"><span class="linenos">124</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">resetted</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="InformationGatheringEnv-125"><a href="#InformationGatheringEnv-125"><span class="linenos">125</span></a>
</span><span id="InformationGatheringEnv-126"><a href="#InformationGatheringEnv-126"><span class="linenos">126</span></a>		<span class="c1"># Reset the dones #</span>
</span><span id="InformationGatheringEnv-127"><a href="#InformationGatheringEnv-127"><span class="linenos">127</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">dones</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span> <span class="kc">False</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">number_of_agents</span><span class="p">)}</span>
</span><span id="InformationGatheringEnv-128"><a href="#InformationGatheringEnv-128"><span class="linenos">128</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">dones</span><span class="p">[</span><span class="s1">&#39;__all__&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="InformationGatheringEnv-129"><a href="#InformationGatheringEnv-129"><span class="linenos">129</span></a>
</span><span id="InformationGatheringEnv-130"><a href="#InformationGatheringEnv-130"><span class="linenos">130</span></a>		<span class="c1"># Reset the ground truth and update the ground truth (if the ground truth is dynamic) #</span>
</span><span id="InformationGatheringEnv-131"><a href="#InformationGatheringEnv-131"><span class="linenos">131</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">ground_truth</span><span class="o">.</span><span class="n">reset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_benchmark</span><span class="p">)</span>
</span><span id="InformationGatheringEnv-132"><a href="#InformationGatheringEnv-132"><span class="linenos">132</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">update_vehicles_ground_truths</span><span class="p">()</span>
</span><span id="InformationGatheringEnv-133"><a href="#InformationGatheringEnv-133"><span class="linenos">133</span></a>
</span><span id="InformationGatheringEnv-134"><a href="#InformationGatheringEnv-134"><span class="linenos">134</span></a>		<span class="c1"># Reset the model parameters#</span>
</span><span id="InformationGatheringEnv-135"><a href="#InformationGatheringEnv-135"><span class="linenos">135</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">measured_locations</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="InformationGatheringEnv-136"><a href="#InformationGatheringEnv-136"><span class="linenos">136</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">measured_values</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="InformationGatheringEnv-137"><a href="#InformationGatheringEnv-137"><span class="linenos">137</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">mu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;navigation_map&#39;</span><span class="p">])</span>
</span><span id="InformationGatheringEnv-138"><a href="#InformationGatheringEnv-138"><span class="linenos">138</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">uncertainty</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;navigation_map&#39;</span><span class="p">])</span>
</span><span id="InformationGatheringEnv-139"><a href="#InformationGatheringEnv-139"><span class="linenos">139</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">number_of_collisions</span><span class="p">[:]</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="InformationGatheringEnv-140"><a href="#InformationGatheringEnv-140"><span class="linenos">140</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">mse_ant</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="InformationGatheringEnv-141"><a href="#InformationGatheringEnv-141"><span class="linenos">141</span></a>
</span><span id="InformationGatheringEnv-142"><a href="#InformationGatheringEnv-142"><span class="linenos">142</span></a>		<span class="c1"># Reset the fleet and take the first measurements #</span>
</span><span id="InformationGatheringEnv-143"><a href="#InformationGatheringEnv-143"><span class="linenos">143</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">measurements</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fleet</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
</span><span id="InformationGatheringEnv-144"><a href="#InformationGatheringEnv-144"><span class="linenos">144</span></a>
</span><span id="InformationGatheringEnv-145"><a href="#InformationGatheringEnv-145"><span class="linenos">145</span></a>		<span class="c1"># Update the model with the initial values #</span>
</span><span id="InformationGatheringEnv-146"><a href="#InformationGatheringEnv-146"><span class="linenos">146</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">last_measurement_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.0</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">number_of_agents</span><span class="p">)])</span>
</span><span id="InformationGatheringEnv-147"><a href="#InformationGatheringEnv-147"><span class="linenos">147</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">intermediate_uncertainty_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">visitable_positions</span><span class="p">),))</span>
</span><span id="InformationGatheringEnv-148"><a href="#InformationGatheringEnv-148"><span class="linenos">148</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">individual_uncertainty_decrement</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.0</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">number_of_agents</span><span class="p">)])</span>
</span><span id="InformationGatheringEnv-149"><a href="#InformationGatheringEnv-149"><span class="linenos">149</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">uncertainty</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">update_model</span><span class="p">(</span><span class="n">new_measurements</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">measurements</span><span class="p">)</span>
</span><span id="InformationGatheringEnv-150"><a href="#InformationGatheringEnv-150"><span class="linenos">150</span></a>
</span><span id="InformationGatheringEnv-151"><a href="#InformationGatheringEnv-151"><span class="linenos">151</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">uncertainty_0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">uncertainty</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</span><span id="InformationGatheringEnv-152"><a href="#InformationGatheringEnv-152"><span class="linenos">152</span></a>
</span><span id="InformationGatheringEnv-153"><a href="#InformationGatheringEnv-153"><span class="linenos">153</span></a>		<span class="c1"># Update the state</span>
</span><span id="InformationGatheringEnv-154"><a href="#InformationGatheringEnv-154"><span class="linenos">154</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">process_states</span><span class="p">()</span>
</span><span id="InformationGatheringEnv-155"><a href="#InformationGatheringEnv-155"><span class="linenos">155</span></a>
</span><span id="InformationGatheringEnv-156"><a href="#InformationGatheringEnv-156"><span class="linenos">156</span></a>		<span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">states</span>
</span><span id="InformationGatheringEnv-157"><a href="#InformationGatheringEnv-157"><span class="linenos">157</span></a>
</span><span id="InformationGatheringEnv-158"><a href="#InformationGatheringEnv-158"><span class="linenos">158</span></a>	<span class="k">def</span> <span class="nf">eval</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="InformationGatheringEnv-159"><a href="#InformationGatheringEnv-159"><span class="linenos">159</span></a>		<span class="sd">&quot;&quot;&quot; Change the environment to evaluation mode. In this mode,</span>
</span><span id="InformationGatheringEnv-160"><a href="#InformationGatheringEnv-160"><span class="linenos">160</span></a><span class="sd">		computationally expensive operations are enabled for evaluation. &quot;&quot;&quot;</span>
</span><span id="InformationGatheringEnv-161"><a href="#InformationGatheringEnv-161"><span class="linenos">161</span></a>
</span><span id="InformationGatheringEnv-162"><a href="#InformationGatheringEnv-162"><span class="linenos">162</span></a>		<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Environment in eval mode!&quot;</span><span class="p">)</span>
</span><span id="InformationGatheringEnv-163"><a href="#InformationGatheringEnv-163"><span class="linenos">163</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">_eval</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="InformationGatheringEnv-164"><a href="#InformationGatheringEnv-164"><span class="linenos">164</span></a>
</span><span id="InformationGatheringEnv-165"><a href="#InformationGatheringEnv-165"><span class="linenos">165</span></a>	<span class="k">def</span> <span class="nf">update_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_measurements</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span> <span class="n">agents_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
</span><span id="InformationGatheringEnv-166"><a href="#InformationGatheringEnv-166"><span class="linenos">166</span></a>		<span class="sd">&quot;&quot;&quot;</span>
</span><span id="InformationGatheringEnv-167"><a href="#InformationGatheringEnv-167"><span class="linenos">167</span></a><span class="sd">		Fit the gaussian process using the new_measurements and return a new inferred map and its uncertainty.</span>
</span><span id="InformationGatheringEnv-168"><a href="#InformationGatheringEnv-168"><span class="linenos">168</span></a><span class="sd">		The process will update the gaussian model sequentially for each agent in *agents_ids*.</span>
</span><span id="InformationGatheringEnv-169"><a href="#InformationGatheringEnv-169"><span class="linenos">169</span></a>
</span><span id="InformationGatheringEnv-170"><a href="#InformationGatheringEnv-170"><span class="linenos">170</span></a>
</span><span id="InformationGatheringEnv-171"><a href="#InformationGatheringEnv-171"><span class="linenos">171</span></a><span class="sd">		:param new_measurements: The new measurements to fit the model with in a dictionary.</span>
</span><span id="InformationGatheringEnv-172"><a href="#InformationGatheringEnv-172"><span class="linenos">172</span></a><span class="sd">		:param agents_ids: The ids of those agents that generated the measurements. If None, all the agents will be updated.</span>
</span><span id="InformationGatheringEnv-173"><a href="#InformationGatheringEnv-173"><span class="linenos">173</span></a>
</span><span id="InformationGatheringEnv-174"><a href="#InformationGatheringEnv-174"><span class="linenos">174</span></a><span class="sd">		:return:</span>
</span><span id="InformationGatheringEnv-175"><a href="#InformationGatheringEnv-175"><span class="linenos">175</span></a><span class="sd">			- mu - The new inferred map mu.</span>
</span><span id="InformationGatheringEnv-176"><a href="#InformationGatheringEnv-176"><span class="linenos">176</span></a><span class="sd">			- sigma - The new inferred uncertainty sigma.</span>
</span><span id="InformationGatheringEnv-177"><a href="#InformationGatheringEnv-177"><span class="linenos">177</span></a>
</span><span id="InformationGatheringEnv-178"><a href="#InformationGatheringEnv-178"><span class="linenos">178</span></a><span class="sd">		&quot;&quot;&quot;</span>
</span><span id="InformationGatheringEnv-179"><a href="#InformationGatheringEnv-179"><span class="linenos">179</span></a>
</span><span id="InformationGatheringEnv-180"><a href="#InformationGatheringEnv-180"><span class="linenos">180</span></a>		<span class="k">if</span> <span class="n">agents_ids</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="InformationGatheringEnv-181"><a href="#InformationGatheringEnv-181"><span class="linenos">181</span></a>			<span class="n">agents_ids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">agents_ids</span>
</span><span id="InformationGatheringEnv-182"><a href="#InformationGatheringEnv-182"><span class="linenos">182</span></a>		<span class="k">else</span><span class="p">:</span>
</span><span id="InformationGatheringEnv-183"><a href="#InformationGatheringEnv-183"><span class="linenos">183</span></a>			<span class="n">new_measurements</span> <span class="o">=</span> <span class="p">[</span><span class="n">new_measurements</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">agents_ids</span><span class="p">]</span>
</span><span id="InformationGatheringEnv-184"><a href="#InformationGatheringEnv-184"><span class="linenos">184</span></a>
</span><span id="InformationGatheringEnv-185"><a href="#InformationGatheringEnv-185"><span class="linenos">185</span></a>		<span class="n">shufled_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">agents_ids</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">agents_ids</span><span class="p">))))</span>
</span><span id="InformationGatheringEnv-186"><a href="#InformationGatheringEnv-186"><span class="linenos">186</span></a>		<span class="n">shuffle</span><span class="p">(</span><span class="n">shufled_list</span><span class="p">)</span>
</span><span id="InformationGatheringEnv-187"><a href="#InformationGatheringEnv-187"><span class="linenos">187</span></a>		<span class="k">for</span> <span class="n">agent_id</span><span class="p">,</span> <span class="n">measurement_id</span> <span class="ow">in</span> <span class="n">shufled_list</span><span class="p">:</span>
</span><span id="InformationGatheringEnv-188"><a href="#InformationGatheringEnv-188"><span class="linenos">188</span></a>			<span class="c1"># Sequentially update the model for each agent. #</span>
</span><span id="InformationGatheringEnv-189"><a href="#InformationGatheringEnv-189"><span class="linenos">189</span></a>
</span><span id="InformationGatheringEnv-190"><a href="#InformationGatheringEnv-190"><span class="linenos">190</span></a>			<span class="c1"># Append the data to the list of measurement locations and values #</span>
</span><span id="InformationGatheringEnv-191"><a href="#InformationGatheringEnv-191"><span class="linenos">191</span></a>			<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">measured_locations</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="InformationGatheringEnv-192"><a href="#InformationGatheringEnv-192"><span class="linenos">192</span></a>				<span class="bp">self</span><span class="o">.</span><span class="n">measured_locations</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="n">new_measurements</span><span class="p">[</span><span class="n">measurement_id</span><span class="p">][</span><span class="s1">&#39;position&#39;</span><span class="p">]])</span>
</span><span id="InformationGatheringEnv-193"><a href="#InformationGatheringEnv-193"><span class="linenos">193</span></a>				<span class="c1"># We compute the mean of the measurement-image #</span>
</span><span id="InformationGatheringEnv-194"><a href="#InformationGatheringEnv-194"><span class="linenos">194</span></a>				<span class="bp">self</span><span class="o">.</span><span class="n">measured_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">nanmean</span><span class="p">(</span><span class="n">new_measurements</span><span class="p">[</span><span class="n">measurement_id</span><span class="p">][</span><span class="s1">&#39;data&#39;</span><span class="p">])])</span>
</span><span id="InformationGatheringEnv-195"><a href="#InformationGatheringEnv-195"><span class="linenos">195</span></a>			<span class="k">else</span><span class="p">:</span>
</span><span id="InformationGatheringEnv-196"><a href="#InformationGatheringEnv-196"><span class="linenos">196</span></a>				<span class="bp">self</span><span class="o">.</span><span class="n">measured_locations</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">measured_locations</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="n">new_measurements</span><span class="p">[</span><span class="n">measurement_id</span><span class="p">][</span><span class="s1">&#39;position&#39;</span><span class="p">]])))</span>
</span><span id="InformationGatheringEnv-197"><a href="#InformationGatheringEnv-197"><span class="linenos">197</span></a>				<span class="bp">self</span><span class="o">.</span><span class="n">measured_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">measured_values</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">nanmean</span><span class="p">(</span><span class="n">new_measurements</span><span class="p">[</span><span class="n">measurement_id</span><span class="p">][</span><span class="s1">&#39;data&#39;</span><span class="p">])])))</span>
</span><span id="InformationGatheringEnv-198"><a href="#InformationGatheringEnv-198"><span class="linenos">198</span></a>
</span><span id="InformationGatheringEnv-199"><a href="#InformationGatheringEnv-199"><span class="linenos">199</span></a>			<span class="c1"># Store this last measured value #</span>
</span><span id="InformationGatheringEnv-200"><a href="#InformationGatheringEnv-200"><span class="linenos">200</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">last_measurement_values</span><span class="p">[</span><span class="n">agent_id</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">measured_values</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span><span id="InformationGatheringEnv-201"><a href="#InformationGatheringEnv-201"><span class="linenos">201</span></a>
</span><span id="InformationGatheringEnv-202"><a href="#InformationGatheringEnv-202"><span class="linenos">202</span></a>			<span class="c1"># Fit the gaussian process #</span>
</span><span id="InformationGatheringEnv-203"><a href="#InformationGatheringEnv-203"><span class="linenos">203</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">GaussianProcess</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">measured_locations</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">measured_values</span><span class="p">)</span>
</span><span id="InformationGatheringEnv-204"><a href="#InformationGatheringEnv-204"><span class="linenos">204</span></a>
</span><span id="InformationGatheringEnv-205"><a href="#InformationGatheringEnv-205"><span class="linenos">205</span></a>			<span class="c1"># Compute the mean and the std values for all the visitable positions #</span>
</span><span id="InformationGatheringEnv-206"><a href="#InformationGatheringEnv-206"><span class="linenos">206</span></a>			<span class="n">mu_array</span><span class="p">,</span> <span class="n">sigma_array</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">GaussianProcess</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">visitable_positions</span><span class="p">[:],</span> <span class="n">return_std</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="InformationGatheringEnv-207"><a href="#InformationGatheringEnv-207"><span class="linenos">207</span></a>
</span><span id="InformationGatheringEnv-208"><a href="#InformationGatheringEnv-208"><span class="linenos">208</span></a>			<span class="c1"># Compute the new mean error #</span>
</span><span id="InformationGatheringEnv-209"><a href="#InformationGatheringEnv-209"><span class="linenos">209</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">mse</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ground_truth</span><span class="o">.</span><span class="n">ground_truth_field</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">visitable_positions</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">visitable_positions</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">-</span> <span class="n">mu_array</span><span class="p">))</span>
</span><span id="InformationGatheringEnv-210"><a href="#InformationGatheringEnv-210"><span class="linenos">210</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">mse_ant</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mse</span>
</span><span id="InformationGatheringEnv-211"><a href="#InformationGatheringEnv-211"><span class="linenos">211</span></a>
</span><span id="InformationGatheringEnv-212"><a href="#InformationGatheringEnv-212"><span class="linenos">212</span></a>			<span class="c1"># Save the intermediate uncertainty maps for uncertainty credit assignment #</span>
</span><span id="InformationGatheringEnv-213"><a href="#InformationGatheringEnv-213"><span class="linenos">213</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">individual_uncertainty_decrement</span><span class="p">[</span><span class="n">agent_id</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">intermediate_uncertainty_values</span> <span class="o">-</span> <span class="n">sigma_array</span><span class="p">)</span>
</span><span id="InformationGatheringEnv-214"><a href="#InformationGatheringEnv-214"><span class="linenos">214</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">intermediate_uncertainty_values</span> <span class="o">=</span> <span class="n">sigma_array</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
</span><span id="InformationGatheringEnv-215"><a href="#InformationGatheringEnv-215"><span class="linenos">215</span></a>
</span><span id="InformationGatheringEnv-216"><a href="#InformationGatheringEnv-216"><span class="linenos">216</span></a>		<span class="c1"># Conform the map of the surrogate model for the state #</span>
</span><span id="InformationGatheringEnv-217"><a href="#InformationGatheringEnv-217"><span class="linenos">217</span></a>		<span class="n">mu_map</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;navigation_map&#39;</span><span class="p">])</span>
</span><span id="InformationGatheringEnv-218"><a href="#InformationGatheringEnv-218"><span class="linenos">218</span></a>		<span class="n">mu_map</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">visitable_positions</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span>
</span><span id="InformationGatheringEnv-219"><a href="#InformationGatheringEnv-219"><span class="linenos">219</span></a>		       <span class="bp">self</span><span class="o">.</span><span class="n">visitable_positions</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="n">mu_array</span>
</span><span id="InformationGatheringEnv-220"><a href="#InformationGatheringEnv-220"><span class="linenos">220</span></a>
</span><span id="InformationGatheringEnv-221"><a href="#InformationGatheringEnv-221"><span class="linenos">221</span></a>		<span class="n">uncertainty_map</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;navigation_map&#39;</span><span class="p">])</span>
</span><span id="InformationGatheringEnv-222"><a href="#InformationGatheringEnv-222"><span class="linenos">222</span></a>		<span class="n">uncertainty_map</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">visitable_positions</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span>
</span><span id="InformationGatheringEnv-223"><a href="#InformationGatheringEnv-223"><span class="linenos">223</span></a>		                <span class="bp">self</span><span class="o">.</span><span class="n">visitable_positions</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="n">sigma_array</span>
</span><span id="InformationGatheringEnv-224"><a href="#InformationGatheringEnv-224"><span class="linenos">224</span></a>
</span><span id="InformationGatheringEnv-225"><a href="#InformationGatheringEnv-225"><span class="linenos">225</span></a>		<span class="k">return</span> <span class="n">mu_map</span><span class="p">,</span> <span class="n">uncertainty_map</span>
</span><span id="InformationGatheringEnv-226"><a href="#InformationGatheringEnv-226"><span class="linenos">226</span></a>
</span><span id="InformationGatheringEnv-227"><a href="#InformationGatheringEnv-227"><span class="linenos">227</span></a>	<span class="k">def</span> <span class="nf">reward_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">collision_array</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span> <span class="n">agents_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
</span><span id="InformationGatheringEnv-228"><a href="#InformationGatheringEnv-228"><span class="linenos">228</span></a>		<span class="sd">&quot;&quot;&quot; The reward function is defined depending on the reward_type parameter</span>
</span><span id="InformationGatheringEnv-229"><a href="#InformationGatheringEnv-229"><span class="linenos">229</span></a><span class="sd">		1) &#39;uncertainty&#39;: the reward is merely the uncertainty decrement of each agent. This will serve for complete coverage</span>
</span><span id="InformationGatheringEnv-230"><a href="#InformationGatheringEnv-230"><span class="linenos">230</span></a><span class="sd">		2) &#39;regret&#39;: the reward is the decrement of uncertainty but weighted with the sampling value of each agent. This will serve for finding maxima</span>
</span><span id="InformationGatheringEnv-231"><a href="#InformationGatheringEnv-231"><span class="linenos">231</span></a><span class="sd">		3) &#39;error&#39;: the reward is the error between the ground truth and the inferred map. This is for characterization.</span>
</span><span id="InformationGatheringEnv-232"><a href="#InformationGatheringEnv-232"><span class="linenos">232</span></a>
</span><span id="InformationGatheringEnv-233"><a href="#InformationGatheringEnv-233"><span class="linenos">233</span></a><span class="sd">		:param collision_array: The collision array of the current state.</span>
</span><span id="InformationGatheringEnv-234"><a href="#InformationGatheringEnv-234"><span class="linenos">234</span></a><span class="sd">		:param agents_ids: The ids of those agents that are expecting the reward.</span>
</span><span id="InformationGatheringEnv-235"><a href="#InformationGatheringEnv-235"><span class="linenos">235</span></a>
</span><span id="InformationGatheringEnv-236"><a href="#InformationGatheringEnv-236"><span class="linenos">236</span></a><span class="sd">		:return:</span>
</span><span id="InformationGatheringEnv-237"><a href="#InformationGatheringEnv-237"><span class="linenos">237</span></a><span class="sd">			- reward: The reward for each agent in a dictionary.</span>
</span><span id="InformationGatheringEnv-238"><a href="#InformationGatheringEnv-238"><span class="linenos">238</span></a><span class="sd">		&quot;&quot;&quot;</span>
</span><span id="InformationGatheringEnv-239"><a href="#InformationGatheringEnv-239"><span class="linenos">239</span></a>
</span><span id="InformationGatheringEnv-240"><a href="#InformationGatheringEnv-240"><span class="linenos">240</span></a>		<span class="k">if</span> <span class="n">agents_ids</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="InformationGatheringEnv-241"><a href="#InformationGatheringEnv-241"><span class="linenos">241</span></a>			<span class="n">agents_ids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">agents_ids</span>
</span><span id="InformationGatheringEnv-242"><a href="#InformationGatheringEnv-242"><span class="linenos">242</span></a>
</span><span id="InformationGatheringEnv-243"><a href="#InformationGatheringEnv-243"><span class="linenos">243</span></a>		<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;reward_type&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;uncertainty&#39;</span><span class="p">:</span>
</span><span id="InformationGatheringEnv-244"><a href="#InformationGatheringEnv-244"><span class="linenos">244</span></a>			<span class="n">reward</span> <span class="o">=</span> <span class="mi">100</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">individual_uncertainty_decrement</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">uncertainty_0</span>
</span><span id="InformationGatheringEnv-245"><a href="#InformationGatheringEnv-245"><span class="linenos">245</span></a>		<span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;reward_type&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;improvement&#39;</span><span class="p">:</span>
</span><span id="InformationGatheringEnv-246"><a href="#InformationGatheringEnv-246"><span class="linenos">246</span></a>			<span class="n">reward</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">individual_uncertainty_decrement</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">last_measurement_values</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">uncertainty_0</span>
</span><span id="InformationGatheringEnv-247"><a href="#InformationGatheringEnv-247"><span class="linenos">247</span></a>		<span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;reward_type&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;error&#39;</span><span class="p">:</span>
</span><span id="InformationGatheringEnv-248"><a href="#InformationGatheringEnv-248"><span class="linenos">248</span></a>			<span class="n">reward</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">mse_ant</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">mse</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">number_of_agents</span><span class="p">)])</span>
</span><span id="InformationGatheringEnv-249"><a href="#InformationGatheringEnv-249"><span class="linenos">249</span></a>		<span class="k">else</span><span class="p">:</span>
</span><span id="InformationGatheringEnv-250"><a href="#InformationGatheringEnv-250"><span class="linenos">250</span></a>			<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Invalid reward type&quot;</span><span class="p">)</span>
</span><span id="InformationGatheringEnv-251"><a href="#InformationGatheringEnv-251"><span class="linenos">251</span></a>
</span><span id="InformationGatheringEnv-252"><a href="#InformationGatheringEnv-252"><span class="linenos">252</span></a>		<span class="c1"># Penalize the agents that collided #</span>
</span><span id="InformationGatheringEnv-253"><a href="#InformationGatheringEnv-253"><span class="linenos">253</span></a>		<span class="n">reward</span><span class="p">[</span><span class="n">collision_array</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span>
</span><span id="InformationGatheringEnv-254"><a href="#InformationGatheringEnv-254"><span class="linenos">254</span></a>
</span><span id="InformationGatheringEnv-255"><a href="#InformationGatheringEnv-255"><span class="linenos">255</span></a>		<span class="k">return</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span> <span class="n">reward</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">agents_ids</span><span class="p">}</span>
</span><span id="InformationGatheringEnv-256"><a href="#InformationGatheringEnv-256"><span class="linenos">256</span></a>
</span><span id="InformationGatheringEnv-257"><a href="#InformationGatheringEnv-257"><span class="linenos">257</span></a>	<span class="k">def</span> <span class="nf">process_states</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">agent_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
</span><span id="InformationGatheringEnv-258"><a href="#InformationGatheringEnv-258"><span class="linenos">258</span></a>		<span class="sd">&quot;&quot;&quot; Render the states of the agents.</span>
</span><span id="InformationGatheringEnv-259"><a href="#InformationGatheringEnv-259"><span class="linenos">259</span></a>
</span><span id="InformationGatheringEnv-260"><a href="#InformationGatheringEnv-260"><span class="linenos">260</span></a><span class="sd">		:param agent_ids: The ids of those agents that are expecting the state.</span>
</span><span id="InformationGatheringEnv-261"><a href="#InformationGatheringEnv-261"><span class="linenos">261</span></a>
</span><span id="InformationGatheringEnv-262"><a href="#InformationGatheringEnv-262"><span class="linenos">262</span></a><span class="sd">		:return:</span>
</span><span id="InformationGatheringEnv-263"><a href="#InformationGatheringEnv-263"><span class="linenos">263</span></a><span class="sd">			- states: The state of the agents in a dictionary.</span>
</span><span id="InformationGatheringEnv-264"><a href="#InformationGatheringEnv-264"><span class="linenos">264</span></a>
</span><span id="InformationGatheringEnv-265"><a href="#InformationGatheringEnv-265"><span class="linenos">265</span></a><span class="sd">		&quot;&quot;&quot;</span>
</span><span id="InformationGatheringEnv-266"><a href="#InformationGatheringEnv-266"><span class="linenos">266</span></a>
</span><span id="InformationGatheringEnv-267"><a href="#InformationGatheringEnv-267"><span class="linenos">267</span></a>		<span class="k">if</span> <span class="n">agent_ids</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="InformationGatheringEnv-268"><a href="#InformationGatheringEnv-268"><span class="linenos">268</span></a>			<span class="n">agent_ids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">agents_ids</span>
</span><span id="InformationGatheringEnv-269"><a href="#InformationGatheringEnv-269"><span class="linenos">269</span></a>
</span><span id="InformationGatheringEnv-270"><a href="#InformationGatheringEnv-270"><span class="linenos">270</span></a>		<span class="n">s</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">individual_state</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">agent_ids</span><span class="p">}</span>
</span><span id="InformationGatheringEnv-271"><a href="#InformationGatheringEnv-271"><span class="linenos">271</span></a>
</span><span id="InformationGatheringEnv-272"><a href="#InformationGatheringEnv-272"><span class="linenos">272</span></a>		<span class="k">return</span> <span class="n">s</span>
</span><span id="InformationGatheringEnv-273"><a href="#InformationGatheringEnv-273"><span class="linenos">273</span></a>
</span><span id="InformationGatheringEnv-274"><a href="#InformationGatheringEnv-274"><span class="linenos">274</span></a>	<span class="k">def</span> <span class="nf">individual_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">agent_indx</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="nb">dict</span><span class="p">]:</span>
</span><span id="InformationGatheringEnv-275"><a href="#InformationGatheringEnv-275"><span class="linenos">275</span></a>		<span class="sd">&quot;&quot;&quot; Return the state of an individual agent.</span>
</span><span id="InformationGatheringEnv-276"><a href="#InformationGatheringEnv-276"><span class="linenos">276</span></a>
</span><span id="InformationGatheringEnv-277"><a href="#InformationGatheringEnv-277"><span class="linenos">277</span></a><span class="sd">		:param agent_indx: The index of the agent.</span>
</span><span id="InformationGatheringEnv-278"><a href="#InformationGatheringEnv-278"><span class="linenos">278</span></a>
</span><span id="InformationGatheringEnv-279"><a href="#InformationGatheringEnv-279"><span class="linenos">279</span></a><span class="sd">		:return:</span>
</span><span id="InformationGatheringEnv-280"><a href="#InformationGatheringEnv-280"><span class="linenos">280</span></a><span class="sd">			- state: The state of the agent. Could be a matrix (visual) or a dictionary (hybrid).</span>
</span><span id="InformationGatheringEnv-281"><a href="#InformationGatheringEnv-281"><span class="linenos">281</span></a>
</span><span id="InformationGatheringEnv-282"><a href="#InformationGatheringEnv-282"><span class="linenos">282</span></a><span class="sd">		&quot;&quot;&quot;</span>
</span><span id="InformationGatheringEnv-283"><a href="#InformationGatheringEnv-283"><span class="linenos">283</span></a>
</span><span id="InformationGatheringEnv-284"><a href="#InformationGatheringEnv-284"><span class="linenos">284</span></a>		<span class="n">other_agents_map</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;navigation_map&#39;</span><span class="p">])</span>
</span><span id="InformationGatheringEnv-285"><a href="#InformationGatheringEnv-285"><span class="linenos">285</span></a>		<span class="n">other_agents_ids</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">agents_ids</span><span class="p">)</span>
</span><span id="InformationGatheringEnv-286"><a href="#InformationGatheringEnv-286"><span class="linenos">286</span></a>		<span class="n">other_agents_ids</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">other_agents_ids</span><span class="p">,</span> <span class="n">agent_indx</span><span class="p">)</span>
</span><span id="InformationGatheringEnv-287"><a href="#InformationGatheringEnv-287"><span class="linenos">287</span></a>
</span><span id="InformationGatheringEnv-288"><a href="#InformationGatheringEnv-288"><span class="linenos">288</span></a>		<span class="k">for</span> <span class="n">agent_id</span> <span class="ow">in</span> <span class="n">other_agents_ids</span><span class="p">:</span>
</span><span id="InformationGatheringEnv-289"><a href="#InformationGatheringEnv-289"><span class="linenos">289</span></a>			<span class="n">agent_position</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fleet</span><span class="o">.</span><span class="n">vehicles</span><span class="p">[</span><span class="n">agent_id</span><span class="p">]</span><span class="o">.</span><span class="n">position</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
</span><span id="InformationGatheringEnv-290"><a href="#InformationGatheringEnv-290"><span class="linenos">290</span></a>			<span class="n">other_agents_map</span><span class="p">[</span><span class="n">agent_position</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">agent_position</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">1.0</span>
</span><span id="InformationGatheringEnv-291"><a href="#InformationGatheringEnv-291"><span class="linenos">291</span></a>
</span><span id="InformationGatheringEnv-292"><a href="#InformationGatheringEnv-292"><span class="linenos">292</span></a>		<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">observation_type</span> <span class="o">==</span> <span class="s1">&#39;visual&#39;</span><span class="p">:</span>
</span><span id="InformationGatheringEnv-293"><a href="#InformationGatheringEnv-293"><span class="linenos">293</span></a>
</span><span id="InformationGatheringEnv-294"><a href="#InformationGatheringEnv-294"><span class="linenos">294</span></a>			<span class="c1"># First channel: navigation/obstacle map</span>
</span><span id="InformationGatheringEnv-295"><a href="#InformationGatheringEnv-295"><span class="linenos">295</span></a>			<span class="n">nav_map</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;navigation_map&#39;</span><span class="p">])</span>
</span><span id="InformationGatheringEnv-296"><a href="#InformationGatheringEnv-296"><span class="linenos">296</span></a>
</span><span id="InformationGatheringEnv-297"><a href="#InformationGatheringEnv-297"><span class="linenos">297</span></a>			<span class="c1"># Second channel: self-position map</span>
</span><span id="InformationGatheringEnv-298"><a href="#InformationGatheringEnv-298"><span class="linenos">298</span></a>			<span class="n">position_map</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;navigation_map&#39;</span><span class="p">])</span>
</span><span id="InformationGatheringEnv-299"><a href="#InformationGatheringEnv-299"><span class="linenos">299</span></a>			<span class="n">agent_position</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fleet</span><span class="o">.</span><span class="n">vehicles</span><span class="p">[</span><span class="n">agent_indx</span><span class="p">]</span><span class="o">.</span><span class="n">position</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
</span><span id="InformationGatheringEnv-300"><a href="#InformationGatheringEnv-300"><span class="linenos">300</span></a>			<span class="n">position_map</span><span class="p">[</span><span class="n">agent_position</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">agent_position</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">1.0</span>
</span><span id="InformationGatheringEnv-301"><a href="#InformationGatheringEnv-301"><span class="linenos">301</span></a>
</span><span id="InformationGatheringEnv-302"><a href="#InformationGatheringEnv-302"><span class="linenos">302</span></a>			<span class="c1"># Note that the mu and sigma maps are already normalized to [0, 1]</span>
</span><span id="InformationGatheringEnv-303"><a href="#InformationGatheringEnv-303"><span class="linenos">303</span></a>			<span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">nav_map</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">],</span>
</span><span id="InformationGatheringEnv-304"><a href="#InformationGatheringEnv-304"><span class="linenos">304</span></a>			                       <span class="n">position_map</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">],</span>
</span><span id="InformationGatheringEnv-305"><a href="#InformationGatheringEnv-305"><span class="linenos">305</span></a>			                       <span class="n">other_agents_map</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">],</span>
</span><span id="InformationGatheringEnv-306"><a href="#InformationGatheringEnv-306"><span class="linenos">306</span></a>			                       <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">],</span> <span class="n">a_min</span><span class="o">=-</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">a_max</span><span class="o">=</span><span class="mf">1.0</span><span class="p">),</span>
</span><span id="InformationGatheringEnv-307"><a href="#InformationGatheringEnv-307"><span class="linenos">307</span></a>			                       <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">uncertainty</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">],</span> <span class="n">a_min</span><span class="o">=-</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">a_max</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)))</span>
</span><span id="InformationGatheringEnv-308"><a href="#InformationGatheringEnv-308"><span class="linenos">308</span></a>
</span><span id="InformationGatheringEnv-309"><a href="#InformationGatheringEnv-309"><span class="linenos">309</span></a>		<span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">observation_type</span> <span class="o">==</span> <span class="s1">&#39;hybrid&#39;</span><span class="p">:</span>
</span><span id="InformationGatheringEnv-310"><a href="#InformationGatheringEnv-310"><span class="linenos">310</span></a>
</span><span id="InformationGatheringEnv-311"><a href="#InformationGatheringEnv-311"><span class="linenos">311</span></a>			<span class="k">return</span> <span class="p">{</span><span class="s1">&#39;visual_state&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">],</span>
</span><span id="InformationGatheringEnv-312"><a href="#InformationGatheringEnv-312"><span class="linenos">312</span></a>			                                        <span class="bp">self</span><span class="o">.</span><span class="n">uncertainty</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">],</span>
</span><span id="InformationGatheringEnv-313"><a href="#InformationGatheringEnv-313"><span class="linenos">313</span></a>			                                        <span class="n">other_agents_map</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">])),</span>
</span><span id="InformationGatheringEnv-314"><a href="#InformationGatheringEnv-314"><span class="linenos">314</span></a>			        <span class="s1">&#39;odometry&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">fleet</span><span class="o">.</span><span class="n">vehicles</span><span class="p">[</span><span class="n">agent_indx</span><span class="p">]</span><span class="o">.</span><span class="n">position</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;navigation_map&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">}</span>
</span><span id="InformationGatheringEnv-315"><a href="#InformationGatheringEnv-315"><span class="linenos">315</span></a>
</span><span id="InformationGatheringEnv-316"><a href="#InformationGatheringEnv-316"><span class="linenos">316</span></a>	<span class="k">def</span> <span class="nf">update_vehicles_ground_truths</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="InformationGatheringEnv-317"><a href="#InformationGatheringEnv-317"><span class="linenos">317</span></a>		<span class="sd">&quot;&quot;&quot; Setter to update the ground truth of the vehicles. &quot;&quot;&quot;</span>
</span><span id="InformationGatheringEnv-318"><a href="#InformationGatheringEnv-318"><span class="linenos">318</span></a>
</span><span id="InformationGatheringEnv-319"><a href="#InformationGatheringEnv-319"><span class="linenos">319</span></a>		<span class="k">for</span> <span class="n">vehicle</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">fleet</span><span class="o">.</span><span class="n">vehicles</span><span class="p">:</span>
</span><span id="InformationGatheringEnv-320"><a href="#InformationGatheringEnv-320"><span class="linenos">320</span></a>			<span class="n">vehicle</span><span class="o">.</span><span class="n">ground_truth</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ground_truth</span><span class="o">.</span><span class="n">ground_truth_field</span>
</span><span id="InformationGatheringEnv-321"><a href="#InformationGatheringEnv-321"><span class="linenos">321</span></a>
</span><span id="InformationGatheringEnv-322"><a href="#InformationGatheringEnv-322"><span class="linenos">322</span></a>	<span class="k">def</span> <span class="nf">action_dict_to_targets</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">a_dict</span><span class="p">:</span> <span class="nb">dict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
</span><span id="InformationGatheringEnv-323"><a href="#InformationGatheringEnv-323"><span class="linenos">323</span></a>		<span class="sd">&quot;&quot;&quot; Transform the actions of the dictionary to a dictionary with the target goals.</span>
</span><span id="InformationGatheringEnv-324"><a href="#InformationGatheringEnv-324"><span class="linenos">324</span></a>
</span><span id="InformationGatheringEnv-325"><a href="#InformationGatheringEnv-325"><span class="linenos">325</span></a><span class="sd">		:param a_dict: The dictionary of actions. Every key is an agent_id, and the values corresponds to the action.</span>
</span><span id="InformationGatheringEnv-326"><a href="#InformationGatheringEnv-326"><span class="linenos">326</span></a>
</span><span id="InformationGatheringEnv-327"><a href="#InformationGatheringEnv-327"><span class="linenos">327</span></a><span class="sd">		:return:</span>
</span><span id="InformationGatheringEnv-328"><a href="#InformationGatheringEnv-328"><span class="linenos">328</span></a><span class="sd">			- targets: An array that contains the target positions for every vehicle.</span>
</span><span id="InformationGatheringEnv-329"><a href="#InformationGatheringEnv-329"><span class="linenos">329</span></a>
</span><span id="InformationGatheringEnv-330"><a href="#InformationGatheringEnv-330"><span class="linenos">330</span></a><span class="sd">		&quot;&quot;&quot;</span>
</span><span id="InformationGatheringEnv-331"><a href="#InformationGatheringEnv-331"><span class="linenos">331</span></a>
</span><span id="InformationGatheringEnv-332"><a href="#InformationGatheringEnv-332"><span class="linenos">332</span></a>		<span class="n">target_agents</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">a_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
</span><span id="InformationGatheringEnv-333"><a href="#InformationGatheringEnv-333"><span class="linenos">333</span></a>
</span><span id="InformationGatheringEnv-334"><a href="#InformationGatheringEnv-334"><span class="linenos">334</span></a>		<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;movement_type&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;DIRECTIONAL&#39;</span><span class="p">:</span>
</span><span id="InformationGatheringEnv-335"><a href="#InformationGatheringEnv-335"><span class="linenos">335</span></a>			<span class="c1"># Transform discrete actions to displacement</span>
</span><span id="InformationGatheringEnv-336"><a href="#InformationGatheringEnv-336"><span class="linenos">336</span></a>			<span class="n">angles</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">action</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;number_of_actions&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">action</span> <span class="ow">in</span> <span class="n">a_dict</span><span class="o">.</span><span class="n">values</span><span class="p">()])</span>
</span><span id="InformationGatheringEnv-337"><a href="#InformationGatheringEnv-337"><span class="linenos">337</span></a>			<span class="c1"># Transform the displacement to positions #</span>
</span><span id="InformationGatheringEnv-338"><a href="#InformationGatheringEnv-338"><span class="linenos">338</span></a>			<span class="n">target_positions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fleet</span><span class="o">.</span><span class="n">get_positions</span><span class="p">()[</span><span class="n">target_agents</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;measurement_distance&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">(</span>
</span><span id="InformationGatheringEnv-339"><a href="#InformationGatheringEnv-339"><span class="linenos">339</span></a>				<span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">angles</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">angles</span><span class="p">)))</span>
</span><span id="InformationGatheringEnv-340"><a href="#InformationGatheringEnv-340"><span class="linenos">340</span></a>
</span><span id="InformationGatheringEnv-341"><a href="#InformationGatheringEnv-341"><span class="linenos">341</span></a>		<span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;movement_type&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;DIRECTIONAL_DISTANCE&#39;</span><span class="p">:</span>
</span><span id="InformationGatheringEnv-342"><a href="#InformationGatheringEnv-342"><span class="linenos">342</span></a>			<span class="c1"># Transform the continuous actions into displacement #</span>
</span><span id="InformationGatheringEnv-343"><a href="#InformationGatheringEnv-343"><span class="linenos">343</span></a>			<span class="n">actions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">action</span> <span class="k">for</span> <span class="n">action</span> <span class="ow">in</span> <span class="n">a_dict</span><span class="o">.</span><span class="n">values</span><span class="p">()])</span>
</span><span id="InformationGatheringEnv-344"><a href="#InformationGatheringEnv-344"><span class="linenos">344</span></a>			<span class="n">angles</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">actions</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
</span><span id="InformationGatheringEnv-345"><a href="#InformationGatheringEnv-345"><span class="linenos">345</span></a>			<span class="n">distances</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear_min_max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;min_measurement_distance&#39;</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;max_measurement_distance&#39;</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span>
</span><span id="InformationGatheringEnv-346"><a href="#InformationGatheringEnv-346"><span class="linenos">346</span></a>			                                <span class="n">actions</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
</span><span id="InformationGatheringEnv-347"><a href="#InformationGatheringEnv-347"><span class="linenos">347</span></a>			<span class="n">target_positions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fleet</span><span class="o">.</span><span class="n">get_positions</span><span class="p">()[</span><span class="n">target_agents</span><span class="p">]</span> <span class="o">+</span> <span class="n">distances</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">angles</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">angles</span><span class="p">)))</span>
</span><span id="InformationGatheringEnv-348"><a href="#InformationGatheringEnv-348"><span class="linenos">348</span></a>		<span class="k">else</span><span class="p">:</span>
</span><span id="InformationGatheringEnv-349"><a href="#InformationGatheringEnv-349"><span class="linenos">349</span></a>			<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Invalid movement type&quot;</span><span class="p">)</span>
</span><span id="InformationGatheringEnv-350"><a href="#InformationGatheringEnv-350"><span class="linenos">350</span></a>
</span><span id="InformationGatheringEnv-351"><a href="#InformationGatheringEnv-351"><span class="linenos">351</span></a>		<span class="k">return</span> <span class="n">target_positions</span>
</span><span id="InformationGatheringEnv-352"><a href="#InformationGatheringEnv-352"><span class="linenos">352</span></a>
</span><span id="InformationGatheringEnv-353"><a href="#InformationGatheringEnv-353"><span class="linenos">353</span></a>	<span class="nd">@staticmethod</span>
</span><span id="InformationGatheringEnv-354"><a href="#InformationGatheringEnv-354"><span class="linenos">354</span></a>	<span class="k">def</span> <span class="nf">linear_min_max</span><span class="p">(</span><span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span><span class="p">,</span> <span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
</span><span id="InformationGatheringEnv-355"><a href="#InformationGatheringEnv-355"><span class="linenos">355</span></a>		<span class="sd">&quot;&quot;&quot; Transform the input x into a line &quot;&quot;&quot;</span>
</span><span id="InformationGatheringEnv-356"><a href="#InformationGatheringEnv-356"><span class="linenos">356</span></a>		<span class="k">return</span> <span class="p">(</span><span class="n">y_max</span> <span class="o">-</span> <span class="n">y_min</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">x_max</span> <span class="o">-</span> <span class="n">x_min</span><span class="p">)</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y_min</span>
</span><span id="InformationGatheringEnv-357"><a href="#InformationGatheringEnv-357"><span class="linenos">357</span></a>
</span><span id="InformationGatheringEnv-358"><a href="#InformationGatheringEnv-358"><span class="linenos">358</span></a>	<span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">action_dict</span><span class="p">:</span> <span class="nb">dict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="p">(</span><span class="nb">dict</span><span class="p">,</span> <span class="nb">dict</span><span class="p">,</span> <span class="nb">dict</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
</span><span id="InformationGatheringEnv-359"><a href="#InformationGatheringEnv-359"><span class="linenos">359</span></a>		<span class="sd">&quot;&quot;&quot; Process the actions. The action is processed for those waiting vehicles. The fleet is updated until one/all vehicles are ready.</span>
</span><span id="InformationGatheringEnv-360"><a href="#InformationGatheringEnv-360"><span class="linenos">360</span></a><span class="sd">		Every vehicle takes a measurement and the reward is processed</span>
</span><span id="InformationGatheringEnv-361"><a href="#InformationGatheringEnv-361"><span class="linenos">361</span></a>
</span><span id="InformationGatheringEnv-362"><a href="#InformationGatheringEnv-362"><span class="linenos">362</span></a><span class="sd">		:param action_dict: The dictionary of actions. Every key is an agent_id, and the values corresponds to the action.</span>
</span><span id="InformationGatheringEnv-363"><a href="#InformationGatheringEnv-363"><span class="linenos">363</span></a>
</span><span id="InformationGatheringEnv-364"><a href="#InformationGatheringEnv-364"><span class="linenos">364</span></a><span class="sd">		:return:</span>
</span><span id="InformationGatheringEnv-365"><a href="#InformationGatheringEnv-365"><span class="linenos">365</span></a><span class="sd">			- reward: The reward for each agent.</span>
</span><span id="InformationGatheringEnv-366"><a href="#InformationGatheringEnv-366"><span class="linenos">366</span></a><span class="sd">			- observation: The observation for each agent.</span>
</span><span id="InformationGatheringEnv-367"><a href="#InformationGatheringEnv-367"><span class="linenos">367</span></a><span class="sd">			- done: A boolean that indicates if the episode is finished.</span>
</span><span id="InformationGatheringEnv-368"><a href="#InformationGatheringEnv-368"><span class="linenos">368</span></a><span class="sd">			- info: A dictionary that contains additional information.</span>
</span><span id="InformationGatheringEnv-369"><a href="#InformationGatheringEnv-369"><span class="linenos">369</span></a>
</span><span id="InformationGatheringEnv-370"><a href="#InformationGatheringEnv-370"><span class="linenos">370</span></a><span class="sd">		&quot;&quot;&quot;</span>
</span><span id="InformationGatheringEnv-371"><a href="#InformationGatheringEnv-371"><span class="linenos">371</span></a>
</span><span id="InformationGatheringEnv-372"><a href="#InformationGatheringEnv-372"><span class="linenos">372</span></a>		<span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">resetted</span><span class="p">,</span> <span class="s2">&quot;You need to reset the environment first with env.reset()&quot;</span>
</span><span id="InformationGatheringEnv-373"><a href="#InformationGatheringEnv-373"><span class="linenos">373</span></a>
</span><span id="InformationGatheringEnv-374"><a href="#InformationGatheringEnv-374"><span class="linenos">374</span></a>		<span class="c1"># Compute the new target with the given actions #</span>
</span><span id="InformationGatheringEnv-375"><a href="#InformationGatheringEnv-375"><span class="linenos">375</span></a>		<span class="n">new_targets</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_dict_to_targets</span><span class="p">(</span><span class="n">action_dict</span><span class="p">)</span>
</span><span id="InformationGatheringEnv-376"><a href="#InformationGatheringEnv-376"><span class="linenos">376</span></a>
</span><span id="InformationGatheringEnv-377"><a href="#InformationGatheringEnv-377"><span class="linenos">377</span></a>		<span class="c1"># Apply the new target to the vehicles #</span>
</span><span id="InformationGatheringEnv-378"><a href="#InformationGatheringEnv-378"><span class="linenos">378</span></a>		<span class="k">for</span> <span class="n">vehicle_id</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">action_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">(),</span> <span class="n">new_targets</span><span class="p">):</span>
</span><span id="InformationGatheringEnv-379"><a href="#InformationGatheringEnv-379"><span class="linenos">379</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">fleet</span><span class="o">.</span><span class="n">set_target_position</span><span class="p">(</span><span class="n">vehicle_id</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
</span><span id="InformationGatheringEnv-380"><a href="#InformationGatheringEnv-380"><span class="linenos">380</span></a>
</span><span id="InformationGatheringEnv-381"><a href="#InformationGatheringEnv-381"><span class="linenos">381</span></a>		<span class="c1"># Step until any vehicle has completed (or failed its goal) #</span>
</span><span id="InformationGatheringEnv-382"><a href="#InformationGatheringEnv-382"><span class="linenos">382</span></a>		<span class="n">new_measurements</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="InformationGatheringEnv-383"><a href="#InformationGatheringEnv-383"><span class="linenos">383</span></a>
</span><span id="InformationGatheringEnv-384"><a href="#InformationGatheringEnv-384"><span class="linenos">384</span></a>		<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;movement_type&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;DIRECTIONAL&#39;</span><span class="p">:</span>
</span><span id="InformationGatheringEnv-385"><a href="#InformationGatheringEnv-385"><span class="linenos">385</span></a>			<span class="c1"># Update until ALL vehicles have arrived to their goals #</span>
</span><span id="InformationGatheringEnv-386"><a href="#InformationGatheringEnv-386"><span class="linenos">386</span></a>			<span class="n">_</span><span class="p">,</span> <span class="n">new_measurements</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fleet</span><span class="o">.</span><span class="n">update_syncronously</span><span class="p">()</span>
</span><span id="InformationGatheringEnv-387"><a href="#InformationGatheringEnv-387"><span class="linenos">387</span></a>		<span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;movement_type&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;DIRECTIONAL_DISTANCE&#39;</span><span class="p">:</span>
</span><span id="InformationGatheringEnv-388"><a href="#InformationGatheringEnv-388"><span class="linenos">388</span></a>			<span class="c1"># Update until AT LEAST ONE vehicle has arrived to their goals#</span>
</span><span id="InformationGatheringEnv-389"><a href="#InformationGatheringEnv-389"><span class="linenos">389</span></a>			<span class="n">_</span><span class="p">,</span> <span class="n">new_measurements</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fleet</span><span class="o">.</span><span class="n">update_asyncronously</span><span class="p">()</span>
</span><span id="InformationGatheringEnv-390"><a href="#InformationGatheringEnv-390"><span class="linenos">390</span></a>
</span><span id="InformationGatheringEnv-391"><a href="#InformationGatheringEnv-391"><span class="linenos">391</span></a>		<span class="c1"># Retrieve the ids of the agents that must return a state and a reward #</span>
</span><span id="InformationGatheringEnv-392"><a href="#InformationGatheringEnv-392"><span class="linenos">392</span></a>		<span class="n">ready_agents_ids</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">veh_state</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fleet</span><span class="o">.</span><span class="n">fleet_state</span><span class="p">)</span> <span class="k">if</span> <span class="n">veh_state</span> <span class="ow">in</span> <span class="p">[</span><span class="n">FleetState</span><span class="o">.</span><span class="n">WAITING_FOR_ACTION</span><span class="p">,</span> <span class="n">FleetState</span><span class="o">.</span><span class="n">COLLIDED</span><span class="p">,</span> <span class="n">FleetState</span><span class="o">.</span><span class="n">LAST_ACTION</span><span class="p">]]</span>
</span><span id="InformationGatheringEnv-393"><a href="#InformationGatheringEnv-393"><span class="linenos">393</span></a>
</span><span id="InformationGatheringEnv-394"><a href="#InformationGatheringEnv-394"><span class="linenos">394</span></a>		<span class="c1"># Compute those agents that collided and add 1 collision to their counter #</span>
</span><span id="InformationGatheringEnv-395"><a href="#InformationGatheringEnv-395"><span class="linenos">395</span></a>		<span class="n">collision_array</span> <span class="o">=</span> <span class="p">[</span><span class="n">s</span> <span class="o">==</span> <span class="n">FleetState</span><span class="o">.</span><span class="n">COLLIDED</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">fleet</span><span class="o">.</span><span class="n">fleet_state</span><span class="p">]</span>
</span><span id="InformationGatheringEnv-396"><a href="#InformationGatheringEnv-396"><span class="linenos">396</span></a>		<span class="c1"># Accumulate every agent collision #</span>
</span><span id="InformationGatheringEnv-397"><a href="#InformationGatheringEnv-397"><span class="linenos">397</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">number_of_collisions</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">collision_array</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
</span><span id="InformationGatheringEnv-398"><a href="#InformationGatheringEnv-398"><span class="linenos">398</span></a>		<span class="c1"># For every agent, change its state to final if its number of collisions is equal to the maximum number of collisions #</span>
</span><span id="InformationGatheringEnv-399"><a href="#InformationGatheringEnv-399"><span class="linenos">399</span></a>		<span class="k">for</span> <span class="n">agent_id</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">agents_ids</span><span class="p">:</span>
</span><span id="InformationGatheringEnv-400"><a href="#InformationGatheringEnv-400"><span class="linenos">400</span></a>			<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">number_of_collisions</span><span class="p">[</span><span class="n">agent_id</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_collisions</span><span class="p">:</span>
</span><span id="InformationGatheringEnv-401"><a href="#InformationGatheringEnv-401"><span class="linenos">401</span></a>				<span class="bp">self</span><span class="o">.</span><span class="n">fleet</span><span class="o">.</span><span class="n">set_state</span><span class="p">(</span><span class="n">agent_id</span><span class="p">,</span> <span class="n">FleetState</span><span class="o">.</span><span class="n">LAST_ACTION</span><span class="p">)</span>
</span><span id="InformationGatheringEnv-402"><a href="#InformationGatheringEnv-402"><span class="linenos">402</span></a>
</span><span id="InformationGatheringEnv-403"><a href="#InformationGatheringEnv-403"><span class="linenos">403</span></a>		<span class="n">done_agents_vals</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">fleet</span><span class="o">.</span><span class="n">fleet_state</span><span class="p">[</span><span class="n">agents_id</span><span class="p">]</span> <span class="o">==</span> <span class="n">FleetState</span><span class="o">.</span><span class="n">LAST_ACTION</span> <span class="k">for</span> <span class="n">agents_id</span> <span class="ow">in</span> <span class="n">ready_agents_ids</span><span class="p">]</span>
</span><span id="InformationGatheringEnv-404"><a href="#InformationGatheringEnv-404"><span class="linenos">404</span></a>
</span><span id="InformationGatheringEnv-405"><a href="#InformationGatheringEnv-405"><span class="linenos">405</span></a>		<span class="c1"># Update the model</span>
</span><span id="InformationGatheringEnv-406"><a href="#InformationGatheringEnv-406"><span class="linenos">406</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">uncertainty</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">update_model</span><span class="p">(</span><span class="n">new_measurements</span><span class="o">=</span><span class="n">new_measurements</span><span class="p">,</span> <span class="n">agents_ids</span><span class="o">=</span><span class="n">ready_agents_ids</span><span class="p">)</span>
</span><span id="InformationGatheringEnv-407"><a href="#InformationGatheringEnv-407"><span class="linenos">407</span></a>
</span><span id="InformationGatheringEnv-408"><a href="#InformationGatheringEnv-408"><span class="linenos">408</span></a>		<span class="c1"># Compute the rewards for those finished agents #</span>
</span><span id="InformationGatheringEnv-409"><a href="#InformationGatheringEnv-409"><span class="linenos">409</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">rewards</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_function</span><span class="p">(</span><span class="n">collision_array</span><span class="o">=</span><span class="n">collision_array</span><span class="p">,</span> <span class="n">agents_ids</span><span class="o">=</span><span class="n">ready_agents_ids</span><span class="p">)</span>
</span><span id="InformationGatheringEnv-410"><a href="#InformationGatheringEnv-410"><span class="linenos">410</span></a>
</span><span id="InformationGatheringEnv-411"><a href="#InformationGatheringEnv-411"><span class="linenos">411</span></a>		<span class="c1"># Compute the states for those same agents #</span>
</span><span id="InformationGatheringEnv-412"><a href="#InformationGatheringEnv-412"><span class="linenos">412</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">process_states</span><span class="p">(</span><span class="n">agent_ids</span><span class="o">=</span><span class="n">ready_agents_ids</span><span class="p">)</span>
</span><span id="InformationGatheringEnv-413"><a href="#InformationGatheringEnv-413"><span class="linenos">413</span></a>
</span><span id="InformationGatheringEnv-414"><a href="#InformationGatheringEnv-414"><span class="linenos">414</span></a>		<span class="c1"># Info is useless by the moment</span>
</span><span id="InformationGatheringEnv-415"><a href="#InformationGatheringEnv-415"><span class="linenos">415</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">infos</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;Collisions&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">number_of_collisions</span><span class="p">[</span><span class="n">i</span><span class="p">]}</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">ready_agents_ids</span><span class="p">}</span>
</span><span id="InformationGatheringEnv-416"><a href="#InformationGatheringEnv-416"><span class="linenos">416</span></a>
</span><span id="InformationGatheringEnv-417"><a href="#InformationGatheringEnv-417"><span class="linenos">417</span></a>		<span class="c1"># Update the ground truth state and pass the field to agents #</span>
</span><span id="InformationGatheringEnv-418"><a href="#InformationGatheringEnv-418"><span class="linenos">418</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">ground_truth</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</span><span id="InformationGatheringEnv-419"><a href="#InformationGatheringEnv-419"><span class="linenos">419</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">update_vehicles_ground_truths</span><span class="p">()</span>
</span><span id="InformationGatheringEnv-420"><a href="#InformationGatheringEnv-420"><span class="linenos">420</span></a>
</span><span id="InformationGatheringEnv-421"><a href="#InformationGatheringEnv-421"><span class="linenos">421</span></a>		<span class="c1"># Compute if the agents have finished #</span>
</span><span id="InformationGatheringEnv-422"><a href="#InformationGatheringEnv-422"><span class="linenos">422</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">dones</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span> <span class="n">val</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">ready_agents_ids</span><span class="p">,</span> <span class="n">done_agents_vals</span><span class="p">)}</span>
</span><span id="InformationGatheringEnv-423"><a href="#InformationGatheringEnv-423"><span class="linenos">423</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">dones</span><span class="p">[</span><span class="s1">&#39;__all__&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">all</span><span class="p">([</span><span class="n">veh_state</span> <span class="ow">in</span> <span class="p">[</span><span class="n">FleetState</span><span class="o">.</span><span class="n">LAST_ACTION</span><span class="p">,</span> <span class="n">FleetState</span><span class="o">.</span><span class="n">FINISHED</span><span class="p">]</span> <span class="k">for</span> <span class="n">veh_state</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">fleet</span><span class="o">.</span><span class="n">fleet_state</span><span class="p">])</span>
</span><span id="InformationGatheringEnv-424"><a href="#InformationGatheringEnv-424"><span class="linenos">424</span></a>
</span><span id="InformationGatheringEnv-425"><a href="#InformationGatheringEnv-425"><span class="linenos">425</span></a>
</span><span id="InformationGatheringEnv-426"><a href="#InformationGatheringEnv-426"><span class="linenos">426</span></a>		<span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">states</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">rewards</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dones</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">infos</span>
</span><span id="InformationGatheringEnv-427"><a href="#InformationGatheringEnv-427"><span class="linenos">427</span></a>
</span><span id="InformationGatheringEnv-428"><a href="#InformationGatheringEnv-428"><span class="linenos">428</span></a>	<span class="k">def</span> <span class="nf">render</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;human&#39;</span><span class="p">):</span>
</span><span id="InformationGatheringEnv-429"><a href="#InformationGatheringEnv-429"><span class="linenos">429</span></a>		<span class="sd">&quot;&quot;&quot; Render the environment. &quot;&quot;&quot;</span>
</span><span id="InformationGatheringEnv-430"><a href="#InformationGatheringEnv-430"><span class="linenos">430</span></a>
</span><span id="InformationGatheringEnv-431"><a href="#InformationGatheringEnv-431"><span class="linenos">431</span></a>		<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">fig</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="InformationGatheringEnv-432"><a href="#InformationGatheringEnv-432"><span class="linenos">432</span></a>
</span><span id="InformationGatheringEnv-433"><a href="#InformationGatheringEnv-433"><span class="linenos">433</span></a>			<span class="n">plt</span><span class="o">.</span><span class="n">ion</span><span class="p">()</span>
</span><span id="InformationGatheringEnv-434"><a href="#InformationGatheringEnv-434"><span class="linenos">434</span></a>
</span><span id="InformationGatheringEnv-435"><a href="#InformationGatheringEnv-435"><span class="linenos">435</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">fig</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
</span><span id="InformationGatheringEnv-436"><a href="#InformationGatheringEnv-436"><span class="linenos">436</span></a>
</span><span id="InformationGatheringEnv-437"><a href="#InformationGatheringEnv-437"><span class="linenos">437</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Navigation map&#39;</span><span class="p">)</span>
</span><span id="InformationGatheringEnv-438"><a href="#InformationGatheringEnv-438"><span class="linenos">438</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">s0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;navigation_map&#39;</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
</span><span id="InformationGatheringEnv-439"><a href="#InformationGatheringEnv-439"><span class="linenos">439</span></a>
</span><span id="InformationGatheringEnv-440"><a href="#InformationGatheringEnv-440"><span class="linenos">440</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Fleet positions&#39;</span><span class="p">)</span>
</span><span id="InformationGatheringEnv-441"><a href="#InformationGatheringEnv-441"><span class="linenos">441</span></a>			<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">observation_type</span> <span class="o">==</span> <span class="s1">&#39;visual&#39;</span><span class="p">:</span>
</span><span id="InformationGatheringEnv-442"><a href="#InformationGatheringEnv-442"><span class="linenos">442</span></a>				<span class="bp">self</span><span class="o">.</span><span class="n">s1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">individual_state</span><span class="p">(</span><span class="n">i</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">number_of_agents</span><span class="p">)],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
</span><span id="InformationGatheringEnv-443"><a href="#InformationGatheringEnv-443"><span class="linenos">443</span></a>			<span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">observation_type</span> <span class="o">==</span> <span class="s1">&#39;hybrid&#39;</span><span class="p">:</span>
</span><span id="InformationGatheringEnv-444"><a href="#InformationGatheringEnv-444"><span class="linenos">444</span></a>				<span class="bp">self</span><span class="o">.</span><span class="n">s1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">individual_state</span><span class="p">(</span><span class="n">i</span><span class="p">)[</span><span class="s1">&#39;visual_state&#39;</span><span class="p">][</span><span class="mi">2</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">number_of_agents</span><span class="p">)],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
</span><span id="InformationGatheringEnv-445"><a href="#InformationGatheringEnv-445"><span class="linenos">445</span></a>			<span class="k">else</span><span class="p">:</span>
</span><span id="InformationGatheringEnv-446"><a href="#InformationGatheringEnv-446"><span class="linenos">446</span></a>				<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s1">&#39;Cannot render with an invalid observation type.&#39;</span><span class="p">)</span>
</span><span id="InformationGatheringEnv-447"><a href="#InformationGatheringEnv-447"><span class="linenos">447</span></a>
</span><span id="InformationGatheringEnv-448"><a href="#InformationGatheringEnv-448"><span class="linenos">448</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Estimated model&#39;</span><span class="p">)</span>
</span><span id="InformationGatheringEnv-449"><a href="#InformationGatheringEnv-449"><span class="linenos">449</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">s2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;jet&#39;</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
</span><span id="InformationGatheringEnv-450"><a href="#InformationGatheringEnv-450"><span class="linenos">450</span></a>
</span><span id="InformationGatheringEnv-451"><a href="#InformationGatheringEnv-451"><span class="linenos">451</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">axs</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Uncertainty&#39;</span><span class="p">)</span>
</span><span id="InformationGatheringEnv-452"><a href="#InformationGatheringEnv-452"><span class="linenos">452</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">s3</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">axs</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">uncertainty</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
</span><span id="InformationGatheringEnv-453"><a href="#InformationGatheringEnv-453"><span class="linenos">453</span></a>
</span><span id="InformationGatheringEnv-454"><a href="#InformationGatheringEnv-454"><span class="linenos">454</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">axs</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Ground truth&#39;</span><span class="p">)</span>
</span><span id="InformationGatheringEnv-455"><a href="#InformationGatheringEnv-455"><span class="linenos">455</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">s4</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">axs</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ground_truth</span><span class="o">.</span><span class="n">ground_truth_field</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;jet&#39;</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
</span><span id="InformationGatheringEnv-456"><a href="#InformationGatheringEnv-456"><span class="linenos">456</span></a>
</span><span id="InformationGatheringEnv-457"><a href="#InformationGatheringEnv-457"><span class="linenos">457</span></a>		<span class="k">else</span><span class="p">:</span>
</span><span id="InformationGatheringEnv-458"><a href="#InformationGatheringEnv-458"><span class="linenos">458</span></a>
</span><span id="InformationGatheringEnv-459"><a href="#InformationGatheringEnv-459"><span class="linenos">459</span></a>			<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">observation_type</span> <span class="o">==</span> <span class="s1">&#39;visual&#39;</span><span class="p">:</span>
</span><span id="InformationGatheringEnv-460"><a href="#InformationGatheringEnv-460"><span class="linenos">460</span></a>				<span class="bp">self</span><span class="o">.</span><span class="n">s1</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">individual_state</span><span class="p">(</span><span class="n">i</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">number_of_agents</span><span class="p">)],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
</span><span id="InformationGatheringEnv-461"><a href="#InformationGatheringEnv-461"><span class="linenos">461</span></a>			<span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">observation_type</span> <span class="o">==</span> <span class="s1">&#39;hybrid&#39;</span><span class="p">:</span>
</span><span id="InformationGatheringEnv-462"><a href="#InformationGatheringEnv-462"><span class="linenos">462</span></a>				<span class="bp">self</span><span class="o">.</span><span class="n">s1</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">individual_state</span><span class="p">(</span><span class="n">i</span><span class="p">)[</span><span class="s1">&#39;visual_state&#39;</span><span class="p">][</span><span class="mi">2</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">number_of_agents</span><span class="p">)],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
</span><span id="InformationGatheringEnv-463"><a href="#InformationGatheringEnv-463"><span class="linenos">463</span></a>
</span><span id="InformationGatheringEnv-464"><a href="#InformationGatheringEnv-464"><span class="linenos">464</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">s2</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="p">)</span>
</span><span id="InformationGatheringEnv-465"><a href="#InformationGatheringEnv-465"><span class="linenos">465</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">s3</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">uncertainty</span><span class="p">)</span>
</span><span id="InformationGatheringEnv-466"><a href="#InformationGatheringEnv-466"><span class="linenos">466</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">s4</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ground_truth</span><span class="o">.</span><span class="n">ground_truth_field</span><span class="p">)</span>
</span><span id="InformationGatheringEnv-467"><a href="#InformationGatheringEnv-467"><span class="linenos">467</span></a>
</span><span id="InformationGatheringEnv-468"><a href="#InformationGatheringEnv-468"><span class="linenos">468</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">fig</span><span class="o">.</span><span class="n">canvas</span><span class="o">.</span><span class="n">draw</span><span class="p">()</span>
</span><span id="InformationGatheringEnv-469"><a href="#InformationGatheringEnv-469"><span class="linenos">469</span></a>
</span><span id="InformationGatheringEnv-470"><a href="#InformationGatheringEnv-470"><span class="linenos">470</span></a>		<span class="n">plt</span><span class="o">.</span><span class="n">pause</span><span class="p">(</span><span class="mf">0.01</span><span class="p">)</span>
</span><span id="InformationGatheringEnv-471"><a href="#InformationGatheringEnv-471"><span class="linenos">471</span></a>		<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">(</span><span class="n">pad</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
</span><span id="InformationGatheringEnv-472"><a href="#InformationGatheringEnv-472"><span class="linenos">472</span></a>		<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span><span id="InformationGatheringEnv-473"><a href="#InformationGatheringEnv-473"><span class="linenos">473</span></a>
</span><span id="InformationGatheringEnv-474"><a href="#InformationGatheringEnv-474"><span class="linenos">474</span></a>	<span class="k">def</span> <span class="nf">get_action_mask</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ind</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
</span><span id="InformationGatheringEnv-475"><a href="#InformationGatheringEnv-475"><span class="linenos">475</span></a>		<span class="sd">&quot;&quot;&quot; Get the invalid action mask for a certain vehicle (*ind*)</span>
</span><span id="InformationGatheringEnv-476"><a href="#InformationGatheringEnv-476"><span class="linenos">476</span></a>
</span><span id="InformationGatheringEnv-477"><a href="#InformationGatheringEnv-477"><span class="linenos">477</span></a><span class="sd">		:param ind: The index of the vehicle</span>
</span><span id="InformationGatheringEnv-478"><a href="#InformationGatheringEnv-478"><span class="linenos">478</span></a>
</span><span id="InformationGatheringEnv-479"><a href="#InformationGatheringEnv-479"><span class="linenos">479</span></a><span class="sd">		:return:</span>
</span><span id="InformationGatheringEnv-480"><a href="#InformationGatheringEnv-480"><span class="linenos">480</span></a><span class="sd">			- mask: The invalid action mask for the vehicle, where true means that the action is valid.</span>
</span><span id="InformationGatheringEnv-481"><a href="#InformationGatheringEnv-481"><span class="linenos">481</span></a>
</span><span id="InformationGatheringEnv-482"><a href="#InformationGatheringEnv-482"><span class="linenos">482</span></a><span class="sd">		&quot;&quot;&quot;</span>
</span><span id="InformationGatheringEnv-483"><a href="#InformationGatheringEnv-483"><span class="linenos">483</span></a>
</span><span id="InformationGatheringEnv-484"><a href="#InformationGatheringEnv-484"><span class="linenos">484</span></a>		<span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;movement_type&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;DIRECTIONAL&#39;</span><span class="p">,</span> <span class="s1">&#39;This function is only valid for DIRECTIONAL movement.&#39;</span>
</span><span id="InformationGatheringEnv-485"><a href="#InformationGatheringEnv-485"><span class="linenos">485</span></a>
</span><span id="InformationGatheringEnv-486"><a href="#InformationGatheringEnv-486"><span class="linenos">486</span></a>		<span class="n">angles</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;number_of_actions&#39;</span><span class="p">])</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;number_of_actions&#39;</span><span class="p">]</span>
</span><span id="InformationGatheringEnv-487"><a href="#InformationGatheringEnv-487"><span class="linenos">487</span></a>		<span class="n">possible_points</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fleet</span><span class="o">.</span><span class="n">vehicles</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span><span class="o">.</span><span class="n">position</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;measurement_distance&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">angles</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">angles</span><span class="p">)))</span>
</span><span id="InformationGatheringEnv-488"><a href="#InformationGatheringEnv-488"><span class="linenos">488</span></a>
</span><span id="InformationGatheringEnv-489"><a href="#InformationGatheringEnv-489"><span class="linenos">489</span></a>		<span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fleet</span><span class="o">.</span><span class="n">vehicles</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span><span class="o">.</span><span class="n">is_the_position_valid</span><span class="p">,</span> <span class="n">possible_points</span><span class="p">)))</span>
</span></pre></div>


            <div class="docstring"><p>An environment that hosts multiple independent agents.</p>

<p>Agents are identified by (string) agent ids. Note that these "agents" here
are not to be confused with RLlib Trainers, which are also sometimes
referred to as "agents" or "RL agents".</p>
</div>


                            <div id="InformationGatheringEnv.__init__" class="classattr">
                                        <input id="InformationGatheringEnv.__init__-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="name">InformationGatheringEnv</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">env_config</span><span class="p">:</span> <span class="nb">dict</span></span>)</span>

                <label class="view-source-button" for="InformationGatheringEnv.__init__-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#InformationGatheringEnv.__init__"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="InformationGatheringEnv.__init__-19"><a href="#InformationGatheringEnv.__init__-19"><span class="linenos"> 19</span></a>	<span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env_config</span><span class="p">:</span> <span class="nb">dict</span><span class="p">):</span>
</span><span id="InformationGatheringEnv.__init__-20"><a href="#InformationGatheringEnv.__init__-20"><span class="linenos"> 20</span></a>
</span><span id="InformationGatheringEnv.__init__-21"><a href="#InformationGatheringEnv.__init__-21"><span class="linenos"> 21</span></a>		<span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span><span id="InformationGatheringEnv.__init__-22"><a href="#InformationGatheringEnv.__init__-22"><span class="linenos"> 22</span></a>
</span><span id="InformationGatheringEnv.__init__-23"><a href="#InformationGatheringEnv.__init__-23"><span class="linenos"> 23</span></a>		<span class="c1"># Environment configuration dictionary</span>
</span><span id="InformationGatheringEnv.__init__-24"><a href="#InformationGatheringEnv.__init__-24"><span class="linenos"> 24</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">env_config</span> <span class="o">=</span> <span class="n">env_config</span>
</span><span id="InformationGatheringEnv.__init__-25"><a href="#InformationGatheringEnv.__init__-25"><span class="linenos"> 25</span></a>
</span><span id="InformationGatheringEnv.__init__-26"><a href="#InformationGatheringEnv.__init__-26"><span class="linenos"> 26</span></a>		<span class="c1"># Create a fleet of N vehicles #</span>
</span><span id="InformationGatheringEnv.__init__-27"><a href="#InformationGatheringEnv.__init__-27"><span class="linenos"> 27</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">fleet</span> <span class="o">=</span> <span class="n">Fleet</span><span class="p">(</span><span class="n">fleet_configuration</span><span class="o">=</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;fleet_configuration&#39;</span><span class="p">])</span>
</span><span id="InformationGatheringEnv.__init__-28"><a href="#InformationGatheringEnv.__init__-28"><span class="linenos"> 28</span></a>		<span class="c1"># Save the number of agents #</span>
</span><span id="InformationGatheringEnv.__init__-29"><a href="#InformationGatheringEnv.__init__-29"><span class="linenos"> 29</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">number_of_agents</span> <span class="o">=</span> <span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;fleet_configuration&#39;</span><span class="p">][</span><span class="s1">&#39;number_of_vehicles&#39;</span><span class="p">]</span>
</span><span id="InformationGatheringEnv.__init__-30"><a href="#InformationGatheringEnv.__init__-30"><span class="linenos"> 30</span></a>		<span class="c1"># Save the agents ids #</span>
</span><span id="InformationGatheringEnv.__init__-31"><a href="#InformationGatheringEnv.__init__-31"><span class="linenos"> 31</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">agents_ids</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">number_of_agents</span><span class="p">))</span>
</span><span id="InformationGatheringEnv.__init__-32"><a href="#InformationGatheringEnv.__init__-32"><span class="linenos"> 32</span></a>		<span class="c1"># Create a set of agents IDs - This is required for the RLLIB MA Environment class #</span>
</span><span id="InformationGatheringEnv.__init__-33"><a href="#InformationGatheringEnv.__init__-33"><span class="linenos"> 33</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">_agent_ids</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">number_of_agents</span><span class="p">))</span>
</span><span id="InformationGatheringEnv.__init__-34"><a href="#InformationGatheringEnv.__init__-34"><span class="linenos"> 34</span></a>
</span><span id="InformationGatheringEnv.__init__-35"><a href="#InformationGatheringEnv.__init__-35"><span class="linenos"> 35</span></a>		<span class="c1"># Define the observation space and the action space #</span>
</span><span id="InformationGatheringEnv.__init__-36"><a href="#InformationGatheringEnv.__init__-36"><span class="linenos"> 36</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">observation_type</span> <span class="o">=</span> <span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;observation_type&#39;</span><span class="p">]</span>
</span><span id="InformationGatheringEnv.__init__-37"><a href="#InformationGatheringEnv.__init__-37"><span class="linenos"> 37</span></a>
</span><span id="InformationGatheringEnv.__init__-38"><a href="#InformationGatheringEnv.__init__-38"><span class="linenos"> 38</span></a>		<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">observation_type</span> <span class="o">==</span> <span class="s1">&#39;visual&#39;</span><span class="p">:</span>
</span><span id="InformationGatheringEnv.__init__-39"><a href="#InformationGatheringEnv.__init__-39"><span class="linenos"> 39</span></a>			<span class="c1"># The visual observation space is defined as 5 images:</span>
</span><span id="InformationGatheringEnv.__init__-40"><a href="#InformationGatheringEnv.__init__-40"><span class="linenos"> 40</span></a>			<span class="c1"># - The navigation map</span>
</span><span id="InformationGatheringEnv.__init__-41"><a href="#InformationGatheringEnv.__init__-41"><span class="linenos"> 41</span></a>			<span class="c1"># - The observer position on the map</span>
</span><span id="InformationGatheringEnv.__init__-42"><a href="#InformationGatheringEnv.__init__-42"><span class="linenos"> 42</span></a>			<span class="c1"># - The other vehicles positions on the map</span>
</span><span id="InformationGatheringEnv.__init__-43"><a href="#InformationGatheringEnv.__init__-43"><span class="linenos"> 43</span></a>			<span class="c1"># - The mu of the model</span>
</span><span id="InformationGatheringEnv.__init__-44"><a href="#InformationGatheringEnv.__init__-44"><span class="linenos"> 44</span></a>			<span class="c1"># - The uncertainty of the model</span>
</span><span id="InformationGatheringEnv.__init__-45"><a href="#InformationGatheringEnv.__init__-45"><span class="linenos"> 45</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">observation_space</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Box</span><span class="p">(</span><span class="n">low</span><span class="o">=-</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="o">*</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;navigation_map&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
</span><span id="InformationGatheringEnv.__init__-46"><a href="#InformationGatheringEnv.__init__-46"><span class="linenos"> 46</span></a>		<span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">observation_type</span> <span class="o">==</span> <span class="s1">&#39;hybrid&#39;</span><span class="p">:</span>
</span><span id="InformationGatheringEnv.__init__-47"><a href="#InformationGatheringEnv.__init__-47"><span class="linenos"> 47</span></a>			<span class="c1"># The hybrid state is its position [x,y] and 3 images [fleet positions, mean-model, uncertainty] #</span>
</span><span id="InformationGatheringEnv.__init__-48"><a href="#InformationGatheringEnv.__init__-48"><span class="linenos"> 48</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">observation_space</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Dict</span><span class="p">({</span><span class="s1">&#39;visual_state&#39;</span><span class="p">:</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Box</span><span class="p">(</span><span class="n">low</span><span class="o">=-</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="o">*</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;navigation_map&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)),</span>
</span><span id="InformationGatheringEnv.__init__-49"><a href="#InformationGatheringEnv.__init__-49"><span class="linenos"> 49</span></a>			                                          <span class="s1">&#39;odometry&#39;</span><span class="p">:</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Box</span><span class="p">(</span><span class="n">low</span><span class="o">=-</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,))})</span>
</span><span id="InformationGatheringEnv.__init__-50"><a href="#InformationGatheringEnv.__init__-50"><span class="linenos"> 50</span></a>		<span class="k">else</span><span class="p">:</span>
</span><span id="InformationGatheringEnv.__init__-51"><a href="#InformationGatheringEnv.__init__-51"><span class="linenos"> 51</span></a>			<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s1">&#39;This observation type is not defined. Pleas choose between: visual / hybrid&#39;</span><span class="p">)</span>
</span><span id="InformationGatheringEnv.__init__-52"><a href="#InformationGatheringEnv.__init__-52"><span class="linenos"> 52</span></a>
</span><span id="InformationGatheringEnv.__init__-53"><a href="#InformationGatheringEnv.__init__-53"><span class="linenos"> 53</span></a>		<span class="c1"># Define the type of the action #</span>
</span><span id="InformationGatheringEnv.__init__-54"><a href="#InformationGatheringEnv.__init__-54"><span class="linenos"> 54</span></a>		<span class="k">if</span> <span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;movement_type&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;DIRECTIONAL&#39;</span><span class="p">:</span>
</span><span id="InformationGatheringEnv.__init__-55"><a href="#InformationGatheringEnv.__init__-55"><span class="linenos"> 55</span></a>			<span class="c1"># The action space is a discrete action space with number_of_actions actions:</span>
</span><span id="InformationGatheringEnv.__init__-56"><a href="#InformationGatheringEnv.__init__-56"><span class="linenos"> 56</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">action_space</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Discrete</span><span class="p">(</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;number_of_actions&#39;</span><span class="p">])</span>
</span><span id="InformationGatheringEnv.__init__-57"><a href="#InformationGatheringEnv.__init__-57"><span class="linenos"> 57</span></a>		<span class="k">elif</span> <span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;movement_type&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;DIRECTIONAL_DISTANCE&#39;</span><span class="p">:</span>
</span><span id="InformationGatheringEnv.__init__-58"><a href="#InformationGatheringEnv.__init__-58"><span class="linenos"> 58</span></a>			<span class="c1"># This action is defined with the direction and the distance to move (both normalized between -1 and 1) #</span>
</span><span id="InformationGatheringEnv.__init__-59"><a href="#InformationGatheringEnv.__init__-59"><span class="linenos"> 59</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">action_space</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Box</span><span class="p">(</span><span class="n">low</span><span class="o">=-</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,))</span>
</span><span id="InformationGatheringEnv.__init__-60"><a href="#InformationGatheringEnv.__init__-60"><span class="linenos"> 60</span></a>		<span class="k">else</span><span class="p">:</span>
</span><span id="InformationGatheringEnv.__init__-61"><a href="#InformationGatheringEnv.__init__-61"><span class="linenos"> 61</span></a>			<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s1">&#39;This movement type is not defined. Pleas choose between: DIRECTIONAL / DIRECTIONAL+DISTANCE&#39;</span><span class="p">)</span>
</span><span id="InformationGatheringEnv.__init__-62"><a href="#InformationGatheringEnv.__init__-62"><span class="linenos"> 62</span></a>
</span><span id="InformationGatheringEnv.__init__-63"><a href="#InformationGatheringEnv.__init__-63"><span class="linenos"> 63</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">measurements</span> <span class="o">=</span> <span class="kc">None</span>  <span class="c1"># Measurements of the environment (Usually a dictionary)</span>
</span><span id="InformationGatheringEnv.__init__-64"><a href="#InformationGatheringEnv.__init__-64"><span class="linenos"> 64</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">resetted</span> <span class="o">=</span> <span class="kc">False</span>  <span class="c1"># Flag to check if the environment has been resetted #</span>
</span><span id="InformationGatheringEnv.__init__-65"><a href="#InformationGatheringEnv.__init__-65"><span class="linenos"> 65</span></a>
</span><span id="InformationGatheringEnv.__init__-66"><a href="#InformationGatheringEnv.__init__-66"><span class="linenos"> 66</span></a>		<span class="c1"># Gym Environment variables #</span>
</span><span id="InformationGatheringEnv.__init__-67"><a href="#InformationGatheringEnv.__init__-67"><span class="linenos"> 67</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">rewards</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="InformationGatheringEnv.__init__-68"><a href="#InformationGatheringEnv.__init__-68"><span class="linenos"> 68</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">states</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="InformationGatheringEnv.__init__-69"><a href="#InformationGatheringEnv.__init__-69"><span class="linenos"> 69</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">infos</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="InformationGatheringEnv.__init__-70"><a href="#InformationGatheringEnv.__init__-70"><span class="linenos"> 70</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">dones</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="InformationGatheringEnv.__init__-71"><a href="#InformationGatheringEnv.__init__-71"><span class="linenos"> 71</span></a>
</span><span id="InformationGatheringEnv.__init__-72"><a href="#InformationGatheringEnv.__init__-72"><span class="linenos"> 72</span></a>		<span class="c1"># Ground truth - The task to solve #</span>
</span><span id="InformationGatheringEnv.__init__-73"><a href="#InformationGatheringEnv.__init__-73"><span class="linenos"> 73</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">random_benchmark</span> <span class="o">=</span> <span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;random_benchmark&#39;</span><span class="p">]</span>
</span><span id="InformationGatheringEnv.__init__-74"><a href="#InformationGatheringEnv.__init__-74"><span class="linenos"> 74</span></a>		<span class="k">if</span> <span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;dynamic&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;OilSpillEnv&#39;</span><span class="p">:</span>
</span><span id="InformationGatheringEnv.__init__-75"><a href="#InformationGatheringEnv.__init__-75"><span class="linenos"> 75</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">ground_truth</span> <span class="o">=</span> <span class="n">OilSpillEnv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;navigation_map&#39;</span><span class="p">],</span> <span class="n">dt</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">flow</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">kc</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">kw</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;seed&#39;</span><span class="p">])</span>
</span><span id="InformationGatheringEnv.__init__-76"><a href="#InformationGatheringEnv.__init__-76"><span class="linenos"> 76</span></a>		<span class="k">elif</span> <span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;dynamic&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;Shekel&#39;</span><span class="p">:</span>
</span><span id="InformationGatheringEnv.__init__-77"><a href="#InformationGatheringEnv.__init__-77"><span class="linenos"> 77</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">ground_truth</span> <span class="o">=</span> <span class="n">Shekel</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;navigation_map&#39;</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="n">max_number_of_peaks</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">is_bounded</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;seed&#39;</span><span class="p">])</span>
</span><span id="InformationGatheringEnv.__init__-78"><a href="#InformationGatheringEnv.__init__-78"><span class="linenos"> 78</span></a>		<span class="k">else</span><span class="p">:</span>
</span><span id="InformationGatheringEnv.__init__-79"><a href="#InformationGatheringEnv.__init__-79"><span class="linenos"> 79</span></a>			<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;This benchmark is not implemented&quot;</span><span class="p">)</span>
</span><span id="InformationGatheringEnv.__init__-80"><a href="#InformationGatheringEnv.__init__-80"><span class="linenos"> 80</span></a>
</span><span id="InformationGatheringEnv.__init__-81"><a href="#InformationGatheringEnv.__init__-81"><span class="linenos"> 81</span></a>		<span class="c1"># [N x 2] matrix with all the possible visitable positions #</span>
</span><span id="InformationGatheringEnv.__init__-82"><a href="#InformationGatheringEnv.__init__-82"><span class="linenos"> 82</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">visitable_positions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;navigation_map&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">))</span>
</span><span id="InformationGatheringEnv.__init__-83"><a href="#InformationGatheringEnv.__init__-83"><span class="linenos"> 83</span></a>
</span><span id="InformationGatheringEnv.__init__-84"><a href="#InformationGatheringEnv.__init__-84"><span class="linenos"> 84</span></a>		<span class="c1"># ---- Parameters of the model (Gaussian Process) ---- #</span>
</span><span id="InformationGatheringEnv.__init__-85"><a href="#InformationGatheringEnv.__init__-85"><span class="linenos"> 85</span></a>		<span class="c1"># Kernel for model-conditioning #</span>
</span><span id="InformationGatheringEnv.__init__-86"><a href="#InformationGatheringEnv.__init__-86"><span class="linenos"> 86</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">kernel</span> <span class="o">=</span> <span class="n">RBF</span><span class="p">(</span><span class="n">length_scale</span><span class="o">=</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;kernel_length_scale&#39;</span><span class="p">],</span> <span class="n">length_scale_bounds</span><span class="o">=</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">))</span>
</span><span id="InformationGatheringEnv.__init__-87"><a href="#InformationGatheringEnv.__init__-87"><span class="linenos"> 87</span></a>		<span class="c1"># The Gaussian Process #</span>
</span><span id="InformationGatheringEnv.__init__-88"><a href="#InformationGatheringEnv.__init__-88"><span class="linenos"> 88</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">GaussianProcess</span> <span class="o">=</span> <span class="n">GaussianProcessRegressor</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">kernel</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">n_restarts_optimizer</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</span><span id="InformationGatheringEnv.__init__-89"><a href="#InformationGatheringEnv.__init__-89"><span class="linenos"> 89</span></a>		<span class="c1"># The list of measured values (y in GP)</span>
</span><span id="InformationGatheringEnv.__init__-90"><a href="#InformationGatheringEnv.__init__-90"><span class="linenos"> 90</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">measured_values</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="InformationGatheringEnv.__init__-91"><a href="#InformationGatheringEnv.__init__-91"><span class="linenos"> 91</span></a>		<span class="c1"># The list of measured positions (x in GP)</span>
</span><span id="InformationGatheringEnv.__init__-92"><a href="#InformationGatheringEnv.__init__-92"><span class="linenos"> 92</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">measured_locations</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="InformationGatheringEnv.__init__-93"><a href="#InformationGatheringEnv.__init__-93"><span class="linenos"> 93</span></a>
</span><span id="InformationGatheringEnv.__init__-94"><a href="#InformationGatheringEnv.__init__-94"><span class="linenos"> 94</span></a>		<span class="c1"># The surrogate model #</span>
</span><span id="InformationGatheringEnv.__init__-95"><a href="#InformationGatheringEnv.__init__-95"><span class="linenos"> 95</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">mu</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="InformationGatheringEnv.__init__-96"><a href="#InformationGatheringEnv.__init__-96"><span class="linenos"> 96</span></a>		<span class="c1"># The surrogate uncertainty #</span>
</span><span id="InformationGatheringEnv.__init__-97"><a href="#InformationGatheringEnv.__init__-97"><span class="linenos"> 97</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">uncertainty</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="InformationGatheringEnv.__init__-98"><a href="#InformationGatheringEnv.__init__-98"><span class="linenos"> 98</span></a>
</span><span id="InformationGatheringEnv.__init__-99"><a href="#InformationGatheringEnv.__init__-99"><span class="linenos"> 99</span></a>		<span class="c1"># Array of the last measurements of every agent (to compute the reward) #</span>
</span><span id="InformationGatheringEnv.__init__-100"><a href="#InformationGatheringEnv.__init__-100"><span class="linenos">100</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">last_measurement_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.0</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">number_of_agents</span><span class="p">)])</span>
</span><span id="InformationGatheringEnv.__init__-101"><a href="#InformationGatheringEnv.__init__-101"><span class="linenos">101</span></a>		<span class="c1"># The contribution of every agent to the uncertainty decrement (to compute the reward)#</span>
</span><span id="InformationGatheringEnv.__init__-102"><a href="#InformationGatheringEnv.__init__-102"><span class="linenos">102</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">intermediate_uncertainty_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">visitable_positions</span><span class="p">),))</span>
</span><span id="InformationGatheringEnv.__init__-103"><a href="#InformationGatheringEnv.__init__-103"><span class="linenos">103</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">individual_uncertainty_decrement</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.0</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">number_of_agents</span><span class="p">)])</span>
</span><span id="InformationGatheringEnv.__init__-104"><a href="#InformationGatheringEnv.__init__-104"><span class="linenos">104</span></a>		<span class="c1"># The error of the model #</span>
</span><span id="InformationGatheringEnv.__init__-105"><a href="#InformationGatheringEnv.__init__-105"><span class="linenos">105</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">mse</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="InformationGatheringEnv.__init__-106"><a href="#InformationGatheringEnv.__init__-106"><span class="linenos">106</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">mse_ant</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="InformationGatheringEnv.__init__-107"><a href="#InformationGatheringEnv.__init__-107"><span class="linenos">107</span></a>
</span><span id="InformationGatheringEnv.__init__-108"><a href="#InformationGatheringEnv.__init__-108"><span class="linenos">108</span></a>		<span class="c1"># For the collision computation #</span>
</span><span id="InformationGatheringEnv.__init__-109"><a href="#InformationGatheringEnv.__init__-109"><span class="linenos">109</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">number_of_collisions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">number_of_agents</span><span class="p">,))</span>
</span><span id="InformationGatheringEnv.__init__-110"><a href="#InformationGatheringEnv.__init__-110"><span class="linenos">110</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">max_collisions</span> <span class="o">=</span> <span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;max_collisions&#39;</span><span class="p">]</span>
</span><span id="InformationGatheringEnv.__init__-111"><a href="#InformationGatheringEnv.__init__-111"><span class="linenos">111</span></a>
</span><span id="InformationGatheringEnv.__init__-112"><a href="#InformationGatheringEnv.__init__-112"><span class="linenos">112</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">_eval</span> <span class="o">=</span> <span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;eval_mode&#39;</span><span class="p">]</span>
</span><span id="InformationGatheringEnv.__init__-113"><a href="#InformationGatheringEnv.__init__-113"><span class="linenos">113</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">fig</span> <span class="o">=</span> <span class="kc">None</span>
</span></pre></div>


    

                            </div>
                            <div id="InformationGatheringEnv.reset" class="classattr">
                                        <input id="InformationGatheringEnv.reset-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">reset</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span></span><span class="return-annotation">) -> <span class="nb">dict</span>:</span></span>

                <label class="view-source-button" for="InformationGatheringEnv.reset-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#InformationGatheringEnv.reset"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="InformationGatheringEnv.reset-115"><a href="#InformationGatheringEnv.reset-115"><span class="linenos">115</span></a>	<span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
</span><span id="InformationGatheringEnv.reset-116"><a href="#InformationGatheringEnv.reset-116"><span class="linenos">116</span></a>		<span class="sd">&quot;&quot;&quot; Reset all the variables and the fleet. This method must be called before the first step of the episode.</span>
</span><span id="InformationGatheringEnv.reset-117"><a href="#InformationGatheringEnv.reset-117"><span class="linenos">117</span></a><span class="sd">		It resets the fleet position, the measurements, the ground truth, the surrogate model and the uncertainty.</span>
</span><span id="InformationGatheringEnv.reset-118"><a href="#InformationGatheringEnv.reset-118"><span class="linenos">118</span></a>
</span><span id="InformationGatheringEnv.reset-119"><a href="#InformationGatheringEnv.reset-119"><span class="linenos">119</span></a><span class="sd">		:return:</span>
</span><span id="InformationGatheringEnv.reset-120"><a href="#InformationGatheringEnv.reset-120"><span class="linenos">120</span></a><span class="sd">			The initial observation of the environment in a dictionary of agents.</span>
</span><span id="InformationGatheringEnv.reset-121"><a href="#InformationGatheringEnv.reset-121"><span class="linenos">121</span></a>
</span><span id="InformationGatheringEnv.reset-122"><a href="#InformationGatheringEnv.reset-122"><span class="linenos">122</span></a><span class="sd">		&quot;&quot;&quot;</span>
</span><span id="InformationGatheringEnv.reset-123"><a href="#InformationGatheringEnv.reset-123"><span class="linenos">123</span></a>
</span><span id="InformationGatheringEnv.reset-124"><a href="#InformationGatheringEnv.reset-124"><span class="linenos">124</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">resetted</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="InformationGatheringEnv.reset-125"><a href="#InformationGatheringEnv.reset-125"><span class="linenos">125</span></a>
</span><span id="InformationGatheringEnv.reset-126"><a href="#InformationGatheringEnv.reset-126"><span class="linenos">126</span></a>		<span class="c1"># Reset the dones #</span>
</span><span id="InformationGatheringEnv.reset-127"><a href="#InformationGatheringEnv.reset-127"><span class="linenos">127</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">dones</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span> <span class="kc">False</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">number_of_agents</span><span class="p">)}</span>
</span><span id="InformationGatheringEnv.reset-128"><a href="#InformationGatheringEnv.reset-128"><span class="linenos">128</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">dones</span><span class="p">[</span><span class="s1">&#39;__all__&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="InformationGatheringEnv.reset-129"><a href="#InformationGatheringEnv.reset-129"><span class="linenos">129</span></a>
</span><span id="InformationGatheringEnv.reset-130"><a href="#InformationGatheringEnv.reset-130"><span class="linenos">130</span></a>		<span class="c1"># Reset the ground truth and update the ground truth (if the ground truth is dynamic) #</span>
</span><span id="InformationGatheringEnv.reset-131"><a href="#InformationGatheringEnv.reset-131"><span class="linenos">131</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">ground_truth</span><span class="o">.</span><span class="n">reset</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_benchmark</span><span class="p">)</span>
</span><span id="InformationGatheringEnv.reset-132"><a href="#InformationGatheringEnv.reset-132"><span class="linenos">132</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">update_vehicles_ground_truths</span><span class="p">()</span>
</span><span id="InformationGatheringEnv.reset-133"><a href="#InformationGatheringEnv.reset-133"><span class="linenos">133</span></a>
</span><span id="InformationGatheringEnv.reset-134"><a href="#InformationGatheringEnv.reset-134"><span class="linenos">134</span></a>		<span class="c1"># Reset the model parameters#</span>
</span><span id="InformationGatheringEnv.reset-135"><a href="#InformationGatheringEnv.reset-135"><span class="linenos">135</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">measured_locations</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="InformationGatheringEnv.reset-136"><a href="#InformationGatheringEnv.reset-136"><span class="linenos">136</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">measured_values</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="InformationGatheringEnv.reset-137"><a href="#InformationGatheringEnv.reset-137"><span class="linenos">137</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">mu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;navigation_map&#39;</span><span class="p">])</span>
</span><span id="InformationGatheringEnv.reset-138"><a href="#InformationGatheringEnv.reset-138"><span class="linenos">138</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">uncertainty</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;navigation_map&#39;</span><span class="p">])</span>
</span><span id="InformationGatheringEnv.reset-139"><a href="#InformationGatheringEnv.reset-139"><span class="linenos">139</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">number_of_collisions</span><span class="p">[:]</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="InformationGatheringEnv.reset-140"><a href="#InformationGatheringEnv.reset-140"><span class="linenos">140</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">mse_ant</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="InformationGatheringEnv.reset-141"><a href="#InformationGatheringEnv.reset-141"><span class="linenos">141</span></a>
</span><span id="InformationGatheringEnv.reset-142"><a href="#InformationGatheringEnv.reset-142"><span class="linenos">142</span></a>		<span class="c1"># Reset the fleet and take the first measurements #</span>
</span><span id="InformationGatheringEnv.reset-143"><a href="#InformationGatheringEnv.reset-143"><span class="linenos">143</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">measurements</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fleet</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
</span><span id="InformationGatheringEnv.reset-144"><a href="#InformationGatheringEnv.reset-144"><span class="linenos">144</span></a>
</span><span id="InformationGatheringEnv.reset-145"><a href="#InformationGatheringEnv.reset-145"><span class="linenos">145</span></a>		<span class="c1"># Update the model with the initial values #</span>
</span><span id="InformationGatheringEnv.reset-146"><a href="#InformationGatheringEnv.reset-146"><span class="linenos">146</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">last_measurement_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.0</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">number_of_agents</span><span class="p">)])</span>
</span><span id="InformationGatheringEnv.reset-147"><a href="#InformationGatheringEnv.reset-147"><span class="linenos">147</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">intermediate_uncertainty_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">visitable_positions</span><span class="p">),))</span>
</span><span id="InformationGatheringEnv.reset-148"><a href="#InformationGatheringEnv.reset-148"><span class="linenos">148</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">individual_uncertainty_decrement</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.0</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">number_of_agents</span><span class="p">)])</span>
</span><span id="InformationGatheringEnv.reset-149"><a href="#InformationGatheringEnv.reset-149"><span class="linenos">149</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">uncertainty</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">update_model</span><span class="p">(</span><span class="n">new_measurements</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">measurements</span><span class="p">)</span>
</span><span id="InformationGatheringEnv.reset-150"><a href="#InformationGatheringEnv.reset-150"><span class="linenos">150</span></a>
</span><span id="InformationGatheringEnv.reset-151"><a href="#InformationGatheringEnv.reset-151"><span class="linenos">151</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">uncertainty_0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">uncertainty</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</span><span id="InformationGatheringEnv.reset-152"><a href="#InformationGatheringEnv.reset-152"><span class="linenos">152</span></a>
</span><span id="InformationGatheringEnv.reset-153"><a href="#InformationGatheringEnv.reset-153"><span class="linenos">153</span></a>		<span class="c1"># Update the state</span>
</span><span id="InformationGatheringEnv.reset-154"><a href="#InformationGatheringEnv.reset-154"><span class="linenos">154</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">process_states</span><span class="p">()</span>
</span><span id="InformationGatheringEnv.reset-155"><a href="#InformationGatheringEnv.reset-155"><span class="linenos">155</span></a>
</span><span id="InformationGatheringEnv.reset-156"><a href="#InformationGatheringEnv.reset-156"><span class="linenos">156</span></a>		<span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">states</span>
</span></pre></div>


            <div class="docstring"><p>Reset all the variables and the fleet. This method must be called before the first step of the episode.
It resets the fleet position, the measurements, the ground truth, the surrogate model and the uncertainty.</p>

<h6 id="returns">Returns</h6>

<blockquote>
<pre><code>    The initial observation of the environment in a dictionary of agents.
</code></pre>
</blockquote>
</div>


                            </div>
                            <div id="InformationGatheringEnv.eval" class="classattr">
                                        <input id="InformationGatheringEnv.eval-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">eval</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="InformationGatheringEnv.eval-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#InformationGatheringEnv.eval"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="InformationGatheringEnv.eval-158"><a href="#InformationGatheringEnv.eval-158"><span class="linenos">158</span></a>	<span class="k">def</span> <span class="nf">eval</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="InformationGatheringEnv.eval-159"><a href="#InformationGatheringEnv.eval-159"><span class="linenos">159</span></a>		<span class="sd">&quot;&quot;&quot; Change the environment to evaluation mode. In this mode,</span>
</span><span id="InformationGatheringEnv.eval-160"><a href="#InformationGatheringEnv.eval-160"><span class="linenos">160</span></a><span class="sd">		computationally expensive operations are enabled for evaluation. &quot;&quot;&quot;</span>
</span><span id="InformationGatheringEnv.eval-161"><a href="#InformationGatheringEnv.eval-161"><span class="linenos">161</span></a>
</span><span id="InformationGatheringEnv.eval-162"><a href="#InformationGatheringEnv.eval-162"><span class="linenos">162</span></a>		<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Environment in eval mode!&quot;</span><span class="p">)</span>
</span><span id="InformationGatheringEnv.eval-163"><a href="#InformationGatheringEnv.eval-163"><span class="linenos">163</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">_eval</span> <span class="o">=</span> <span class="kc">True</span>
</span></pre></div>


            <div class="docstring"><p>Change the environment to evaluation mode. In this mode,
computationally expensive operations are enabled for evaluation.</p>
</div>


                            </div>
                            <div id="InformationGatheringEnv.update_model" class="classattr">
                                        <input id="InformationGatheringEnv.update_model-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">update_model</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">new_measurements</span><span class="p">:</span> <span class="nb">dict</span>,</span><span class="param">	<span class="n">agents_ids</span><span class="o">=</span><span class="kc">None</span></span><span class="return-annotation">) -> (&lt;class &#x27;numpy.ndarray&#x27;&gt;, &lt;class &#x27;numpy.ndarray&#x27;&gt;):</span></span>

                <label class="view-source-button" for="InformationGatheringEnv.update_model-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#InformationGatheringEnv.update_model"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="InformationGatheringEnv.update_model-165"><a href="#InformationGatheringEnv.update_model-165"><span class="linenos">165</span></a>	<span class="k">def</span> <span class="nf">update_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">new_measurements</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span> <span class="n">agents_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
</span><span id="InformationGatheringEnv.update_model-166"><a href="#InformationGatheringEnv.update_model-166"><span class="linenos">166</span></a>		<span class="sd">&quot;&quot;&quot;</span>
</span><span id="InformationGatheringEnv.update_model-167"><a href="#InformationGatheringEnv.update_model-167"><span class="linenos">167</span></a><span class="sd">		Fit the gaussian process using the new_measurements and return a new inferred map and its uncertainty.</span>
</span><span id="InformationGatheringEnv.update_model-168"><a href="#InformationGatheringEnv.update_model-168"><span class="linenos">168</span></a><span class="sd">		The process will update the gaussian model sequentially for each agent in *agents_ids*.</span>
</span><span id="InformationGatheringEnv.update_model-169"><a href="#InformationGatheringEnv.update_model-169"><span class="linenos">169</span></a>
</span><span id="InformationGatheringEnv.update_model-170"><a href="#InformationGatheringEnv.update_model-170"><span class="linenos">170</span></a>
</span><span id="InformationGatheringEnv.update_model-171"><a href="#InformationGatheringEnv.update_model-171"><span class="linenos">171</span></a><span class="sd">		:param new_measurements: The new measurements to fit the model with in a dictionary.</span>
</span><span id="InformationGatheringEnv.update_model-172"><a href="#InformationGatheringEnv.update_model-172"><span class="linenos">172</span></a><span class="sd">		:param agents_ids: The ids of those agents that generated the measurements. If None, all the agents will be updated.</span>
</span><span id="InformationGatheringEnv.update_model-173"><a href="#InformationGatheringEnv.update_model-173"><span class="linenos">173</span></a>
</span><span id="InformationGatheringEnv.update_model-174"><a href="#InformationGatheringEnv.update_model-174"><span class="linenos">174</span></a><span class="sd">		:return:</span>
</span><span id="InformationGatheringEnv.update_model-175"><a href="#InformationGatheringEnv.update_model-175"><span class="linenos">175</span></a><span class="sd">			- mu - The new inferred map mu.</span>
</span><span id="InformationGatheringEnv.update_model-176"><a href="#InformationGatheringEnv.update_model-176"><span class="linenos">176</span></a><span class="sd">			- sigma - The new inferred uncertainty sigma.</span>
</span><span id="InformationGatheringEnv.update_model-177"><a href="#InformationGatheringEnv.update_model-177"><span class="linenos">177</span></a>
</span><span id="InformationGatheringEnv.update_model-178"><a href="#InformationGatheringEnv.update_model-178"><span class="linenos">178</span></a><span class="sd">		&quot;&quot;&quot;</span>
</span><span id="InformationGatheringEnv.update_model-179"><a href="#InformationGatheringEnv.update_model-179"><span class="linenos">179</span></a>
</span><span id="InformationGatheringEnv.update_model-180"><a href="#InformationGatheringEnv.update_model-180"><span class="linenos">180</span></a>		<span class="k">if</span> <span class="n">agents_ids</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="InformationGatheringEnv.update_model-181"><a href="#InformationGatheringEnv.update_model-181"><span class="linenos">181</span></a>			<span class="n">agents_ids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">agents_ids</span>
</span><span id="InformationGatheringEnv.update_model-182"><a href="#InformationGatheringEnv.update_model-182"><span class="linenos">182</span></a>		<span class="k">else</span><span class="p">:</span>
</span><span id="InformationGatheringEnv.update_model-183"><a href="#InformationGatheringEnv.update_model-183"><span class="linenos">183</span></a>			<span class="n">new_measurements</span> <span class="o">=</span> <span class="p">[</span><span class="n">new_measurements</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">agents_ids</span><span class="p">]</span>
</span><span id="InformationGatheringEnv.update_model-184"><a href="#InformationGatheringEnv.update_model-184"><span class="linenos">184</span></a>
</span><span id="InformationGatheringEnv.update_model-185"><a href="#InformationGatheringEnv.update_model-185"><span class="linenos">185</span></a>		<span class="n">shufled_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">agents_ids</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">agents_ids</span><span class="p">))))</span>
</span><span id="InformationGatheringEnv.update_model-186"><a href="#InformationGatheringEnv.update_model-186"><span class="linenos">186</span></a>		<span class="n">shuffle</span><span class="p">(</span><span class="n">shufled_list</span><span class="p">)</span>
</span><span id="InformationGatheringEnv.update_model-187"><a href="#InformationGatheringEnv.update_model-187"><span class="linenos">187</span></a>		<span class="k">for</span> <span class="n">agent_id</span><span class="p">,</span> <span class="n">measurement_id</span> <span class="ow">in</span> <span class="n">shufled_list</span><span class="p">:</span>
</span><span id="InformationGatheringEnv.update_model-188"><a href="#InformationGatheringEnv.update_model-188"><span class="linenos">188</span></a>			<span class="c1"># Sequentially update the model for each agent. #</span>
</span><span id="InformationGatheringEnv.update_model-189"><a href="#InformationGatheringEnv.update_model-189"><span class="linenos">189</span></a>
</span><span id="InformationGatheringEnv.update_model-190"><a href="#InformationGatheringEnv.update_model-190"><span class="linenos">190</span></a>			<span class="c1"># Append the data to the list of measurement locations and values #</span>
</span><span id="InformationGatheringEnv.update_model-191"><a href="#InformationGatheringEnv.update_model-191"><span class="linenos">191</span></a>			<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">measured_locations</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="InformationGatheringEnv.update_model-192"><a href="#InformationGatheringEnv.update_model-192"><span class="linenos">192</span></a>				<span class="bp">self</span><span class="o">.</span><span class="n">measured_locations</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="n">new_measurements</span><span class="p">[</span><span class="n">measurement_id</span><span class="p">][</span><span class="s1">&#39;position&#39;</span><span class="p">]])</span>
</span><span id="InformationGatheringEnv.update_model-193"><a href="#InformationGatheringEnv.update_model-193"><span class="linenos">193</span></a>				<span class="c1"># We compute the mean of the measurement-image #</span>
</span><span id="InformationGatheringEnv.update_model-194"><a href="#InformationGatheringEnv.update_model-194"><span class="linenos">194</span></a>				<span class="bp">self</span><span class="o">.</span><span class="n">measured_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">nanmean</span><span class="p">(</span><span class="n">new_measurements</span><span class="p">[</span><span class="n">measurement_id</span><span class="p">][</span><span class="s1">&#39;data&#39;</span><span class="p">])])</span>
</span><span id="InformationGatheringEnv.update_model-195"><a href="#InformationGatheringEnv.update_model-195"><span class="linenos">195</span></a>			<span class="k">else</span><span class="p">:</span>
</span><span id="InformationGatheringEnv.update_model-196"><a href="#InformationGatheringEnv.update_model-196"><span class="linenos">196</span></a>				<span class="bp">self</span><span class="o">.</span><span class="n">measured_locations</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">measured_locations</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="n">new_measurements</span><span class="p">[</span><span class="n">measurement_id</span><span class="p">][</span><span class="s1">&#39;position&#39;</span><span class="p">]])))</span>
</span><span id="InformationGatheringEnv.update_model-197"><a href="#InformationGatheringEnv.update_model-197"><span class="linenos">197</span></a>				<span class="bp">self</span><span class="o">.</span><span class="n">measured_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">measured_values</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">nanmean</span><span class="p">(</span><span class="n">new_measurements</span><span class="p">[</span><span class="n">measurement_id</span><span class="p">][</span><span class="s1">&#39;data&#39;</span><span class="p">])])))</span>
</span><span id="InformationGatheringEnv.update_model-198"><a href="#InformationGatheringEnv.update_model-198"><span class="linenos">198</span></a>
</span><span id="InformationGatheringEnv.update_model-199"><a href="#InformationGatheringEnv.update_model-199"><span class="linenos">199</span></a>			<span class="c1"># Store this last measured value #</span>
</span><span id="InformationGatheringEnv.update_model-200"><a href="#InformationGatheringEnv.update_model-200"><span class="linenos">200</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">last_measurement_values</span><span class="p">[</span><span class="n">agent_id</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">measured_values</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span><span id="InformationGatheringEnv.update_model-201"><a href="#InformationGatheringEnv.update_model-201"><span class="linenos">201</span></a>
</span><span id="InformationGatheringEnv.update_model-202"><a href="#InformationGatheringEnv.update_model-202"><span class="linenos">202</span></a>			<span class="c1"># Fit the gaussian process #</span>
</span><span id="InformationGatheringEnv.update_model-203"><a href="#InformationGatheringEnv.update_model-203"><span class="linenos">203</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">GaussianProcess</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">measured_locations</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">measured_values</span><span class="p">)</span>
</span><span id="InformationGatheringEnv.update_model-204"><a href="#InformationGatheringEnv.update_model-204"><span class="linenos">204</span></a>
</span><span id="InformationGatheringEnv.update_model-205"><a href="#InformationGatheringEnv.update_model-205"><span class="linenos">205</span></a>			<span class="c1"># Compute the mean and the std values for all the visitable positions #</span>
</span><span id="InformationGatheringEnv.update_model-206"><a href="#InformationGatheringEnv.update_model-206"><span class="linenos">206</span></a>			<span class="n">mu_array</span><span class="p">,</span> <span class="n">sigma_array</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">GaussianProcess</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">visitable_positions</span><span class="p">[:],</span> <span class="n">return_std</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="InformationGatheringEnv.update_model-207"><a href="#InformationGatheringEnv.update_model-207"><span class="linenos">207</span></a>
</span><span id="InformationGatheringEnv.update_model-208"><a href="#InformationGatheringEnv.update_model-208"><span class="linenos">208</span></a>			<span class="c1"># Compute the new mean error #</span>
</span><span id="InformationGatheringEnv.update_model-209"><a href="#InformationGatheringEnv.update_model-209"><span class="linenos">209</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">mse</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ground_truth</span><span class="o">.</span><span class="n">ground_truth_field</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">visitable_positions</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">visitable_positions</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">-</span> <span class="n">mu_array</span><span class="p">))</span>
</span><span id="InformationGatheringEnv.update_model-210"><a href="#InformationGatheringEnv.update_model-210"><span class="linenos">210</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">mse_ant</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mse</span>
</span><span id="InformationGatheringEnv.update_model-211"><a href="#InformationGatheringEnv.update_model-211"><span class="linenos">211</span></a>
</span><span id="InformationGatheringEnv.update_model-212"><a href="#InformationGatheringEnv.update_model-212"><span class="linenos">212</span></a>			<span class="c1"># Save the intermediate uncertainty maps for uncertainty credit assignment #</span>
</span><span id="InformationGatheringEnv.update_model-213"><a href="#InformationGatheringEnv.update_model-213"><span class="linenos">213</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">individual_uncertainty_decrement</span><span class="p">[</span><span class="n">agent_id</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">intermediate_uncertainty_values</span> <span class="o">-</span> <span class="n">sigma_array</span><span class="p">)</span>
</span><span id="InformationGatheringEnv.update_model-214"><a href="#InformationGatheringEnv.update_model-214"><span class="linenos">214</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">intermediate_uncertainty_values</span> <span class="o">=</span> <span class="n">sigma_array</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
</span><span id="InformationGatheringEnv.update_model-215"><a href="#InformationGatheringEnv.update_model-215"><span class="linenos">215</span></a>
</span><span id="InformationGatheringEnv.update_model-216"><a href="#InformationGatheringEnv.update_model-216"><span class="linenos">216</span></a>		<span class="c1"># Conform the map of the surrogate model for the state #</span>
</span><span id="InformationGatheringEnv.update_model-217"><a href="#InformationGatheringEnv.update_model-217"><span class="linenos">217</span></a>		<span class="n">mu_map</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;navigation_map&#39;</span><span class="p">])</span>
</span><span id="InformationGatheringEnv.update_model-218"><a href="#InformationGatheringEnv.update_model-218"><span class="linenos">218</span></a>		<span class="n">mu_map</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">visitable_positions</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span>
</span><span id="InformationGatheringEnv.update_model-219"><a href="#InformationGatheringEnv.update_model-219"><span class="linenos">219</span></a>		       <span class="bp">self</span><span class="o">.</span><span class="n">visitable_positions</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="n">mu_array</span>
</span><span id="InformationGatheringEnv.update_model-220"><a href="#InformationGatheringEnv.update_model-220"><span class="linenos">220</span></a>
</span><span id="InformationGatheringEnv.update_model-221"><a href="#InformationGatheringEnv.update_model-221"><span class="linenos">221</span></a>		<span class="n">uncertainty_map</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;navigation_map&#39;</span><span class="p">])</span>
</span><span id="InformationGatheringEnv.update_model-222"><a href="#InformationGatheringEnv.update_model-222"><span class="linenos">222</span></a>		<span class="n">uncertainty_map</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">visitable_positions</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span>
</span><span id="InformationGatheringEnv.update_model-223"><a href="#InformationGatheringEnv.update_model-223"><span class="linenos">223</span></a>		                <span class="bp">self</span><span class="o">.</span><span class="n">visitable_positions</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="n">sigma_array</span>
</span><span id="InformationGatheringEnv.update_model-224"><a href="#InformationGatheringEnv.update_model-224"><span class="linenos">224</span></a>
</span><span id="InformationGatheringEnv.update_model-225"><a href="#InformationGatheringEnv.update_model-225"><span class="linenos">225</span></a>		<span class="k">return</span> <span class="n">mu_map</span><span class="p">,</span> <span class="n">uncertainty_map</span>
</span></pre></div>


            <div class="docstring"><p>Fit the gaussian process using the new_measurements and return a new inferred map and its uncertainty.
The process will update the gaussian model sequentially for each agent in <em>agents_ids</em>.</p>

<h6 id="parameters">Parameters</h6>

<ul>
<li><strong>new_measurements</strong>:  The new measurements to fit the model with in a dictionary.</li>
<li><strong>agents_ids</strong>:  The ids of those agents that generated the measurements. If None, all the agents will be updated.</li>
</ul>

<h6 id="returns">Returns</h6>

<blockquote>
<pre><code>    - mu - The new inferred map mu.
    - sigma - The new inferred uncertainty sigma.
</code></pre>
</blockquote>
</div>


                            </div>
                            <div id="InformationGatheringEnv.reward_function" class="classattr">
                                        <input id="InformationGatheringEnv.reward_function-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">reward_function</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">collision_array</span><span class="p">:</span> <span class="nb">list</span>, </span><span class="param"><span class="n">agents_ids</span><span class="o">=</span><span class="kc">None</span></span><span class="return-annotation">) -> <span class="nb">dict</span>:</span></span>

                <label class="view-source-button" for="InformationGatheringEnv.reward_function-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#InformationGatheringEnv.reward_function"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="InformationGatheringEnv.reward_function-227"><a href="#InformationGatheringEnv.reward_function-227"><span class="linenos">227</span></a>	<span class="k">def</span> <span class="nf">reward_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">collision_array</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span> <span class="n">agents_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
</span><span id="InformationGatheringEnv.reward_function-228"><a href="#InformationGatheringEnv.reward_function-228"><span class="linenos">228</span></a>		<span class="sd">&quot;&quot;&quot; The reward function is defined depending on the reward_type parameter</span>
</span><span id="InformationGatheringEnv.reward_function-229"><a href="#InformationGatheringEnv.reward_function-229"><span class="linenos">229</span></a><span class="sd">		1) &#39;uncertainty&#39;: the reward is merely the uncertainty decrement of each agent. This will serve for complete coverage</span>
</span><span id="InformationGatheringEnv.reward_function-230"><a href="#InformationGatheringEnv.reward_function-230"><span class="linenos">230</span></a><span class="sd">		2) &#39;regret&#39;: the reward is the decrement of uncertainty but weighted with the sampling value of each agent. This will serve for finding maxima</span>
</span><span id="InformationGatheringEnv.reward_function-231"><a href="#InformationGatheringEnv.reward_function-231"><span class="linenos">231</span></a><span class="sd">		3) &#39;error&#39;: the reward is the error between the ground truth and the inferred map. This is for characterization.</span>
</span><span id="InformationGatheringEnv.reward_function-232"><a href="#InformationGatheringEnv.reward_function-232"><span class="linenos">232</span></a>
</span><span id="InformationGatheringEnv.reward_function-233"><a href="#InformationGatheringEnv.reward_function-233"><span class="linenos">233</span></a><span class="sd">		:param collision_array: The collision array of the current state.</span>
</span><span id="InformationGatheringEnv.reward_function-234"><a href="#InformationGatheringEnv.reward_function-234"><span class="linenos">234</span></a><span class="sd">		:param agents_ids: The ids of those agents that are expecting the reward.</span>
</span><span id="InformationGatheringEnv.reward_function-235"><a href="#InformationGatheringEnv.reward_function-235"><span class="linenos">235</span></a>
</span><span id="InformationGatheringEnv.reward_function-236"><a href="#InformationGatheringEnv.reward_function-236"><span class="linenos">236</span></a><span class="sd">		:return:</span>
</span><span id="InformationGatheringEnv.reward_function-237"><a href="#InformationGatheringEnv.reward_function-237"><span class="linenos">237</span></a><span class="sd">			- reward: The reward for each agent in a dictionary.</span>
</span><span id="InformationGatheringEnv.reward_function-238"><a href="#InformationGatheringEnv.reward_function-238"><span class="linenos">238</span></a><span class="sd">		&quot;&quot;&quot;</span>
</span><span id="InformationGatheringEnv.reward_function-239"><a href="#InformationGatheringEnv.reward_function-239"><span class="linenos">239</span></a>
</span><span id="InformationGatheringEnv.reward_function-240"><a href="#InformationGatheringEnv.reward_function-240"><span class="linenos">240</span></a>		<span class="k">if</span> <span class="n">agents_ids</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="InformationGatheringEnv.reward_function-241"><a href="#InformationGatheringEnv.reward_function-241"><span class="linenos">241</span></a>			<span class="n">agents_ids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">agents_ids</span>
</span><span id="InformationGatheringEnv.reward_function-242"><a href="#InformationGatheringEnv.reward_function-242"><span class="linenos">242</span></a>
</span><span id="InformationGatheringEnv.reward_function-243"><a href="#InformationGatheringEnv.reward_function-243"><span class="linenos">243</span></a>		<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;reward_type&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;uncertainty&#39;</span><span class="p">:</span>
</span><span id="InformationGatheringEnv.reward_function-244"><a href="#InformationGatheringEnv.reward_function-244"><span class="linenos">244</span></a>			<span class="n">reward</span> <span class="o">=</span> <span class="mi">100</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">individual_uncertainty_decrement</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">uncertainty_0</span>
</span><span id="InformationGatheringEnv.reward_function-245"><a href="#InformationGatheringEnv.reward_function-245"><span class="linenos">245</span></a>		<span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;reward_type&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;improvement&#39;</span><span class="p">:</span>
</span><span id="InformationGatheringEnv.reward_function-246"><a href="#InformationGatheringEnv.reward_function-246"><span class="linenos">246</span></a>			<span class="n">reward</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">individual_uncertainty_decrement</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">last_measurement_values</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">uncertainty_0</span>
</span><span id="InformationGatheringEnv.reward_function-247"><a href="#InformationGatheringEnv.reward_function-247"><span class="linenos">247</span></a>		<span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;reward_type&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;error&#39;</span><span class="p">:</span>
</span><span id="InformationGatheringEnv.reward_function-248"><a href="#InformationGatheringEnv.reward_function-248"><span class="linenos">248</span></a>			<span class="n">reward</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">mse_ant</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">mse</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">number_of_agents</span><span class="p">)])</span>
</span><span id="InformationGatheringEnv.reward_function-249"><a href="#InformationGatheringEnv.reward_function-249"><span class="linenos">249</span></a>		<span class="k">else</span><span class="p">:</span>
</span><span id="InformationGatheringEnv.reward_function-250"><a href="#InformationGatheringEnv.reward_function-250"><span class="linenos">250</span></a>			<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Invalid reward type&quot;</span><span class="p">)</span>
</span><span id="InformationGatheringEnv.reward_function-251"><a href="#InformationGatheringEnv.reward_function-251"><span class="linenos">251</span></a>
</span><span id="InformationGatheringEnv.reward_function-252"><a href="#InformationGatheringEnv.reward_function-252"><span class="linenos">252</span></a>		<span class="c1"># Penalize the agents that collided #</span>
</span><span id="InformationGatheringEnv.reward_function-253"><a href="#InformationGatheringEnv.reward_function-253"><span class="linenos">253</span></a>		<span class="n">reward</span><span class="p">[</span><span class="n">collision_array</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span>
</span><span id="InformationGatheringEnv.reward_function-254"><a href="#InformationGatheringEnv.reward_function-254"><span class="linenos">254</span></a>
</span><span id="InformationGatheringEnv.reward_function-255"><a href="#InformationGatheringEnv.reward_function-255"><span class="linenos">255</span></a>		<span class="k">return</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span> <span class="n">reward</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">agents_ids</span><span class="p">}</span>
</span></pre></div>


            <div class="docstring"><p>The reward function is defined depending on the reward_type parameter
1) 'uncertainty': the reward is merely the uncertainty decrement of each agent. This will serve for complete coverage
2) 'regret': the reward is the decrement of uncertainty but weighted with the sampling value of each agent. This will serve for finding maxima
3) 'error': the reward is the error between the ground truth and the inferred map. This is for characterization.</p>

<h6 id="parameters">Parameters</h6>

<ul>
<li><strong>collision_array</strong>:  The collision array of the current state.</li>
<li><strong>agents_ids</strong>:  The ids of those agents that are expecting the reward.</li>
</ul>

<h6 id="returns">Returns</h6>

<blockquote>
<pre><code>    - reward: The reward for each agent in a dictionary.
</code></pre>
</blockquote>
</div>


                            </div>
                            <div id="InformationGatheringEnv.process_states" class="classattr">
                                        <input id="InformationGatheringEnv.process_states-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">process_states</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">agent_ids</span><span class="o">=</span><span class="kc">None</span></span><span class="return-annotation">) -> <span class="nb">dict</span>:</span></span>

                <label class="view-source-button" for="InformationGatheringEnv.process_states-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#InformationGatheringEnv.process_states"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="InformationGatheringEnv.process_states-257"><a href="#InformationGatheringEnv.process_states-257"><span class="linenos">257</span></a>	<span class="k">def</span> <span class="nf">process_states</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">agent_ids</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
</span><span id="InformationGatheringEnv.process_states-258"><a href="#InformationGatheringEnv.process_states-258"><span class="linenos">258</span></a>		<span class="sd">&quot;&quot;&quot; Render the states of the agents.</span>
</span><span id="InformationGatheringEnv.process_states-259"><a href="#InformationGatheringEnv.process_states-259"><span class="linenos">259</span></a>
</span><span id="InformationGatheringEnv.process_states-260"><a href="#InformationGatheringEnv.process_states-260"><span class="linenos">260</span></a><span class="sd">		:param agent_ids: The ids of those agents that are expecting the state.</span>
</span><span id="InformationGatheringEnv.process_states-261"><a href="#InformationGatheringEnv.process_states-261"><span class="linenos">261</span></a>
</span><span id="InformationGatheringEnv.process_states-262"><a href="#InformationGatheringEnv.process_states-262"><span class="linenos">262</span></a><span class="sd">		:return:</span>
</span><span id="InformationGatheringEnv.process_states-263"><a href="#InformationGatheringEnv.process_states-263"><span class="linenos">263</span></a><span class="sd">			- states: The state of the agents in a dictionary.</span>
</span><span id="InformationGatheringEnv.process_states-264"><a href="#InformationGatheringEnv.process_states-264"><span class="linenos">264</span></a>
</span><span id="InformationGatheringEnv.process_states-265"><a href="#InformationGatheringEnv.process_states-265"><span class="linenos">265</span></a><span class="sd">		&quot;&quot;&quot;</span>
</span><span id="InformationGatheringEnv.process_states-266"><a href="#InformationGatheringEnv.process_states-266"><span class="linenos">266</span></a>
</span><span id="InformationGatheringEnv.process_states-267"><a href="#InformationGatheringEnv.process_states-267"><span class="linenos">267</span></a>		<span class="k">if</span> <span class="n">agent_ids</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="InformationGatheringEnv.process_states-268"><a href="#InformationGatheringEnv.process_states-268"><span class="linenos">268</span></a>			<span class="n">agent_ids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">agents_ids</span>
</span><span id="InformationGatheringEnv.process_states-269"><a href="#InformationGatheringEnv.process_states-269"><span class="linenos">269</span></a>
</span><span id="InformationGatheringEnv.process_states-270"><a href="#InformationGatheringEnv.process_states-270"><span class="linenos">270</span></a>		<span class="n">s</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">individual_state</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">agent_ids</span><span class="p">}</span>
</span><span id="InformationGatheringEnv.process_states-271"><a href="#InformationGatheringEnv.process_states-271"><span class="linenos">271</span></a>
</span><span id="InformationGatheringEnv.process_states-272"><a href="#InformationGatheringEnv.process_states-272"><span class="linenos">272</span></a>		<span class="k">return</span> <span class="n">s</span>
</span></pre></div>


            <div class="docstring"><p>Render the states of the agents.</p>

<h6 id="parameters">Parameters</h6>

<ul>
<li><strong>agent_ids</strong>:  The ids of those agents that are expecting the state.</li>
</ul>

<h6 id="returns">Returns</h6>

<blockquote>
<pre><code>    - states: The state of the agents in a dictionary.
</code></pre>
</blockquote>
</div>


                            </div>
                            <div id="InformationGatheringEnv.individual_state" class="classattr">
                                        <input id="InformationGatheringEnv.individual_state-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">individual_state</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">agent_indx</span><span class="p">:</span> <span class="nb">int</span></span><span class="return-annotation">) -> <span class="n">Union</span><span class="p">[</span><span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="nb">dict</span><span class="p">]</span>:</span></span>

                <label class="view-source-button" for="InformationGatheringEnv.individual_state-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#InformationGatheringEnv.individual_state"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="InformationGatheringEnv.individual_state-274"><a href="#InformationGatheringEnv.individual_state-274"><span class="linenos">274</span></a>	<span class="k">def</span> <span class="nf">individual_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">agent_indx</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="nb">dict</span><span class="p">]:</span>
</span><span id="InformationGatheringEnv.individual_state-275"><a href="#InformationGatheringEnv.individual_state-275"><span class="linenos">275</span></a>		<span class="sd">&quot;&quot;&quot; Return the state of an individual agent.</span>
</span><span id="InformationGatheringEnv.individual_state-276"><a href="#InformationGatheringEnv.individual_state-276"><span class="linenos">276</span></a>
</span><span id="InformationGatheringEnv.individual_state-277"><a href="#InformationGatheringEnv.individual_state-277"><span class="linenos">277</span></a><span class="sd">		:param agent_indx: The index of the agent.</span>
</span><span id="InformationGatheringEnv.individual_state-278"><a href="#InformationGatheringEnv.individual_state-278"><span class="linenos">278</span></a>
</span><span id="InformationGatheringEnv.individual_state-279"><a href="#InformationGatheringEnv.individual_state-279"><span class="linenos">279</span></a><span class="sd">		:return:</span>
</span><span id="InformationGatheringEnv.individual_state-280"><a href="#InformationGatheringEnv.individual_state-280"><span class="linenos">280</span></a><span class="sd">			- state: The state of the agent. Could be a matrix (visual) or a dictionary (hybrid).</span>
</span><span id="InformationGatheringEnv.individual_state-281"><a href="#InformationGatheringEnv.individual_state-281"><span class="linenos">281</span></a>
</span><span id="InformationGatheringEnv.individual_state-282"><a href="#InformationGatheringEnv.individual_state-282"><span class="linenos">282</span></a><span class="sd">		&quot;&quot;&quot;</span>
</span><span id="InformationGatheringEnv.individual_state-283"><a href="#InformationGatheringEnv.individual_state-283"><span class="linenos">283</span></a>
</span><span id="InformationGatheringEnv.individual_state-284"><a href="#InformationGatheringEnv.individual_state-284"><span class="linenos">284</span></a>		<span class="n">other_agents_map</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;navigation_map&#39;</span><span class="p">])</span>
</span><span id="InformationGatheringEnv.individual_state-285"><a href="#InformationGatheringEnv.individual_state-285"><span class="linenos">285</span></a>		<span class="n">other_agents_ids</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">agents_ids</span><span class="p">)</span>
</span><span id="InformationGatheringEnv.individual_state-286"><a href="#InformationGatheringEnv.individual_state-286"><span class="linenos">286</span></a>		<span class="n">other_agents_ids</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">other_agents_ids</span><span class="p">,</span> <span class="n">agent_indx</span><span class="p">)</span>
</span><span id="InformationGatheringEnv.individual_state-287"><a href="#InformationGatheringEnv.individual_state-287"><span class="linenos">287</span></a>
</span><span id="InformationGatheringEnv.individual_state-288"><a href="#InformationGatheringEnv.individual_state-288"><span class="linenos">288</span></a>		<span class="k">for</span> <span class="n">agent_id</span> <span class="ow">in</span> <span class="n">other_agents_ids</span><span class="p">:</span>
</span><span id="InformationGatheringEnv.individual_state-289"><a href="#InformationGatheringEnv.individual_state-289"><span class="linenos">289</span></a>			<span class="n">agent_position</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fleet</span><span class="o">.</span><span class="n">vehicles</span><span class="p">[</span><span class="n">agent_id</span><span class="p">]</span><span class="o">.</span><span class="n">position</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
</span><span id="InformationGatheringEnv.individual_state-290"><a href="#InformationGatheringEnv.individual_state-290"><span class="linenos">290</span></a>			<span class="n">other_agents_map</span><span class="p">[</span><span class="n">agent_position</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">agent_position</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">1.0</span>
</span><span id="InformationGatheringEnv.individual_state-291"><a href="#InformationGatheringEnv.individual_state-291"><span class="linenos">291</span></a>
</span><span id="InformationGatheringEnv.individual_state-292"><a href="#InformationGatheringEnv.individual_state-292"><span class="linenos">292</span></a>		<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">observation_type</span> <span class="o">==</span> <span class="s1">&#39;visual&#39;</span><span class="p">:</span>
</span><span id="InformationGatheringEnv.individual_state-293"><a href="#InformationGatheringEnv.individual_state-293"><span class="linenos">293</span></a>
</span><span id="InformationGatheringEnv.individual_state-294"><a href="#InformationGatheringEnv.individual_state-294"><span class="linenos">294</span></a>			<span class="c1"># First channel: navigation/obstacle map</span>
</span><span id="InformationGatheringEnv.individual_state-295"><a href="#InformationGatheringEnv.individual_state-295"><span class="linenos">295</span></a>			<span class="n">nav_map</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;navigation_map&#39;</span><span class="p">])</span>
</span><span id="InformationGatheringEnv.individual_state-296"><a href="#InformationGatheringEnv.individual_state-296"><span class="linenos">296</span></a>
</span><span id="InformationGatheringEnv.individual_state-297"><a href="#InformationGatheringEnv.individual_state-297"><span class="linenos">297</span></a>			<span class="c1"># Second channel: self-position map</span>
</span><span id="InformationGatheringEnv.individual_state-298"><a href="#InformationGatheringEnv.individual_state-298"><span class="linenos">298</span></a>			<span class="n">position_map</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;navigation_map&#39;</span><span class="p">])</span>
</span><span id="InformationGatheringEnv.individual_state-299"><a href="#InformationGatheringEnv.individual_state-299"><span class="linenos">299</span></a>			<span class="n">agent_position</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fleet</span><span class="o">.</span><span class="n">vehicles</span><span class="p">[</span><span class="n">agent_indx</span><span class="p">]</span><span class="o">.</span><span class="n">position</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
</span><span id="InformationGatheringEnv.individual_state-300"><a href="#InformationGatheringEnv.individual_state-300"><span class="linenos">300</span></a>			<span class="n">position_map</span><span class="p">[</span><span class="n">agent_position</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">agent_position</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">1.0</span>
</span><span id="InformationGatheringEnv.individual_state-301"><a href="#InformationGatheringEnv.individual_state-301"><span class="linenos">301</span></a>
</span><span id="InformationGatheringEnv.individual_state-302"><a href="#InformationGatheringEnv.individual_state-302"><span class="linenos">302</span></a>			<span class="c1"># Note that the mu and sigma maps are already normalized to [0, 1]</span>
</span><span id="InformationGatheringEnv.individual_state-303"><a href="#InformationGatheringEnv.individual_state-303"><span class="linenos">303</span></a>			<span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">nav_map</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">],</span>
</span><span id="InformationGatheringEnv.individual_state-304"><a href="#InformationGatheringEnv.individual_state-304"><span class="linenos">304</span></a>			                       <span class="n">position_map</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">],</span>
</span><span id="InformationGatheringEnv.individual_state-305"><a href="#InformationGatheringEnv.individual_state-305"><span class="linenos">305</span></a>			                       <span class="n">other_agents_map</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">],</span>
</span><span id="InformationGatheringEnv.individual_state-306"><a href="#InformationGatheringEnv.individual_state-306"><span class="linenos">306</span></a>			                       <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">],</span> <span class="n">a_min</span><span class="o">=-</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">a_max</span><span class="o">=</span><span class="mf">1.0</span><span class="p">),</span>
</span><span id="InformationGatheringEnv.individual_state-307"><a href="#InformationGatheringEnv.individual_state-307"><span class="linenos">307</span></a>			                       <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">uncertainty</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">],</span> <span class="n">a_min</span><span class="o">=-</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">a_max</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)))</span>
</span><span id="InformationGatheringEnv.individual_state-308"><a href="#InformationGatheringEnv.individual_state-308"><span class="linenos">308</span></a>
</span><span id="InformationGatheringEnv.individual_state-309"><a href="#InformationGatheringEnv.individual_state-309"><span class="linenos">309</span></a>		<span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">observation_type</span> <span class="o">==</span> <span class="s1">&#39;hybrid&#39;</span><span class="p">:</span>
</span><span id="InformationGatheringEnv.individual_state-310"><a href="#InformationGatheringEnv.individual_state-310"><span class="linenos">310</span></a>
</span><span id="InformationGatheringEnv.individual_state-311"><a href="#InformationGatheringEnv.individual_state-311"><span class="linenos">311</span></a>			<span class="k">return</span> <span class="p">{</span><span class="s1">&#39;visual_state&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">],</span>
</span><span id="InformationGatheringEnv.individual_state-312"><a href="#InformationGatheringEnv.individual_state-312"><span class="linenos">312</span></a>			                                        <span class="bp">self</span><span class="o">.</span><span class="n">uncertainty</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">],</span>
</span><span id="InformationGatheringEnv.individual_state-313"><a href="#InformationGatheringEnv.individual_state-313"><span class="linenos">313</span></a>			                                        <span class="n">other_agents_map</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">])),</span>
</span><span id="InformationGatheringEnv.individual_state-314"><a href="#InformationGatheringEnv.individual_state-314"><span class="linenos">314</span></a>			        <span class="s1">&#39;odometry&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">fleet</span><span class="o">.</span><span class="n">vehicles</span><span class="p">[</span><span class="n">agent_indx</span><span class="p">]</span><span class="o">.</span><span class="n">position</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;navigation_map&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">}</span>
</span></pre></div>


            <div class="docstring"><p>Return the state of an individual agent.</p>

<h6 id="parameters">Parameters</h6>

<ul>
<li><strong>agent_indx</strong>:  The index of the agent.</li>
</ul>

<h6 id="returns">Returns</h6>

<blockquote>
<pre><code>    - state: The state of the agent. Could be a matrix (visual) or a dictionary (hybrid).
</code></pre>
</blockquote>
</div>


                            </div>
                            <div id="InformationGatheringEnv.update_vehicles_ground_truths" class="classattr">
                                        <input id="InformationGatheringEnv.update_vehicles_ground_truths-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">update_vehicles_ground_truths</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="InformationGatheringEnv.update_vehicles_ground_truths-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#InformationGatheringEnv.update_vehicles_ground_truths"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="InformationGatheringEnv.update_vehicles_ground_truths-316"><a href="#InformationGatheringEnv.update_vehicles_ground_truths-316"><span class="linenos">316</span></a>	<span class="k">def</span> <span class="nf">update_vehicles_ground_truths</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span id="InformationGatheringEnv.update_vehicles_ground_truths-317"><a href="#InformationGatheringEnv.update_vehicles_ground_truths-317"><span class="linenos">317</span></a>		<span class="sd">&quot;&quot;&quot; Setter to update the ground truth of the vehicles. &quot;&quot;&quot;</span>
</span><span id="InformationGatheringEnv.update_vehicles_ground_truths-318"><a href="#InformationGatheringEnv.update_vehicles_ground_truths-318"><span class="linenos">318</span></a>
</span><span id="InformationGatheringEnv.update_vehicles_ground_truths-319"><a href="#InformationGatheringEnv.update_vehicles_ground_truths-319"><span class="linenos">319</span></a>		<span class="k">for</span> <span class="n">vehicle</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">fleet</span><span class="o">.</span><span class="n">vehicles</span><span class="p">:</span>
</span><span id="InformationGatheringEnv.update_vehicles_ground_truths-320"><a href="#InformationGatheringEnv.update_vehicles_ground_truths-320"><span class="linenos">320</span></a>			<span class="n">vehicle</span><span class="o">.</span><span class="n">ground_truth</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ground_truth</span><span class="o">.</span><span class="n">ground_truth_field</span>
</span></pre></div>


            <div class="docstring"><p>Setter to update the ground truth of the vehicles.</p>
</div>


                            </div>
                            <div id="InformationGatheringEnv.action_dict_to_targets" class="classattr">
                                        <input id="InformationGatheringEnv.action_dict_to_targets-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">action_dict_to_targets</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">a_dict</span><span class="p">:</span> <span class="nb">dict</span></span><span class="return-annotation">) -> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span>:</span></span>

                <label class="view-source-button" for="InformationGatheringEnv.action_dict_to_targets-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#InformationGatheringEnv.action_dict_to_targets"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="InformationGatheringEnv.action_dict_to_targets-322"><a href="#InformationGatheringEnv.action_dict_to_targets-322"><span class="linenos">322</span></a>	<span class="k">def</span> <span class="nf">action_dict_to_targets</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">a_dict</span><span class="p">:</span> <span class="nb">dict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
</span><span id="InformationGatheringEnv.action_dict_to_targets-323"><a href="#InformationGatheringEnv.action_dict_to_targets-323"><span class="linenos">323</span></a>		<span class="sd">&quot;&quot;&quot; Transform the actions of the dictionary to a dictionary with the target goals.</span>
</span><span id="InformationGatheringEnv.action_dict_to_targets-324"><a href="#InformationGatheringEnv.action_dict_to_targets-324"><span class="linenos">324</span></a>
</span><span id="InformationGatheringEnv.action_dict_to_targets-325"><a href="#InformationGatheringEnv.action_dict_to_targets-325"><span class="linenos">325</span></a><span class="sd">		:param a_dict: The dictionary of actions. Every key is an agent_id, and the values corresponds to the action.</span>
</span><span id="InformationGatheringEnv.action_dict_to_targets-326"><a href="#InformationGatheringEnv.action_dict_to_targets-326"><span class="linenos">326</span></a>
</span><span id="InformationGatheringEnv.action_dict_to_targets-327"><a href="#InformationGatheringEnv.action_dict_to_targets-327"><span class="linenos">327</span></a><span class="sd">		:return:</span>
</span><span id="InformationGatheringEnv.action_dict_to_targets-328"><a href="#InformationGatheringEnv.action_dict_to_targets-328"><span class="linenos">328</span></a><span class="sd">			- targets: An array that contains the target positions for every vehicle.</span>
</span><span id="InformationGatheringEnv.action_dict_to_targets-329"><a href="#InformationGatheringEnv.action_dict_to_targets-329"><span class="linenos">329</span></a>
</span><span id="InformationGatheringEnv.action_dict_to_targets-330"><a href="#InformationGatheringEnv.action_dict_to_targets-330"><span class="linenos">330</span></a><span class="sd">		&quot;&quot;&quot;</span>
</span><span id="InformationGatheringEnv.action_dict_to_targets-331"><a href="#InformationGatheringEnv.action_dict_to_targets-331"><span class="linenos">331</span></a>
</span><span id="InformationGatheringEnv.action_dict_to_targets-332"><a href="#InformationGatheringEnv.action_dict_to_targets-332"><span class="linenos">332</span></a>		<span class="n">target_agents</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">a_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
</span><span id="InformationGatheringEnv.action_dict_to_targets-333"><a href="#InformationGatheringEnv.action_dict_to_targets-333"><span class="linenos">333</span></a>
</span><span id="InformationGatheringEnv.action_dict_to_targets-334"><a href="#InformationGatheringEnv.action_dict_to_targets-334"><span class="linenos">334</span></a>		<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;movement_type&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;DIRECTIONAL&#39;</span><span class="p">:</span>
</span><span id="InformationGatheringEnv.action_dict_to_targets-335"><a href="#InformationGatheringEnv.action_dict_to_targets-335"><span class="linenos">335</span></a>			<span class="c1"># Transform discrete actions to displacement</span>
</span><span id="InformationGatheringEnv.action_dict_to_targets-336"><a href="#InformationGatheringEnv.action_dict_to_targets-336"><span class="linenos">336</span></a>			<span class="n">angles</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">action</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;number_of_actions&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">action</span> <span class="ow">in</span> <span class="n">a_dict</span><span class="o">.</span><span class="n">values</span><span class="p">()])</span>
</span><span id="InformationGatheringEnv.action_dict_to_targets-337"><a href="#InformationGatheringEnv.action_dict_to_targets-337"><span class="linenos">337</span></a>			<span class="c1"># Transform the displacement to positions #</span>
</span><span id="InformationGatheringEnv.action_dict_to_targets-338"><a href="#InformationGatheringEnv.action_dict_to_targets-338"><span class="linenos">338</span></a>			<span class="n">target_positions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fleet</span><span class="o">.</span><span class="n">get_positions</span><span class="p">()[</span><span class="n">target_agents</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;measurement_distance&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">(</span>
</span><span id="InformationGatheringEnv.action_dict_to_targets-339"><a href="#InformationGatheringEnv.action_dict_to_targets-339"><span class="linenos">339</span></a>				<span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">angles</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">angles</span><span class="p">)))</span>
</span><span id="InformationGatheringEnv.action_dict_to_targets-340"><a href="#InformationGatheringEnv.action_dict_to_targets-340"><span class="linenos">340</span></a>
</span><span id="InformationGatheringEnv.action_dict_to_targets-341"><a href="#InformationGatheringEnv.action_dict_to_targets-341"><span class="linenos">341</span></a>		<span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;movement_type&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;DIRECTIONAL_DISTANCE&#39;</span><span class="p">:</span>
</span><span id="InformationGatheringEnv.action_dict_to_targets-342"><a href="#InformationGatheringEnv.action_dict_to_targets-342"><span class="linenos">342</span></a>			<span class="c1"># Transform the continuous actions into displacement #</span>
</span><span id="InformationGatheringEnv.action_dict_to_targets-343"><a href="#InformationGatheringEnv.action_dict_to_targets-343"><span class="linenos">343</span></a>			<span class="n">actions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">action</span> <span class="k">for</span> <span class="n">action</span> <span class="ow">in</span> <span class="n">a_dict</span><span class="o">.</span><span class="n">values</span><span class="p">()])</span>
</span><span id="InformationGatheringEnv.action_dict_to_targets-344"><a href="#InformationGatheringEnv.action_dict_to_targets-344"><span class="linenos">344</span></a>			<span class="n">angles</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">actions</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
</span><span id="InformationGatheringEnv.action_dict_to_targets-345"><a href="#InformationGatheringEnv.action_dict_to_targets-345"><span class="linenos">345</span></a>			<span class="n">distances</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear_min_max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;min_measurement_distance&#39;</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;max_measurement_distance&#39;</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span>
</span><span id="InformationGatheringEnv.action_dict_to_targets-346"><a href="#InformationGatheringEnv.action_dict_to_targets-346"><span class="linenos">346</span></a>			                                <span class="n">actions</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
</span><span id="InformationGatheringEnv.action_dict_to_targets-347"><a href="#InformationGatheringEnv.action_dict_to_targets-347"><span class="linenos">347</span></a>			<span class="n">target_positions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fleet</span><span class="o">.</span><span class="n">get_positions</span><span class="p">()[</span><span class="n">target_agents</span><span class="p">]</span> <span class="o">+</span> <span class="n">distances</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">angles</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">angles</span><span class="p">)))</span>
</span><span id="InformationGatheringEnv.action_dict_to_targets-348"><a href="#InformationGatheringEnv.action_dict_to_targets-348"><span class="linenos">348</span></a>		<span class="k">else</span><span class="p">:</span>
</span><span id="InformationGatheringEnv.action_dict_to_targets-349"><a href="#InformationGatheringEnv.action_dict_to_targets-349"><span class="linenos">349</span></a>			<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Invalid movement type&quot;</span><span class="p">)</span>
</span><span id="InformationGatheringEnv.action_dict_to_targets-350"><a href="#InformationGatheringEnv.action_dict_to_targets-350"><span class="linenos">350</span></a>
</span><span id="InformationGatheringEnv.action_dict_to_targets-351"><a href="#InformationGatheringEnv.action_dict_to_targets-351"><span class="linenos">351</span></a>		<span class="k">return</span> <span class="n">target_positions</span>
</span></pre></div>


            <div class="docstring"><p>Transform the actions of the dictionary to a dictionary with the target goals.</p>

<h6 id="parameters">Parameters</h6>

<ul>
<li><strong>a_dict</strong>:  The dictionary of actions. Every key is an agent_id, and the values corresponds to the action.</li>
</ul>

<h6 id="returns">Returns</h6>

<blockquote>
<pre><code>    - targets: An array that contains the target positions for every vehicle.
</code></pre>
</blockquote>
</div>


                            </div>
                            <div id="InformationGatheringEnv.linear_min_max" class="classattr">
                                        <input id="InformationGatheringEnv.linear_min_max-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
                    <div class="decorator">@staticmethod</div>

        <span class="def">def</span>
        <span class="name">linear_min_max</span><span class="signature pdoc-code condensed">(<span class="param"><span class="n">y_min</span>, </span><span class="param"><span class="n">y_max</span>, </span><span class="param"><span class="n">x_min</span>, </span><span class="param"><span class="n">x_max</span>, </span><span class="param"><span class="n">x</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="InformationGatheringEnv.linear_min_max-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#InformationGatheringEnv.linear_min_max"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="InformationGatheringEnv.linear_min_max-353"><a href="#InformationGatheringEnv.linear_min_max-353"><span class="linenos">353</span></a>	<span class="nd">@staticmethod</span>
</span><span id="InformationGatheringEnv.linear_min_max-354"><a href="#InformationGatheringEnv.linear_min_max-354"><span class="linenos">354</span></a>	<span class="k">def</span> <span class="nf">linear_min_max</span><span class="p">(</span><span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span><span class="p">,</span> <span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
</span><span id="InformationGatheringEnv.linear_min_max-355"><a href="#InformationGatheringEnv.linear_min_max-355"><span class="linenos">355</span></a>		<span class="sd">&quot;&quot;&quot; Transform the input x into a line &quot;&quot;&quot;</span>
</span><span id="InformationGatheringEnv.linear_min_max-356"><a href="#InformationGatheringEnv.linear_min_max-356"><span class="linenos">356</span></a>		<span class="k">return</span> <span class="p">(</span><span class="n">y_max</span> <span class="o">-</span> <span class="n">y_min</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">x_max</span> <span class="o">-</span> <span class="n">x_min</span><span class="p">)</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y_min</span>
</span></pre></div>


            <div class="docstring"><p>Transform the input x into a line</p>
</div>


                            </div>
                            <div id="InformationGatheringEnv.step" class="classattr">
                                        <input id="InformationGatheringEnv.step-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">step</span><span class="signature pdoc-code multiline">(<span class="param">	<span class="bp">self</span>,</span><span class="param">	<span class="n">action_dict</span><span class="p">:</span> <span class="nb">dict</span></span><span class="return-annotation">) -> (&lt;class &#x27;dict&#x27;&gt;, &lt;class &#x27;dict&#x27;&gt;, &lt;class &#x27;dict&#x27;&gt;, &lt;class &#x27;dict&#x27;&gt;):</span></span>

                <label class="view-source-button" for="InformationGatheringEnv.step-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#InformationGatheringEnv.step"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="InformationGatheringEnv.step-358"><a href="#InformationGatheringEnv.step-358"><span class="linenos">358</span></a>	<span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">action_dict</span><span class="p">:</span> <span class="nb">dict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="p">(</span><span class="nb">dict</span><span class="p">,</span> <span class="nb">dict</span><span class="p">,</span> <span class="nb">dict</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
</span><span id="InformationGatheringEnv.step-359"><a href="#InformationGatheringEnv.step-359"><span class="linenos">359</span></a>		<span class="sd">&quot;&quot;&quot; Process the actions. The action is processed for those waiting vehicles. The fleet is updated until one/all vehicles are ready.</span>
</span><span id="InformationGatheringEnv.step-360"><a href="#InformationGatheringEnv.step-360"><span class="linenos">360</span></a><span class="sd">		Every vehicle takes a measurement and the reward is processed</span>
</span><span id="InformationGatheringEnv.step-361"><a href="#InformationGatheringEnv.step-361"><span class="linenos">361</span></a>
</span><span id="InformationGatheringEnv.step-362"><a href="#InformationGatheringEnv.step-362"><span class="linenos">362</span></a><span class="sd">		:param action_dict: The dictionary of actions. Every key is an agent_id, and the values corresponds to the action.</span>
</span><span id="InformationGatheringEnv.step-363"><a href="#InformationGatheringEnv.step-363"><span class="linenos">363</span></a>
</span><span id="InformationGatheringEnv.step-364"><a href="#InformationGatheringEnv.step-364"><span class="linenos">364</span></a><span class="sd">		:return:</span>
</span><span id="InformationGatheringEnv.step-365"><a href="#InformationGatheringEnv.step-365"><span class="linenos">365</span></a><span class="sd">			- reward: The reward for each agent.</span>
</span><span id="InformationGatheringEnv.step-366"><a href="#InformationGatheringEnv.step-366"><span class="linenos">366</span></a><span class="sd">			- observation: The observation for each agent.</span>
</span><span id="InformationGatheringEnv.step-367"><a href="#InformationGatheringEnv.step-367"><span class="linenos">367</span></a><span class="sd">			- done: A boolean that indicates if the episode is finished.</span>
</span><span id="InformationGatheringEnv.step-368"><a href="#InformationGatheringEnv.step-368"><span class="linenos">368</span></a><span class="sd">			- info: A dictionary that contains additional information.</span>
</span><span id="InformationGatheringEnv.step-369"><a href="#InformationGatheringEnv.step-369"><span class="linenos">369</span></a>
</span><span id="InformationGatheringEnv.step-370"><a href="#InformationGatheringEnv.step-370"><span class="linenos">370</span></a><span class="sd">		&quot;&quot;&quot;</span>
</span><span id="InformationGatheringEnv.step-371"><a href="#InformationGatheringEnv.step-371"><span class="linenos">371</span></a>
</span><span id="InformationGatheringEnv.step-372"><a href="#InformationGatheringEnv.step-372"><span class="linenos">372</span></a>		<span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">resetted</span><span class="p">,</span> <span class="s2">&quot;You need to reset the environment first with env.reset()&quot;</span>
</span><span id="InformationGatheringEnv.step-373"><a href="#InformationGatheringEnv.step-373"><span class="linenos">373</span></a>
</span><span id="InformationGatheringEnv.step-374"><a href="#InformationGatheringEnv.step-374"><span class="linenos">374</span></a>		<span class="c1"># Compute the new target with the given actions #</span>
</span><span id="InformationGatheringEnv.step-375"><a href="#InformationGatheringEnv.step-375"><span class="linenos">375</span></a>		<span class="n">new_targets</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_dict_to_targets</span><span class="p">(</span><span class="n">action_dict</span><span class="p">)</span>
</span><span id="InformationGatheringEnv.step-376"><a href="#InformationGatheringEnv.step-376"><span class="linenos">376</span></a>
</span><span id="InformationGatheringEnv.step-377"><a href="#InformationGatheringEnv.step-377"><span class="linenos">377</span></a>		<span class="c1"># Apply the new target to the vehicles #</span>
</span><span id="InformationGatheringEnv.step-378"><a href="#InformationGatheringEnv.step-378"><span class="linenos">378</span></a>		<span class="k">for</span> <span class="n">vehicle_id</span><span class="p">,</span> <span class="n">target</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">action_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">(),</span> <span class="n">new_targets</span><span class="p">):</span>
</span><span id="InformationGatheringEnv.step-379"><a href="#InformationGatheringEnv.step-379"><span class="linenos">379</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">fleet</span><span class="o">.</span><span class="n">set_target_position</span><span class="p">(</span><span class="n">vehicle_id</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
</span><span id="InformationGatheringEnv.step-380"><a href="#InformationGatheringEnv.step-380"><span class="linenos">380</span></a>
</span><span id="InformationGatheringEnv.step-381"><a href="#InformationGatheringEnv.step-381"><span class="linenos">381</span></a>		<span class="c1"># Step until any vehicle has completed (or failed its goal) #</span>
</span><span id="InformationGatheringEnv.step-382"><a href="#InformationGatheringEnv.step-382"><span class="linenos">382</span></a>		<span class="n">new_measurements</span> <span class="o">=</span> <span class="kc">None</span>
</span><span id="InformationGatheringEnv.step-383"><a href="#InformationGatheringEnv.step-383"><span class="linenos">383</span></a>
</span><span id="InformationGatheringEnv.step-384"><a href="#InformationGatheringEnv.step-384"><span class="linenos">384</span></a>		<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;movement_type&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;DIRECTIONAL&#39;</span><span class="p">:</span>
</span><span id="InformationGatheringEnv.step-385"><a href="#InformationGatheringEnv.step-385"><span class="linenos">385</span></a>			<span class="c1"># Update until ALL vehicles have arrived to their goals #</span>
</span><span id="InformationGatheringEnv.step-386"><a href="#InformationGatheringEnv.step-386"><span class="linenos">386</span></a>			<span class="n">_</span><span class="p">,</span> <span class="n">new_measurements</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fleet</span><span class="o">.</span><span class="n">update_syncronously</span><span class="p">()</span>
</span><span id="InformationGatheringEnv.step-387"><a href="#InformationGatheringEnv.step-387"><span class="linenos">387</span></a>		<span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;movement_type&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;DIRECTIONAL_DISTANCE&#39;</span><span class="p">:</span>
</span><span id="InformationGatheringEnv.step-388"><a href="#InformationGatheringEnv.step-388"><span class="linenos">388</span></a>			<span class="c1"># Update until AT LEAST ONE vehicle has arrived to their goals#</span>
</span><span id="InformationGatheringEnv.step-389"><a href="#InformationGatheringEnv.step-389"><span class="linenos">389</span></a>			<span class="n">_</span><span class="p">,</span> <span class="n">new_measurements</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fleet</span><span class="o">.</span><span class="n">update_asyncronously</span><span class="p">()</span>
</span><span id="InformationGatheringEnv.step-390"><a href="#InformationGatheringEnv.step-390"><span class="linenos">390</span></a>
</span><span id="InformationGatheringEnv.step-391"><a href="#InformationGatheringEnv.step-391"><span class="linenos">391</span></a>		<span class="c1"># Retrieve the ids of the agents that must return a state and a reward #</span>
</span><span id="InformationGatheringEnv.step-392"><a href="#InformationGatheringEnv.step-392"><span class="linenos">392</span></a>		<span class="n">ready_agents_ids</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">veh_state</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fleet</span><span class="o">.</span><span class="n">fleet_state</span><span class="p">)</span> <span class="k">if</span> <span class="n">veh_state</span> <span class="ow">in</span> <span class="p">[</span><span class="n">FleetState</span><span class="o">.</span><span class="n">WAITING_FOR_ACTION</span><span class="p">,</span> <span class="n">FleetState</span><span class="o">.</span><span class="n">COLLIDED</span><span class="p">,</span> <span class="n">FleetState</span><span class="o">.</span><span class="n">LAST_ACTION</span><span class="p">]]</span>
</span><span id="InformationGatheringEnv.step-393"><a href="#InformationGatheringEnv.step-393"><span class="linenos">393</span></a>
</span><span id="InformationGatheringEnv.step-394"><a href="#InformationGatheringEnv.step-394"><span class="linenos">394</span></a>		<span class="c1"># Compute those agents that collided and add 1 collision to their counter #</span>
</span><span id="InformationGatheringEnv.step-395"><a href="#InformationGatheringEnv.step-395"><span class="linenos">395</span></a>		<span class="n">collision_array</span> <span class="o">=</span> <span class="p">[</span><span class="n">s</span> <span class="o">==</span> <span class="n">FleetState</span><span class="o">.</span><span class="n">COLLIDED</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">fleet</span><span class="o">.</span><span class="n">fleet_state</span><span class="p">]</span>
</span><span id="InformationGatheringEnv.step-396"><a href="#InformationGatheringEnv.step-396"><span class="linenos">396</span></a>		<span class="c1"># Accumulate every agent collision #</span>
</span><span id="InformationGatheringEnv.step-397"><a href="#InformationGatheringEnv.step-397"><span class="linenos">397</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">number_of_collisions</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">collision_array</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
</span><span id="InformationGatheringEnv.step-398"><a href="#InformationGatheringEnv.step-398"><span class="linenos">398</span></a>		<span class="c1"># For every agent, change its state to final if its number of collisions is equal to the maximum number of collisions #</span>
</span><span id="InformationGatheringEnv.step-399"><a href="#InformationGatheringEnv.step-399"><span class="linenos">399</span></a>		<span class="k">for</span> <span class="n">agent_id</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">agents_ids</span><span class="p">:</span>
</span><span id="InformationGatheringEnv.step-400"><a href="#InformationGatheringEnv.step-400"><span class="linenos">400</span></a>			<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">number_of_collisions</span><span class="p">[</span><span class="n">agent_id</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_collisions</span><span class="p">:</span>
</span><span id="InformationGatheringEnv.step-401"><a href="#InformationGatheringEnv.step-401"><span class="linenos">401</span></a>				<span class="bp">self</span><span class="o">.</span><span class="n">fleet</span><span class="o">.</span><span class="n">set_state</span><span class="p">(</span><span class="n">agent_id</span><span class="p">,</span> <span class="n">FleetState</span><span class="o">.</span><span class="n">LAST_ACTION</span><span class="p">)</span>
</span><span id="InformationGatheringEnv.step-402"><a href="#InformationGatheringEnv.step-402"><span class="linenos">402</span></a>
</span><span id="InformationGatheringEnv.step-403"><a href="#InformationGatheringEnv.step-403"><span class="linenos">403</span></a>		<span class="n">done_agents_vals</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">fleet</span><span class="o">.</span><span class="n">fleet_state</span><span class="p">[</span><span class="n">agents_id</span><span class="p">]</span> <span class="o">==</span> <span class="n">FleetState</span><span class="o">.</span><span class="n">LAST_ACTION</span> <span class="k">for</span> <span class="n">agents_id</span> <span class="ow">in</span> <span class="n">ready_agents_ids</span><span class="p">]</span>
</span><span id="InformationGatheringEnv.step-404"><a href="#InformationGatheringEnv.step-404"><span class="linenos">404</span></a>
</span><span id="InformationGatheringEnv.step-405"><a href="#InformationGatheringEnv.step-405"><span class="linenos">405</span></a>		<span class="c1"># Update the model</span>
</span><span id="InformationGatheringEnv.step-406"><a href="#InformationGatheringEnv.step-406"><span class="linenos">406</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">uncertainty</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">update_model</span><span class="p">(</span><span class="n">new_measurements</span><span class="o">=</span><span class="n">new_measurements</span><span class="p">,</span> <span class="n">agents_ids</span><span class="o">=</span><span class="n">ready_agents_ids</span><span class="p">)</span>
</span><span id="InformationGatheringEnv.step-407"><a href="#InformationGatheringEnv.step-407"><span class="linenos">407</span></a>
</span><span id="InformationGatheringEnv.step-408"><a href="#InformationGatheringEnv.step-408"><span class="linenos">408</span></a>		<span class="c1"># Compute the rewards for those finished agents #</span>
</span><span id="InformationGatheringEnv.step-409"><a href="#InformationGatheringEnv.step-409"><span class="linenos">409</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">rewards</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reward_function</span><span class="p">(</span><span class="n">collision_array</span><span class="o">=</span><span class="n">collision_array</span><span class="p">,</span> <span class="n">agents_ids</span><span class="o">=</span><span class="n">ready_agents_ids</span><span class="p">)</span>
</span><span id="InformationGatheringEnv.step-410"><a href="#InformationGatheringEnv.step-410"><span class="linenos">410</span></a>
</span><span id="InformationGatheringEnv.step-411"><a href="#InformationGatheringEnv.step-411"><span class="linenos">411</span></a>		<span class="c1"># Compute the states for those same agents #</span>
</span><span id="InformationGatheringEnv.step-412"><a href="#InformationGatheringEnv.step-412"><span class="linenos">412</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">states</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">process_states</span><span class="p">(</span><span class="n">agent_ids</span><span class="o">=</span><span class="n">ready_agents_ids</span><span class="p">)</span>
</span><span id="InformationGatheringEnv.step-413"><a href="#InformationGatheringEnv.step-413"><span class="linenos">413</span></a>
</span><span id="InformationGatheringEnv.step-414"><a href="#InformationGatheringEnv.step-414"><span class="linenos">414</span></a>		<span class="c1"># Info is useless by the moment</span>
</span><span id="InformationGatheringEnv.step-415"><a href="#InformationGatheringEnv.step-415"><span class="linenos">415</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">infos</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;Collisions&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">number_of_collisions</span><span class="p">[</span><span class="n">i</span><span class="p">]}</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">ready_agents_ids</span><span class="p">}</span>
</span><span id="InformationGatheringEnv.step-416"><a href="#InformationGatheringEnv.step-416"><span class="linenos">416</span></a>
</span><span id="InformationGatheringEnv.step-417"><a href="#InformationGatheringEnv.step-417"><span class="linenos">417</span></a>		<span class="c1"># Update the ground truth state and pass the field to agents #</span>
</span><span id="InformationGatheringEnv.step-418"><a href="#InformationGatheringEnv.step-418"><span class="linenos">418</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">ground_truth</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</span><span id="InformationGatheringEnv.step-419"><a href="#InformationGatheringEnv.step-419"><span class="linenos">419</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">update_vehicles_ground_truths</span><span class="p">()</span>
</span><span id="InformationGatheringEnv.step-420"><a href="#InformationGatheringEnv.step-420"><span class="linenos">420</span></a>
</span><span id="InformationGatheringEnv.step-421"><a href="#InformationGatheringEnv.step-421"><span class="linenos">421</span></a>		<span class="c1"># Compute if the agents have finished #</span>
</span><span id="InformationGatheringEnv.step-422"><a href="#InformationGatheringEnv.step-422"><span class="linenos">422</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">dones</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span> <span class="n">val</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">ready_agents_ids</span><span class="p">,</span> <span class="n">done_agents_vals</span><span class="p">)}</span>
</span><span id="InformationGatheringEnv.step-423"><a href="#InformationGatheringEnv.step-423"><span class="linenos">423</span></a>		<span class="bp">self</span><span class="o">.</span><span class="n">dones</span><span class="p">[</span><span class="s1">&#39;__all__&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">all</span><span class="p">([</span><span class="n">veh_state</span> <span class="ow">in</span> <span class="p">[</span><span class="n">FleetState</span><span class="o">.</span><span class="n">LAST_ACTION</span><span class="p">,</span> <span class="n">FleetState</span><span class="o">.</span><span class="n">FINISHED</span><span class="p">]</span> <span class="k">for</span> <span class="n">veh_state</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">fleet</span><span class="o">.</span><span class="n">fleet_state</span><span class="p">])</span>
</span><span id="InformationGatheringEnv.step-424"><a href="#InformationGatheringEnv.step-424"><span class="linenos">424</span></a>
</span><span id="InformationGatheringEnv.step-425"><a href="#InformationGatheringEnv.step-425"><span class="linenos">425</span></a>
</span><span id="InformationGatheringEnv.step-426"><a href="#InformationGatheringEnv.step-426"><span class="linenos">426</span></a>		<span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">states</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">rewards</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dones</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">infos</span>
</span></pre></div>


            <div class="docstring"><p>Process the actions. The action is processed for those waiting vehicles. The fleet is updated until one/all vehicles are ready.
Every vehicle takes a measurement and the reward is processed</p>

<h6 id="parameters">Parameters</h6>

<ul>
<li><strong>action_dict</strong>:  The dictionary of actions. Every key is an agent_id, and the values corresponds to the action.</li>
</ul>

<h6 id="returns">Returns</h6>

<blockquote>
<pre><code>    - reward: The reward for each agent.
    - observation: The observation for each agent.
    - done: A boolean that indicates if the episode is finished.
    - info: A dictionary that contains additional information.
</code></pre>
</blockquote>
</div>


                            </div>
                            <div id="InformationGatheringEnv.render" class="classattr">
                                        <input id="InformationGatheringEnv.render-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">render</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">mode</span><span class="o">=</span><span class="s1">&#39;human&#39;</span></span><span class="return-annotation">):</span></span>

                <label class="view-source-button" for="InformationGatheringEnv.render-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#InformationGatheringEnv.render"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="InformationGatheringEnv.render-428"><a href="#InformationGatheringEnv.render-428"><span class="linenos">428</span></a>	<span class="k">def</span> <span class="nf">render</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;human&#39;</span><span class="p">):</span>
</span><span id="InformationGatheringEnv.render-429"><a href="#InformationGatheringEnv.render-429"><span class="linenos">429</span></a>		<span class="sd">&quot;&quot;&quot; Render the environment. &quot;&quot;&quot;</span>
</span><span id="InformationGatheringEnv.render-430"><a href="#InformationGatheringEnv.render-430"><span class="linenos">430</span></a>
</span><span id="InformationGatheringEnv.render-431"><a href="#InformationGatheringEnv.render-431"><span class="linenos">431</span></a>		<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">fig</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="InformationGatheringEnv.render-432"><a href="#InformationGatheringEnv.render-432"><span class="linenos">432</span></a>
</span><span id="InformationGatheringEnv.render-433"><a href="#InformationGatheringEnv.render-433"><span class="linenos">433</span></a>			<span class="n">plt</span><span class="o">.</span><span class="n">ion</span><span class="p">()</span>
</span><span id="InformationGatheringEnv.render-434"><a href="#InformationGatheringEnv.render-434"><span class="linenos">434</span></a>
</span><span id="InformationGatheringEnv.render-435"><a href="#InformationGatheringEnv.render-435"><span class="linenos">435</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">fig</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
</span><span id="InformationGatheringEnv.render-436"><a href="#InformationGatheringEnv.render-436"><span class="linenos">436</span></a>
</span><span id="InformationGatheringEnv.render-437"><a href="#InformationGatheringEnv.render-437"><span class="linenos">437</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Navigation map&#39;</span><span class="p">)</span>
</span><span id="InformationGatheringEnv.render-438"><a href="#InformationGatheringEnv.render-438"><span class="linenos">438</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">s0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">axs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;navigation_map&#39;</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
</span><span id="InformationGatheringEnv.render-439"><a href="#InformationGatheringEnv.render-439"><span class="linenos">439</span></a>
</span><span id="InformationGatheringEnv.render-440"><a href="#InformationGatheringEnv.render-440"><span class="linenos">440</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Fleet positions&#39;</span><span class="p">)</span>
</span><span id="InformationGatheringEnv.render-441"><a href="#InformationGatheringEnv.render-441"><span class="linenos">441</span></a>			<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">observation_type</span> <span class="o">==</span> <span class="s1">&#39;visual&#39;</span><span class="p">:</span>
</span><span id="InformationGatheringEnv.render-442"><a href="#InformationGatheringEnv.render-442"><span class="linenos">442</span></a>				<span class="bp">self</span><span class="o">.</span><span class="n">s1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">individual_state</span><span class="p">(</span><span class="n">i</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">number_of_agents</span><span class="p">)],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
</span><span id="InformationGatheringEnv.render-443"><a href="#InformationGatheringEnv.render-443"><span class="linenos">443</span></a>			<span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">observation_type</span> <span class="o">==</span> <span class="s1">&#39;hybrid&#39;</span><span class="p">:</span>
</span><span id="InformationGatheringEnv.render-444"><a href="#InformationGatheringEnv.render-444"><span class="linenos">444</span></a>				<span class="bp">self</span><span class="o">.</span><span class="n">s1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">axs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">individual_state</span><span class="p">(</span><span class="n">i</span><span class="p">)[</span><span class="s1">&#39;visual_state&#39;</span><span class="p">][</span><span class="mi">2</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">number_of_agents</span><span class="p">)],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
</span><span id="InformationGatheringEnv.render-445"><a href="#InformationGatheringEnv.render-445"><span class="linenos">445</span></a>			<span class="k">else</span><span class="p">:</span>
</span><span id="InformationGatheringEnv.render-446"><a href="#InformationGatheringEnv.render-446"><span class="linenos">446</span></a>				<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s1">&#39;Cannot render with an invalid observation type.&#39;</span><span class="p">)</span>
</span><span id="InformationGatheringEnv.render-447"><a href="#InformationGatheringEnv.render-447"><span class="linenos">447</span></a>
</span><span id="InformationGatheringEnv.render-448"><a href="#InformationGatheringEnv.render-448"><span class="linenos">448</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Estimated model&#39;</span><span class="p">)</span>
</span><span id="InformationGatheringEnv.render-449"><a href="#InformationGatheringEnv.render-449"><span class="linenos">449</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">s2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">axs</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;jet&#39;</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
</span><span id="InformationGatheringEnv.render-450"><a href="#InformationGatheringEnv.render-450"><span class="linenos">450</span></a>
</span><span id="InformationGatheringEnv.render-451"><a href="#InformationGatheringEnv.render-451"><span class="linenos">451</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">axs</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Uncertainty&#39;</span><span class="p">)</span>
</span><span id="InformationGatheringEnv.render-452"><a href="#InformationGatheringEnv.render-452"><span class="linenos">452</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">s3</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">axs</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">uncertainty</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
</span><span id="InformationGatheringEnv.render-453"><a href="#InformationGatheringEnv.render-453"><span class="linenos">453</span></a>
</span><span id="InformationGatheringEnv.render-454"><a href="#InformationGatheringEnv.render-454"><span class="linenos">454</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">axs</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Ground truth&#39;</span><span class="p">)</span>
</span><span id="InformationGatheringEnv.render-455"><a href="#InformationGatheringEnv.render-455"><span class="linenos">455</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">s4</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">axs</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ground_truth</span><span class="o">.</span><span class="n">ground_truth_field</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;jet&#39;</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
</span><span id="InformationGatheringEnv.render-456"><a href="#InformationGatheringEnv.render-456"><span class="linenos">456</span></a>
</span><span id="InformationGatheringEnv.render-457"><a href="#InformationGatheringEnv.render-457"><span class="linenos">457</span></a>		<span class="k">else</span><span class="p">:</span>
</span><span id="InformationGatheringEnv.render-458"><a href="#InformationGatheringEnv.render-458"><span class="linenos">458</span></a>
</span><span id="InformationGatheringEnv.render-459"><a href="#InformationGatheringEnv.render-459"><span class="linenos">459</span></a>			<span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">observation_type</span> <span class="o">==</span> <span class="s1">&#39;visual&#39;</span><span class="p">:</span>
</span><span id="InformationGatheringEnv.render-460"><a href="#InformationGatheringEnv.render-460"><span class="linenos">460</span></a>				<span class="bp">self</span><span class="o">.</span><span class="n">s1</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">individual_state</span><span class="p">(</span><span class="n">i</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">number_of_agents</span><span class="p">)],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
</span><span id="InformationGatheringEnv.render-461"><a href="#InformationGatheringEnv.render-461"><span class="linenos">461</span></a>			<span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">observation_type</span> <span class="o">==</span> <span class="s1">&#39;hybrid&#39;</span><span class="p">:</span>
</span><span id="InformationGatheringEnv.render-462"><a href="#InformationGatheringEnv.render-462"><span class="linenos">462</span></a>				<span class="bp">self</span><span class="o">.</span><span class="n">s1</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">individual_state</span><span class="p">(</span><span class="n">i</span><span class="p">)[</span><span class="s1">&#39;visual_state&#39;</span><span class="p">][</span><span class="mi">2</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">number_of_agents</span><span class="p">)],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
</span><span id="InformationGatheringEnv.render-463"><a href="#InformationGatheringEnv.render-463"><span class="linenos">463</span></a>
</span><span id="InformationGatheringEnv.render-464"><a href="#InformationGatheringEnv.render-464"><span class="linenos">464</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">s2</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="p">)</span>
</span><span id="InformationGatheringEnv.render-465"><a href="#InformationGatheringEnv.render-465"><span class="linenos">465</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">s3</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">uncertainty</span><span class="p">)</span>
</span><span id="InformationGatheringEnv.render-466"><a href="#InformationGatheringEnv.render-466"><span class="linenos">466</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">s4</span><span class="o">.</span><span class="n">set_data</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ground_truth</span><span class="o">.</span><span class="n">ground_truth_field</span><span class="p">)</span>
</span><span id="InformationGatheringEnv.render-467"><a href="#InformationGatheringEnv.render-467"><span class="linenos">467</span></a>
</span><span id="InformationGatheringEnv.render-468"><a href="#InformationGatheringEnv.render-468"><span class="linenos">468</span></a>			<span class="bp">self</span><span class="o">.</span><span class="n">fig</span><span class="o">.</span><span class="n">canvas</span><span class="o">.</span><span class="n">draw</span><span class="p">()</span>
</span><span id="InformationGatheringEnv.render-469"><a href="#InformationGatheringEnv.render-469"><span class="linenos">469</span></a>
</span><span id="InformationGatheringEnv.render-470"><a href="#InformationGatheringEnv.render-470"><span class="linenos">470</span></a>		<span class="n">plt</span><span class="o">.</span><span class="n">pause</span><span class="p">(</span><span class="mf">0.01</span><span class="p">)</span>
</span><span id="InformationGatheringEnv.render-471"><a href="#InformationGatheringEnv.render-471"><span class="linenos">471</span></a>		<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">(</span><span class="n">pad</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
</span><span id="InformationGatheringEnv.render-472"><a href="#InformationGatheringEnv.render-472"><span class="linenos">472</span></a>		<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></pre></div>


            <div class="docstring"><p>Render the environment.</p>
</div>


                            </div>
                            <div id="InformationGatheringEnv.get_action_mask" class="classattr">
                                        <input id="InformationGatheringEnv.get_action_mask-view-source" class="view-source-toggle-state" type="checkbox" aria-hidden="true" tabindex="-1">
<div class="attr function">
            
        <span class="def">def</span>
        <span class="name">get_action_mask</span><span class="signature pdoc-code condensed">(<span class="param"><span class="bp">self</span>, </span><span class="param"><span class="n">ind</span><span class="p">:</span> <span class="nb">int</span></span><span class="return-annotation">) -> <span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span>:</span></span>

                <label class="view-source-button" for="InformationGatheringEnv.get_action_mask-view-source"><span>View Source</span></label>

    </div>
    <a class="headerlink" href="#InformationGatheringEnv.get_action_mask"></a>
            <div class="pdoc-code codehilite"><pre><span></span><span id="InformationGatheringEnv.get_action_mask-474"><a href="#InformationGatheringEnv.get_action_mask-474"><span class="linenos">474</span></a>	<span class="k">def</span> <span class="nf">get_action_mask</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ind</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
</span><span id="InformationGatheringEnv.get_action_mask-475"><a href="#InformationGatheringEnv.get_action_mask-475"><span class="linenos">475</span></a>		<span class="sd">&quot;&quot;&quot; Get the invalid action mask for a certain vehicle (*ind*)</span>
</span><span id="InformationGatheringEnv.get_action_mask-476"><a href="#InformationGatheringEnv.get_action_mask-476"><span class="linenos">476</span></a>
</span><span id="InformationGatheringEnv.get_action_mask-477"><a href="#InformationGatheringEnv.get_action_mask-477"><span class="linenos">477</span></a><span class="sd">		:param ind: The index of the vehicle</span>
</span><span id="InformationGatheringEnv.get_action_mask-478"><a href="#InformationGatheringEnv.get_action_mask-478"><span class="linenos">478</span></a>
</span><span id="InformationGatheringEnv.get_action_mask-479"><a href="#InformationGatheringEnv.get_action_mask-479"><span class="linenos">479</span></a><span class="sd">		:return:</span>
</span><span id="InformationGatheringEnv.get_action_mask-480"><a href="#InformationGatheringEnv.get_action_mask-480"><span class="linenos">480</span></a><span class="sd">			- mask: The invalid action mask for the vehicle, where true means that the action is valid.</span>
</span><span id="InformationGatheringEnv.get_action_mask-481"><a href="#InformationGatheringEnv.get_action_mask-481"><span class="linenos">481</span></a>
</span><span id="InformationGatheringEnv.get_action_mask-482"><a href="#InformationGatheringEnv.get_action_mask-482"><span class="linenos">482</span></a><span class="sd">		&quot;&quot;&quot;</span>
</span><span id="InformationGatheringEnv.get_action_mask-483"><a href="#InformationGatheringEnv.get_action_mask-483"><span class="linenos">483</span></a>
</span><span id="InformationGatheringEnv.get_action_mask-484"><a href="#InformationGatheringEnv.get_action_mask-484"><span class="linenos">484</span></a>		<span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;movement_type&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;DIRECTIONAL&#39;</span><span class="p">,</span> <span class="s1">&#39;This function is only valid for DIRECTIONAL movement.&#39;</span>
</span><span id="InformationGatheringEnv.get_action_mask-485"><a href="#InformationGatheringEnv.get_action_mask-485"><span class="linenos">485</span></a>
</span><span id="InformationGatheringEnv.get_action_mask-486"><a href="#InformationGatheringEnv.get_action_mask-486"><span class="linenos">486</span></a>		<span class="n">angles</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;number_of_actions&#39;</span><span class="p">])</span><span class="o">/</span><span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;number_of_actions&#39;</span><span class="p">]</span>
</span><span id="InformationGatheringEnv.get_action_mask-487"><a href="#InformationGatheringEnv.get_action_mask-487"><span class="linenos">487</span></a>		<span class="n">possible_points</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fleet</span><span class="o">.</span><span class="n">vehicles</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span><span class="o">.</span><span class="n">position</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">env_config</span><span class="p">[</span><span class="s1">&#39;measurement_distance&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">angles</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">angles</span><span class="p">)))</span>
</span><span id="InformationGatheringEnv.get_action_mask-488"><a href="#InformationGatheringEnv.get_action_mask-488"><span class="linenos">488</span></a>
</span><span id="InformationGatheringEnv.get_action_mask-489"><a href="#InformationGatheringEnv.get_action_mask-489"><span class="linenos">489</span></a>		<span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fleet</span><span class="o">.</span><span class="n">vehicles</span><span class="p">[</span><span class="n">ind</span><span class="p">]</span><span class="o">.</span><span class="n">is_the_position_valid</span><span class="p">,</span> <span class="n">possible_points</span><span class="p">)))</span>
</span></pre></div>


            <div class="docstring"><p>Get the invalid action mask for a certain vehicle (<em>ind</em>)</p>

<h6 id="parameters">Parameters</h6>

<ul>
<li><strong>ind</strong>:  The index of the vehicle</li>
</ul>

<h6 id="returns">Returns</h6>

<blockquote>
<pre><code>    - mask: The invalid action mask for the vehicle, where true means that the action is valid.
</code></pre>
</blockquote>
</div>


                            </div>
                            <div class="inherited">
                                <h5>Inherited Members</h5>
                                <dl>
                                    <div><dt>ray.rllib.env.multi_agent_env.MultiAgentEnv</dt>
                                <dd id="InformationGatheringEnv.observation_space_contains" class="function">observation_space_contains</dd>
                <dd id="InformationGatheringEnv.action_space_contains" class="function">action_space_contains</dd>
                <dd id="InformationGatheringEnv.action_space_sample" class="function">action_space_sample</dd>
                <dd id="InformationGatheringEnv.observation_space_sample" class="function">observation_space_sample</dd>
                <dd id="InformationGatheringEnv.get_agent_ids" class="function">get_agent_ids</dd>
                <dd id="InformationGatheringEnv.with_agent_groups" class="function">with_agent_groups</dd>
                <dd id="InformationGatheringEnv.to_base_env" class="function">to_base_env</dd>

            </div>
            <div><dt>gym.core.Env</dt>
                                <dd id="InformationGatheringEnv.metadata" class="variable">metadata</dd>
                <dd id="InformationGatheringEnv.reward_range" class="variable">reward_range</dd>
                <dd id="InformationGatheringEnv.spec" class="variable">spec</dd>
                <dd id="InformationGatheringEnv.action_space" class="variable">action_space</dd>
                <dd id="InformationGatheringEnv.observation_space" class="variable">observation_space</dd>
                <dd id="InformationGatheringEnv.close" class="function">close</dd>
                <dd id="InformationGatheringEnv.seed" class="function">seed</dd>
                <dd id="InformationGatheringEnv.unwrapped" class="variable">unwrapped</dd>

            </div>
                                </dl>
                            </div>
                </section>
    </main>
<script>
    function escapeHTML(html) {
        return document.createElement('div').appendChild(document.createTextNode(html)).parentNode.innerHTML;
    }

    const originalContent = document.querySelector("main.pdoc");
    let currentContent = originalContent;

    function setContent(innerHTML) {
        let elem;
        if (innerHTML) {
            elem = document.createElement("main");
            elem.classList.add("pdoc");
            elem.innerHTML = innerHTML;
        } else {
            elem = originalContent;
        }
        if (currentContent !== elem) {
            currentContent.replaceWith(elem);
            currentContent = elem;
        }
    }

    function getSearchTerm() {
        return (new URL(window.location)).searchParams.get("search");
    }

    const searchBox = document.querySelector(".pdoc input[type=search]");
    searchBox.addEventListener("input", function () {
        let url = new URL(window.location);
        if (searchBox.value.trim()) {
            url.hash = "";
            url.searchParams.set("search", searchBox.value);
        } else {
            url.searchParams.delete("search");
        }
        history.replaceState("", "", url.toString());
        onInput();
    });
    window.addEventListener("popstate", onInput);


    let search, searchErr;

    async function initialize() {
        try {
            search = await new Promise((resolve, reject) => {
                const script = document.createElement("script");
                script.type = "text/javascript";
                script.async = true;
                script.onload = () => resolve(window.pdocSearch);
                script.onerror = (e) => reject(e);
                script.src = "search.js";
                document.getElementsByTagName("head")[0].appendChild(script);
            });
        } catch (e) {
            console.error("Cannot fetch pdoc search index");
            searchErr = "Cannot fetch search index.";
        }
        onInput();

        document.querySelector("nav.pdoc").addEventListener("click", e => {
            if (e.target.hash) {
                searchBox.value = "";
                searchBox.dispatchEvent(new Event("input"));
            }
        });
    }

    function onInput() {
        setContent((() => {
            const term = getSearchTerm();
            if (!term) {
                return null
            }
            if (searchErr) {
                return `<h3>Error: ${searchErr}</h3>`
            }
            if (!search) {
                return "<h3>Searching...</h3>"
            }

            window.scrollTo({top: 0, left: 0, behavior: 'auto'});

            const results = search(term);

            let html;
            if (results.length === 0) {
                html = `No search results for '${escapeHTML(term)}'.`
            } else {
                html = `<h4>${results.length} search result${results.length > 1 ? "s" : ""} for '${escapeHTML(term)}'.</h4>`;
            }
            for (let result of results.slice(0, 10)) {
                let doc = result.doc;
                let url = `${doc.modulename.replaceAll(".", "/")}.html`;
                if (doc.qualname) {
                    url += `#${doc.qualname}`;
                }

                let heading;
                switch (result.doc.type) {
                    case "function":
                        if (doc.fullname.endsWith(".__init__")) {
                            heading = `<span class="name">${doc.fullname.replace(/\.__init__$/, "")}</span>${doc.signature}`;
                        } else {
                            heading = `<span class="def">${doc.funcdef}</span> <span class="name">${doc.fullname}</span>${doc.signature}`;
                        }
                        break;
                    case "class":
                        heading = `<span class="def">class</span> <span class="name">${doc.fullname}</span>`;
                        if (doc.bases)
                            heading += `<wbr>(<span class="base">${doc.bases}</span>)`;
                        heading += `:`;
                        break;
                    case "variable":
                        heading = `<span class="name">${doc.fullname}</span>`;
                        if (doc.annotation)
                            heading += `<span class="annotation">${doc.annotation}</span>`;
                        if (doc.default_value)
                            heading += `<span class="default_value">${doc.default_value}</span>`;
                        break;
                    default:
                        heading = `<span class="name">${doc.fullname}</span>`;
                        break;
                }
                html += `
                        <section class="search-result">
                        <a href="${url}" class="attr ${doc.type}">${heading}</a>
                        <div class="docstring">${doc.doc}</div>
                        </section>
                    `;

            }
            return html;
        })());
    }

    if (getSearchTerm()) {
        initialize();
        searchBox.value = getSearchTerm();
        onInput();
    } else {
        searchBox.addEventListener("focus", initialize, {once: true});
    }

    searchBox.addEventListener("keydown", e => {
        if (["ArrowDown", "ArrowUp", "Enter"].includes(e.key)) {
            let focused = currentContent.querySelector(".search-result.focused");
            if (!focused) {
                currentContent.querySelector(".search-result").classList.add("focused");
            } else if (
                e.key === "ArrowDown"
                && focused.nextElementSibling
                && focused.nextElementSibling.classList.contains("search-result")
            ) {
                focused.classList.remove("focused");
                focused.nextElementSibling.classList.add("focused");
                focused.nextElementSibling.scrollIntoView({
                    behavior: "smooth",
                    block: "nearest",
                    inline: "nearest"
                });
            } else if (
                e.key === "ArrowUp"
                && focused.previousElementSibling
                && focused.previousElementSibling.classList.contains("search-result")
            ) {
                focused.classList.remove("focused");
                focused.previousElementSibling.classList.add("focused");
                focused.previousElementSibling.scrollIntoView({
                    behavior: "smooth",
                    block: "nearest",
                    inline: "nearest"
                });
            } else if (
                e.key === "Enter"
            ) {
                focused.querySelector("a").click();
            }
        }
    });
</script></body>
</html>